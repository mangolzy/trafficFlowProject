{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>did</th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97ebd0c6680f7c0535dbfdead6e51b4b</td>\n",
       "      <td>dd65fa250fca2833a3a8c16d2cf0457c</td>\n",
       "      <td>ed180d7daf639d936f1aeae4f7fb482f</td>\n",
       "      <td>4725c39a5e5f4c188d382da3910b3f3f</td>\n",
       "      <td>3e12208dd0be281c92a6ab57d9a6fb32</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>13:37:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92c3ac9251cc9b5aab90b114a1e363be</td>\n",
       "      <td>c077e0297639edcb1df6189e8cda2c3d</td>\n",
       "      <td>191a180f0a262aff3267775c4fac8972</td>\n",
       "      <td>82cc4851f9e4faa4e54309f8bb73fd7c</td>\n",
       "      <td>b05379ac3f9b7d99370d443cfd5dcc28</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>09:47:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abeefc3e2aec952468e2fd42a1649640</td>\n",
       "      <td>86dbc1b68de435957c61b5a523854b69</td>\n",
       "      <td>7029e813bb3de8cc73a8615e2785070c</td>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>18:24:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb31d0be64cda3cc66b46617bf49a05c</td>\n",
       "      <td>4fadfa6eeaa694742de036dddf02b0c4</td>\n",
       "      <td>21dc133ac68e4c07803d1c2f48988a83</td>\n",
       "      <td>4b7f6f4e2bf237b6cc58f57142bea5c0</td>\n",
       "      <td>4b7f6f4e2bf237b6cc58f57142bea5c0</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>22:13:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139d492189ae5a933122c098f63252b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26963cc76da2d8450d8f23fc357db987</td>\n",
       "      <td>fc34648599753c9e74ab238e9a4a07ad</td>\n",
       "      <td>87285a66236346350541b8815c5fae94</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>17:00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                oid                               did  \\\n",
       "0  97ebd0c6680f7c0535dbfdead6e51b4b  dd65fa250fca2833a3a8c16d2cf0457c   \n",
       "1  92c3ac9251cc9b5aab90b114a1e363be  c077e0297639edcb1df6189e8cda2c3d   \n",
       "2  abeefc3e2aec952468e2fd42a1649640  86dbc1b68de435957c61b5a523854b69   \n",
       "3  cb31d0be64cda3cc66b46617bf49a05c  4fadfa6eeaa694742de036dddf02b0c4   \n",
       "4  139d492189ae5a933122c098f63252b3                               NaN   \n",
       "\n",
       "                                pid                             start  \\\n",
       "0  ed180d7daf639d936f1aeae4f7fb482f  4725c39a5e5f4c188d382da3910b3f3f   \n",
       "1  191a180f0a262aff3267775c4fac8972  82cc4851f9e4faa4e54309f8bb73fd7c   \n",
       "2  7029e813bb3de8cc73a8615e2785070c  fff4e8465d1e12621bc361276b6217cf   \n",
       "3  21dc133ac68e4c07803d1c2f48988a83  4b7f6f4e2bf237b6cc58f57142bea5c0   \n",
       "4  26963cc76da2d8450d8f23fc357db987  fc34648599753c9e74ab238e9a4a07ad   \n",
       "\n",
       "                                end  price        date      time  \n",
       "0  3e12208dd0be281c92a6ab57d9a6fb32     24  2016-01-01  13:37:23  \n",
       "1  b05379ac3f9b7d99370d443cfd5dcc28      2  2016-01-01  09:47:54  \n",
       "2  fff4e8465d1e12621bc361276b6217cf      9  2016-01-01  18:24:02  \n",
       "3  4b7f6f4e2bf237b6cc58f57142bea5c0     11  2016-01-01  22:13:27  \n",
       "4  87285a66236346350541b8815c5fae94      4  2016-01-01  17:00:06  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# order = pd.read_csv('./order_data_2016-01-01')\n",
    "order = pd.read_table(\"./order_data_2016-01-01\", delim_whitespace=True, header=None)\n",
    "col = ['oid','did','pid','start','end','price','date','time']\n",
    "order.columns = col\n",
    "order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>501287.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.792990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.913423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>499.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               price\n",
       "count  501287.000000\n",
       "mean       18.792990\n",
       "std        16.913423\n",
       "min         0.000000\n",
       "25%         8.000000\n",
       "50%        14.000000\n",
       "75%        23.000000\n",
       "max       499.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37661"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = set(order['did'])\n",
    "len(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250378"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passenger = set(order['pid'])\n",
    "len(passenger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = set(order['start'])\n",
    "end = set(order['end'])\n",
    "len(start)\n",
    "# len(end)   363    we consider only the start point here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'08232402614a9b48895cc3d0aeb0e9f2': '50',\n",
       " '08f5b445ec6b29deba62e6fd8b0325a6': '43',\n",
       " '0a5fef95db34383403d11cb6af937309': '63',\n",
       " '1afd7afbc81ecc1b13886a569d869e8a': '46',\n",
       " '1c60154546102e6525f68cb4f31e0657': '56',\n",
       " '1cbfbdd079ef93e74405c53fcfff8567': '6',\n",
       " '1ecbb52d73c522f184a6fc53128b1ea1': '66',\n",
       " '2301bc920194c95cf0c7486e5675243c': '31',\n",
       " '2350be163432e42270d2670cb3c02f80': '18',\n",
       " '2407d482f0ffa22a947068f2551fe62c': '28',\n",
       " '2920ece99323b4c111d6f9affc7ea034': '14',\n",
       " '307afa4120c590b3a46cf4ff5415608a': '16',\n",
       " '364bf755f9b270f0f9141d1a61de43ee': '21',\n",
       " '38d5ad2d22b61109fd8e7b43cd0e8901': '24',\n",
       " '3a43dcdff3c0b66b1acb1644ff055f9d': '25',\n",
       " '3e12208dd0be281c92a6ab57d9a6fb32': '47',\n",
       " '445ff793ebd3477d4a2e0b36b2db9271': '55',\n",
       " '44c097b7bd219d104050abbafe51bd49': '35',\n",
       " '4725c39a5e5f4c188d382da3910b3f3f': '23',\n",
       " '49ac89aa860c27e26c0836cb8dab2df2': '60',\n",
       " '4b7f6f4e2bf237b6cc58f57142bea5c0': '13',\n",
       " '4b9e4cf2fbdc8281b8a1f9f12b80ce4d': '5',\n",
       " '4f4041f7db0c7f69892d9b74c1a7efa1': '10',\n",
       " '4f8d81b5c31af5d1ba579a65ddc8a5cb': '38',\n",
       " '52a4e8aaa12f70020e889aed8fd5ddbc': '29',\n",
       " '52d7b69796362a8ed1691a6cc02ddde4': '33',\n",
       " '52e56004d92b8c74d53e1e42699cba6f': '26',\n",
       " '58c7a4888306d8ff3a641d1c0feccbe3': '3',\n",
       " '62afaf3288e236b389af9cfdc5206415': '48',\n",
       " '693a21b16653871bbd455403da5412b4': '39',\n",
       " '73ff8ef735e1d68f0cdcbb84d788f2b6': '40',\n",
       " '74c1c25f4b283fa74a5514307b0d0278': '12',\n",
       " '74ec84f1cf75cf89ae176c8c6ceec5ba': '49',\n",
       " '7f84bdfc2b6d4541e1f6c0a3349e0251': '52',\n",
       " '825a21aa308dea206adb49c4b77c7805': '65',\n",
       " '825c426141df01d38c1b9e9c5330bdac': '30',\n",
       " '82cc4851f9e4faa4e54309f8bb73fd7c': '8',\n",
       " '8316146a6f78cc6d9f113f0390859417': '44',\n",
       " '87285a66236346350541b8815c5fae94': '22',\n",
       " '8bb37d24db1ad665e706c2655d9c4c72': '34',\n",
       " '90c5a34f06ac86aee0fd70e2adce7d8a': '1',\n",
       " '91690261186ae5bee8f83808ea1e4a01': '20',\n",
       " '929ec6c160e6f52c20a4217c7978f681': '7',\n",
       " 'a5609739c6b5c2719a3752327c5e33a7': '19',\n",
       " 'a735449c5c09df639c35a7d61fad3ee5': '62',\n",
       " 'a814069db8d32f0fa6e188f41059c6e1': '17',\n",
       " 'b05379ac3f9b7d99370d443cfd5dcc28': '37',\n",
       " 'b26a240205c852804ff8758628c0a86a': '4',\n",
       " 'b702e920dcd2765e624dc1ce3a770512': '9',\n",
       " 'ba32abfc048219e933bee869741da911': '57',\n",
       " 'bf44d327f0232325c6d5280926d7b37d': '64',\n",
       " 'c4ec24e0a58ebedaa1661e5c09e47bb5': '54',\n",
       " 'c9f855e3e13480aad0af64b418e810c3': '45',\n",
       " 'ca064c2682ca48c6a21de012e87c0df5': '42',\n",
       " 'cb6041cc08444746caf6039d8b9e43cb': '58',\n",
       " 'd05052b4bda7662a084f235e880f50fa': '36',\n",
       " 'd4ec2125aff74eded207d2d915ef682f': '51',\n",
       " 'd524868ce69cb9db10fc5af177fb9423': '59',\n",
       " 'd5cb17978de290c56e84c9cf97e63186': '15',\n",
       " 'dd8d3b9665536d6e05b29c2648c0e69a': '11',\n",
       " 'de092beab9305613aca8f79d7d7224e7': '61',\n",
       " 'f2c8c4bb99e6377d21de71275afd6cd2': '2',\n",
       " 'f47f35242ed40655814bc086d7514046': '53',\n",
       " 'f9280c5dab6910ed44e518248048b9fe': '41',\n",
       " 'fc34648599753c9e74ab238e9a4a07ad': '27',\n",
       " 'fff4e8465d1e12621bc361276b6217cf': '32'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone_dict = {}\n",
    "#dist = pd.read_table(\"../cluster_map/cluster_map\", delim_whitespace=True, header=None)\n",
    "f = file('../cluster_map/cluster_map', 'r')\n",
    "zone_list = []\n",
    "# iterate over the lines in the file\n",
    "for line in f:\n",
    "    # split the line into a list of column values\n",
    "    column = line.split('\\n')[0]\n",
    "    columns = column.split('\\t')\n",
    "    # clean any whitespace off the items\n",
    "    # columns = [col.strip() for col in columns]\n",
    "\n",
    "    # ensure the column has at least one value before printing\n",
    "    if columns:\n",
    "        zone_dict[columns[0]] = columns[1] # print the first column\n",
    "        zone_list.append(columns[0])\n",
    "zone_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zone_dict['ed8eb1876d270f25e29fe4339ad41524'] = 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66]\n"
     ]
    }
   ],
   "source": [
    "print range(1,67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>did</th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>start_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501282</th>\n",
       "      <td>3f89a682ad12708095da4cbe2ccdab90</td>\n",
       "      <td>ac8c9e9a93fd7466ea26e729ce719dc4</td>\n",
       "      <td>56242551b109c1836958fa1ba09d94ba</td>\n",
       "      <td>74c1c25f4b283fa74a5514307b0d0278</td>\n",
       "      <td>74c1c25f4b283fa74a5514307b0d0278</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>20:43:07</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501283</th>\n",
       "      <td>677a78060b26e60191ff874b2b07be1d</td>\n",
       "      <td>48f1dca979de77f9a1db47cf867317f7</td>\n",
       "      <td>f5636ff3c2dbce0bf29283abbd0d48d7</td>\n",
       "      <td>2407d482f0ffa22a947068f2551fe62c</td>\n",
       "      <td>91690261186ae5bee8f83808ea1e4a01</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>15:27:42</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501284</th>\n",
       "      <td>b63daeda6d2f6d07af9d3bb37ebc8318</td>\n",
       "      <td>8c4c2fea7256337d2bbcc9fd2d1ae349</td>\n",
       "      <td>92ce1d70618e510792555ff10d96dd61</td>\n",
       "      <td>929ec6c160e6f52c20a4217c7978f681</td>\n",
       "      <td>d4ec2125aff74eded207d2d915ef682f</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>21:49:58</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501285</th>\n",
       "      <td>c0060c34335286a268f6783bf860062c</td>\n",
       "      <td>9ea6d19f8607f1a0df3fa1577b32953a</td>\n",
       "      <td>b030de3d2c88ba6d88b1eca06c74050f</td>\n",
       "      <td>825a21aa308dea206adb49c4b77c7805</td>\n",
       "      <td>2308e5edf2fbee52203b5c262f557ddf</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>13:05:37</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501286</th>\n",
       "      <td>892d1416f003cd5b0d7d751d69900e02</td>\n",
       "      <td>c20498e62d06829df93c2b1455866d3d</td>\n",
       "      <td>d5a45b1681a35d2d456d62d51556ec0d</td>\n",
       "      <td>d4ec2125aff74eded207d2d915ef682f</td>\n",
       "      <td>d4ec2125aff74eded207d2d915ef682f</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>11:05:59</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     oid                               did  \\\n",
       "501282  3f89a682ad12708095da4cbe2ccdab90  ac8c9e9a93fd7466ea26e729ce719dc4   \n",
       "501283  677a78060b26e60191ff874b2b07be1d  48f1dca979de77f9a1db47cf867317f7   \n",
       "501284  b63daeda6d2f6d07af9d3bb37ebc8318  8c4c2fea7256337d2bbcc9fd2d1ae349   \n",
       "501285  c0060c34335286a268f6783bf860062c  9ea6d19f8607f1a0df3fa1577b32953a   \n",
       "501286  892d1416f003cd5b0d7d751d69900e02  c20498e62d06829df93c2b1455866d3d   \n",
       "\n",
       "                                     pid                             start  \\\n",
       "501282  56242551b109c1836958fa1ba09d94ba  74c1c25f4b283fa74a5514307b0d0278   \n",
       "501283  f5636ff3c2dbce0bf29283abbd0d48d7  2407d482f0ffa22a947068f2551fe62c   \n",
       "501284  92ce1d70618e510792555ff10d96dd61  929ec6c160e6f52c20a4217c7978f681   \n",
       "501285  b030de3d2c88ba6d88b1eca06c74050f  825a21aa308dea206adb49c4b77c7805   \n",
       "501286  d5a45b1681a35d2d456d62d51556ec0d  d4ec2125aff74eded207d2d915ef682f   \n",
       "\n",
       "                                     end  price        date      time  \\\n",
       "501282  74c1c25f4b283fa74a5514307b0d0278    7.0  2016-01-01  20:43:07   \n",
       "501283  91690261186ae5bee8f83808ea1e4a01    7.0  2016-01-01  15:27:42   \n",
       "501284  d4ec2125aff74eded207d2d915ef682f   15.0  2016-01-01  21:49:58   \n",
       "501285  2308e5edf2fbee52203b5c262f557ddf   12.0  2016-01-01  13:05:37   \n",
       "501286  d4ec2125aff74eded207d2d915ef682f   10.6  2016-01-01  11:05:59   \n",
       "\n",
       "       start_index  \n",
       "501282          12  \n",
       "501283          28  \n",
       "501284           7  \n",
       "501285          65  \n",
       "501286          51  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order['start_index'] = order['start'].map(lambda x : zone_dict[x])\n",
    "#order['end_index'] = filter(lambda x: x in zone_list,  order['end'])\n",
    "order.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#accept = order[order['did'].isnull()]   175710\n",
    "accept = order[order['did'].notnull()] # 325577 =      501287\n",
    "gap = order[order['did'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>325577.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.445547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.742865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>463.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               price\n",
       "count  325577.000000\n",
       "mean       17.445547\n",
       "std        15.742865\n",
       "min         0.000000\n",
       "25%         8.000000\n",
       "50%        13.000000\n",
       "75%        21.400000\n",
       "max       463.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accept.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns \n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/IPython/kernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Library/Python/2.7/site-packages/IPython/kernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from IPython.kernel.zmq import kernelapp as app\n",
      "/Library/Python/2.7/site-packages/IPython/kernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Library/Python/2.7/site-packages/IPython/kernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>did</th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>start_index</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97ebd0c6680f7c0535dbfdead6e51b4b</td>\n",
       "      <td>dd65fa250fca2833a3a8c16d2cf0457c</td>\n",
       "      <td>ed180d7daf639d936f1aeae4f7fb482f</td>\n",
       "      <td>4725c39a5e5f4c188d382da3910b3f3f</td>\n",
       "      <td>3e12208dd0be281c92a6ab57d9a6fb32</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>13:37:23</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92c3ac9251cc9b5aab90b114a1e363be</td>\n",
       "      <td>c077e0297639edcb1df6189e8cda2c3d</td>\n",
       "      <td>191a180f0a262aff3267775c4fac8972</td>\n",
       "      <td>82cc4851f9e4faa4e54309f8bb73fd7c</td>\n",
       "      <td>b05379ac3f9b7d99370d443cfd5dcc28</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>09:47:54</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abeefc3e2aec952468e2fd42a1649640</td>\n",
       "      <td>86dbc1b68de435957c61b5a523854b69</td>\n",
       "      <td>7029e813bb3de8cc73a8615e2785070c</td>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>18:24:02</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb31d0be64cda3cc66b46617bf49a05c</td>\n",
       "      <td>4fadfa6eeaa694742de036dddf02b0c4</td>\n",
       "      <td>21dc133ac68e4c07803d1c2f48988a83</td>\n",
       "      <td>4b7f6f4e2bf237b6cc58f57142bea5c0</td>\n",
       "      <td>4b7f6f4e2bf237b6cc58f57142bea5c0</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>22:13:27</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17c1c85144ab532947c7ea724fdcc945</td>\n",
       "      <td>115ac9b23f00a2e6d8a3041e23469f41</td>\n",
       "      <td>2f206d28eb6d7daa6d058304c00782de</td>\n",
       "      <td>a5609739c6b5c2719a3752327c5e33a7</td>\n",
       "      <td>a5609739c6b5c2719a3752327c5e33a7</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>17:34:33</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                oid                               did  \\\n",
       "0  97ebd0c6680f7c0535dbfdead6e51b4b  dd65fa250fca2833a3a8c16d2cf0457c   \n",
       "1  92c3ac9251cc9b5aab90b114a1e363be  c077e0297639edcb1df6189e8cda2c3d   \n",
       "2  abeefc3e2aec952468e2fd42a1649640  86dbc1b68de435957c61b5a523854b69   \n",
       "3  cb31d0be64cda3cc66b46617bf49a05c  4fadfa6eeaa694742de036dddf02b0c4   \n",
       "6  17c1c85144ab532947c7ea724fdcc945  115ac9b23f00a2e6d8a3041e23469f41   \n",
       "\n",
       "                                pid                             start  \\\n",
       "0  ed180d7daf639d936f1aeae4f7fb482f  4725c39a5e5f4c188d382da3910b3f3f   \n",
       "1  191a180f0a262aff3267775c4fac8972  82cc4851f9e4faa4e54309f8bb73fd7c   \n",
       "2  7029e813bb3de8cc73a8615e2785070c  fff4e8465d1e12621bc361276b6217cf   \n",
       "3  21dc133ac68e4c07803d1c2f48988a83  4b7f6f4e2bf237b6cc58f57142bea5c0   \n",
       "6  2f206d28eb6d7daa6d058304c00782de  a5609739c6b5c2719a3752327c5e33a7   \n",
       "\n",
       "                                end  price        date      time start_index  \\\n",
       "0  3e12208dd0be281c92a6ab57d9a6fb32     24  2016-01-01  13:37:23          23   \n",
       "1  b05379ac3f9b7d99370d443cfd5dcc28      2  2016-01-01  09:47:54           8   \n",
       "2  fff4e8465d1e12621bc361276b6217cf      9  2016-01-01  18:24:02          32   \n",
       "3  4b7f6f4e2bf237b6cc58f57142bea5c0     11  2016-01-01  22:13:27          13   \n",
       "6  a5609739c6b5c2719a3752327c5e33a7      6  2016-01-01  17:34:33          19   \n",
       "\n",
       "   i   j  \n",
       "0  2   1  \n",
       "1  0   8  \n",
       "2  2  10  \n",
       "3  1   2  \n",
       "6  1   8  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accept['i'] = accept['start_index'].map(lambda x : int(x) / 11 )\n",
    "accept['j'] = accept['start_index'].map(lambda x : int(x) % 11 )\n",
    "gap = order[order['did'].isnull()]\n",
    "gap['i'] = gap['start_index'].map(lambda x : int(x) / 11)\n",
    "gap['j'] = gap['start_index'].map(lambda x : int(x) % 11)\n",
    "accept.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accept_grid = accept.groupby(['i','j'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>oid</th>\n",
       "      <th>did</th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>start_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5802</td>\n",
       "      <td>5802</td>\n",
       "      <td>5802</td>\n",
       "      <td>5802</td>\n",
       "      <td>5802</td>\n",
       "      <td>5802</td>\n",
       "      <td>5802</td>\n",
       "      <td>5802</td>\n",
       "      <td>5802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12326</td>\n",
       "      <td>12326</td>\n",
       "      <td>12326</td>\n",
       "      <td>12326</td>\n",
       "      <td>12326</td>\n",
       "      <td>12326</td>\n",
       "      <td>12326</td>\n",
       "      <td>12326</td>\n",
       "      <td>12326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1095</td>\n",
       "      <td>1095</td>\n",
       "      <td>1095</td>\n",
       "      <td>1095</td>\n",
       "      <td>1095</td>\n",
       "      <td>1095</td>\n",
       "      <td>1095</td>\n",
       "      <td>1095</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>762</td>\n",
       "      <td>762</td>\n",
       "      <td>762</td>\n",
       "      <td>762</td>\n",
       "      <td>762</td>\n",
       "      <td>762</td>\n",
       "      <td>762</td>\n",
       "      <td>762</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    i   j    oid    did    pid  start    end  price   date   time  start_index\n",
       "0   0   1  23185  23185  23185  23185  23185  23185  23185  23185        23185\n",
       "1   0   2   2322   2322   2322   2322   2322   2322   2322   2322         2322\n",
       "2   0   3    292    292    292    292    292    292    292    292          292\n",
       "3   0   4   5802   5802   5802   5802   5802   5802   5802   5802         5802\n",
       "4   0   5    309    309    309    309    309    309    309    309          309\n",
       "5   0   6   1561   1561   1561   1561   1561   1561   1561   1561         1561\n",
       "6   0   7  14432  14432  14432  14432  14432  14432  14432  14432        14432\n",
       "7   0   8  24341  24341  24341  24341  24341  24341  24341  24341        24341\n",
       "8   0   9   3995   3995   3995   3995   3995   3995   3995   3995         3995\n",
       "9   0  10    298    298    298    298    298    298    298    298          298\n",
       "10  1   0   2824   2824   2824   2824   2824   2824   2824   2824         2824\n",
       "11  1   1  14205  14205  14205  14205  14205  14205  14205  14205        14205\n",
       "12  1   2   1328   1328   1328   1328   1328   1328   1328   1328         1328\n",
       "13  1   3   8215   8215   8215   8215   8215   8215   8215   8215         8215\n",
       "14  1   4     80     80     80     80     80     80     80     80           80\n",
       "15  1   5    894    894    894    894    894    894    894    894          894\n",
       "16  1   6    522    522    522    522    522    522    522    522          522\n",
       "17  1   7    804    804    804    804    804    804    804    804          804\n",
       "18  1   8   5536   5536   5536   5536   5536   5536   5536   5536         5536\n",
       "19  1   9   7872   7872   7872   7872   7872   7872   7872   7872         7872\n",
       "20  1  10   7973   7973   7973   7973   7973   7973   7973   7973         7973\n",
       "21  2   0   3397   3397   3397   3397   3397   3397   3397   3397         3397\n",
       "22  2   1  28847  28847  28847  28847  28847  28847  28847  28847        28847\n",
       "23  2   2   7996   7996   7996   7996   7996   7996   7996   7996         7996\n",
       "24  2   3   3558   3558   3558   3558   3558   3558   3558   3558         3558\n",
       "25  2   4   2226   2226   2226   2226   2226   2226   2226   2226         2226\n",
       "26  2   5   7261   7261   7261   7261   7261   7261   7261   7261         7261\n",
       "27  2   6  16822  16822  16822  16822  16822  16822  16822  16822        16822\n",
       "28  2   7   2977   2977   2977   2977   2977   2977   2977   2977         2977\n",
       "29  2   8    261    261    261    261    261    261    261    261          261\n",
       ".. ..  ..    ...    ...    ...    ...    ...    ...    ...    ...          ...\n",
       "36  3   4  12326  12326  12326  12326  12326  12326  12326  12326        12326\n",
       "37  3   5   1095   1095   1095   1095   1095   1095   1095   1095         1095\n",
       "38  3   6    713    713    713    713    713    713    713    713          713\n",
       "39  3   7    747    747    747    747    747    747    747    747          747\n",
       "40  3   8    762    762    762    762    762    762    762    762          762\n",
       "41  3   9   8565   8565   8565   8565   8565   8565   8565   8565         8565\n",
       "42  3  10    301    301    301    301    301    301    301    301          301\n",
       "43  4   0     78     78     78     78     78     78     78     78           78\n",
       "44  4   1    429    429    429    429    429    429    429    429          429\n",
       "45  4   2   9468   9468   9468   9468   9468   9468   9468   9468         9468\n",
       "46  4   3    840    840    840    840    840    840    840    840          840\n",
       "47  4   4  19410  19410  19410  19410  19410  19410  19410  19410        19410\n",
       "48  4   5    216    216    216    216    216    216    216    216          216\n",
       "49  4   6    164    164    164    164    164    164    164    164          164\n",
       "50  4   7  54132  54132  54132  54132  54132  54132  54132  54132        54132\n",
       "51  4   8    129    129    129    129    129    129    129    129          129\n",
       "52  4   9    873    873    873    873    873    873    873    873          873\n",
       "53  4  10   1855   1855   1855   1855   1855   1855   1855   1855         1855\n",
       "54  5   0    202    202    202    202    202    202    202    202          202\n",
       "55  5   1    580    580    580    580    580    580    580    580          580\n",
       "56  5   2   1465   1465   1465   1465   1465   1465   1465   1465         1465\n",
       "57  5   3    337    337    337    337    337    337    337    337          337\n",
       "58  5   4    283    283    283    283    283    283    283    283          283\n",
       "59  5   5    105    105    105    105    105    105    105    105          105\n",
       "60  5   6    296    296    296    296    296    296    296    296          296\n",
       "61  5   7     44     44     44     44     44     44     44     44           44\n",
       "62  5   8     34     34     34     34     34     34     34     34           34\n",
       "63  5   9   1471   1471   1471   1471   1471   1471   1471   1471         1471\n",
       "64  5  10    254    254    254    254    254    254    254    254          254\n",
       "65  6   0   1512   1512   1512   1512   1512   1512   1512   1512         1512\n",
       "\n",
       "[66 rows x 11 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accept_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "third arg must be a format string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-c285609de905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccept_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'oid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_zlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/matplotlib/axes.pyc\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/matplotlib/axes.pyc\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/matplotlib/axes.pyc\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'third arg must be a format string'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mlinestyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: third arg must be a format string"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD9CAYAAABHnDf0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB+WD5fosZ4hRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e1c8890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "from matplotlib import cm  \n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter  \n",
    "fig = plt.figure()  \n",
    "\n",
    "#ax = fig.gca(projection='3d') \n",
    "ax = fig.gca() \n",
    "X = accept_grid['i'].tolist() \n",
    "Y = accept_grid['j'].tolist() \n",
    "X, Y = np.meshgrid(X, Y)  \n",
    "R = accept_grid['oid'].tolist()   \n",
    "Z = R  \n",
    "ax.plot(X, Y, Z)  \n",
    "ax.set_zlim(-1.01, 1.01)  \n",
    " \n",
    "ax.zaxis.set_major_locator(LinearLocator(10))  \n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))  \n",
    " \n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5)  \n",
    " \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23185  2322   292  5802   309  1561 14432 24341  3995   298  2824]\n",
      " [14205  1328  8215    80   894   522   804  5536  7872  7973  3397]\n",
      " [28847  7996  3558  2226  7261 16822  2977   261  1141   260   860]\n",
      " [  838   970  2687 12326  1095   713   747   762  8565   301    78]\n",
      " [  429  9468   840 19410   216   164 54132   129   873  1855   202]\n",
      " [  580  1465   337   283   105   296    44    34  1471   254  1512]]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "X = accept_grid['i'].tolist() \n",
    "Y = accept_grid['j'].tolist()\n",
    "data = accept_grid['oid'].reshape(6,11)\n",
    "print data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD9CAYAAAB6DlaSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEjJJREFUeJzt3X1U1HW+wPHvD2bMkETxAdDBC1c0GDQHH6JY0DEhzdTV\n5HRFCxYfbsfWXfWW69p22x5WF655kqzdc0/rA5VrnbyV6EVWuTr5QGYu0LWgfAhuoMiaigroDsP8\n7h8u6pbN8DB8f37Z9+uc3zkgw3w+42He/PwxlKbrugAA3N78jF4AAOAdsQYABRBrAFAAsQYABRBr\nAFAAsQYABXiNdV1dXa/U1NStMTEx5VartezQoUP3yVgMAHCDydsNFi9enDN58uT8rVu3prpcLlND\nQ0MPGYsBAG7QPP1SzMWLF4Pi4uJKvv7663+WuBMA4Ds8nllXVFRE9uvX72xmZubGzz77bMSoUaP+\nnJOTszggIKBRCCE0TePXHwGgHXRd19pye49n1keOHBl9//33f1xUVJQwZsyYT5csWbK2Z8+el158\n8cXnhLgW6wanu4Mrt02zW973h9/+5gXx78+9IG2ebCtfel48+9zz0ubJ/i8byH58sr34wq/Fimd/\nLW2eyU/e6xFWvvS8WP6r56TNa3HXHX5tCmh7aZqmtzXWHv/2LRZLtcViqR4zZsynQgiRmpq6tbi4\neGRHlgQAtJ3HWIeGhp4JDw+vOnbs2FAhhCgsLEyOjY39Qs5qAIAWXl8Nsm7dup/NmTNns9Pp7DZ4\n8OCTGzduzJSx2O0gcew4o1foVElj7Uav0KnGjrMbvUKn6spfn139a7M9PF6z9vrJXfyatRByr9MZ\nQZNyhe4a2desZT42IzQ1y33uyX4uuNxyH58QCl+zBgDcHog1ACiAWAOAAog1ACiAWAOAAog1ACiA\nWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOA\nAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACjA5O0GERERlT179rzk7+/f\nbDabmw4fPnyvjMUAADd4jbWmabrD4bAHBwefl7EQAOD7WnUZRNd1rbMXAQD8sFadWScnJxf6+/s3\nP/HEE/+5YMGCN27++MqXXrj+dtLYcWLsOLvvtwQAhTkcDrvD4bB35D40Xdc93qCmpiYsLCys5uzZ\ns/1SUlJ2r1u37mdJSUn7hbgW8kan58/3tYqzDVLnRfQNkDrvg6OnpM6bOcIidZ5Mvccskjrvwqev\nSZ3ndst97rkkz+tmkv/6h+4mIeUqgqZpeluvWHj92wgLC6sRQoh+/fqdnTFjxgf8gBEA5PMY68bG\nxoDLly/fJYQQDQ0NPXbt2vXg8OHDj8pZDQDQwuM169ra2pAZM2Z8IIQQLpfLNGfOnM0PPvjgLjmr\nAQBaeIx1ZGRkRWlpqU3WMgCAW+M3GAFAAcQaABRArAFAAcQaABRArAFAAcQaABRArAFAAcQaABRA\nrAFAAcQaABRArAFAAcQaABRArAFAAcQaABRArAFAAcQaABRArAFAAcQaABRArAFAAcQaABRArAFA\nAcQaABRArAFAAcQaABRArAFAAcQaABRArAFAAcQaABTQqlg3Nzf7x8XFlUydOnV7Zy8EAPi+VsU6\nJydnsdVqLdM0Te/shQAA3+c11tXV1Zb8/PzJ8+fP/4Ou65qMpQAAf8/k7QZLly59ZfXq1csuXbrU\n81YfX/nS89ffThprF2PH2X22HAB0BQ6Hw+5wOOwduQ9N13/4ysaOHTum7Ny586HXX3/9pw6Hw75m\nzZqntm/fPvX6J2ua3vBXd0fmt5ns6zBOl9zHd6K2Xuq8mAG3/B7cKfz4d5lPVZ2/InXeoD4BUudp\nBny9dDcJKVM1TdPbeqXC42WQoqKihLy8vGmRkZEVaWlpW/bs2fNAenr6mx1bEwDQVh7PrG/20Ucf\njXv55Zef5sy6c3FmjdbizNr3lD2zvtWAtq0EAPCFVp9Z3/KTObP2Oc6s0VqcWftelzmzBgAYg1gD\ngAKINQAogFgDgAKINQAogFgDgAKINQAogFgDgAKINQAogFgDgAKINQAogFgDgAKINQAogFgDgAKI\nNQAogFgDgAKINQAogFgDgAKINQAogFgDgAKINQAogFgDgAKINQAogFgDgAKINQAogFgDgAKINQAo\ngFgDgAI8xvrq1avd4+PjP7HZbKVWq7VsxYoVv5W1GADgBpOnD3bv3v3q3r17xwcEBDS6XC5TYmLi\ngQMHDiQmJiYekLUgAKAVl0ECAgIahRDC6XR2a25u9g8ODj7f+WsBAG7m8cxaCCHcbrffyJEji0+e\nPDl44cKFv7darWU3f3zlSy9cfztp7Dgxdpzd91sCgMIcDofd4XDYO3Ifmq7rrbrhxYsXgyZOnPin\nrKysX9rtdocQQmiapjf81d2R+W3Wum19x+mS+/hO1NZLnRczoKe0WX6atFH/EKrOX5E6b1CfAKnz\nNAO+XrqbhJSpmqbpuq63aZbXM+sWQUFBFx9++OH/PnLkyOiWWAshxE/f/7wt8zrsmfFRUuf16mGW\nOm9IaKDUebWXrkqbVV57SdosIYRIiOwrdd6d3fylzhvY+06p82Rzu2Wfmgkh5LS6XTxes/7222/7\n1tXV9RJCiCtXrty5e/fulLi4uBI5qwEAWng8s66pqQnLyMjIdbvdfm632+/xxx9/a8KECf8jazkA\nwDUeYz18+PCjxcXFI2UtAwC4NX6DEQAUQKwBQAHEGgAUQKwBQAHEGgAUQKwBQAHEGgAUQKwBQAHE\nGgAUQKwBQAHEGgAUQKwBQAHEGgAUQKwBQAHEGgAUQKwBQAHEGgAUQKwBQAHEGgAUQKwBQAHEGgAU\nQKwBQAHEGgAUQKwBQAHEGgAUQKwBQAHEGgAUQKwBQAEeY11VVRU+fvz4vbGxsV8MGzbs81dfffXn\nshYDANxg8vRBs9nc9Morryy12Wyl9fX1gaNGjfpzSkrK7piYmHJZCwIAvJxZh4aGnrHZbKVCCBEY\nGFgfExNTfvr06QFyVgMAtPB4Zn2zysrKiJKSkrj4+PhPbv7z0q2/v/52qHW0CLWO8eF6AKA+h8Nh\ndzgc9o7ch6brutcb1dfXB9rtdsezzz77m+nTp394/ZM1Tf/Jlv/tyPw2e2Z8lNR5vXqYpc4z+2tS\n552rd0qbVV57SdosIYRIiOwrdd6d3fylzmt2e3/u+pK/n9yvzda0ydcCumlSHqSmabqu622a5TXW\nTU1N5ilTpux46KGHdi5ZsmTtdwfu++p8O1ZtP9s/BUmdV1N3Veq8QX0CpM6T+YSX8zS4ieTn+vkG\ned/4hBDiitMtdZ5svSWfKAkhRN9A020ba4/XrHVd1+bNm7fearWWfTfUAAB5PMb64MGDP3r77bcf\n27t37/i4uLiSuLi4koKCgkmylgMAXOPxB4yJiYkH3G43vzgDAAYjxACgAGINAAog1gCgAGINAAog\n1gCgAGINAAog1gCgAGINAAog1gCgAGINAAog1gCgAGINAAog1gCgAGINAAog1gCgAGINAAog1gCg\nAGINAAog1gCgAGINAAog1gCgAGINAAog1gCgAGINAAog1gCgAGINAAog1gCgAGINAAog1gCgAK+x\nnjt37oaQkJDa4cOHH5WxEADg+7zGOjMzc2NBQcEkGcsAAG7Na6yTkpL29+7d+4KMZQAAt2bq6B1s\nXJd9/W3bvT8ScfGJHb1LAOhSHA6H3eFw2DtyH5qu615vVFlZGTF16tTtR48eHf53n6xpevaeEx2Z\n32b/el+E1Hl3mPylzvv28l+lzut71x3SZrma3dJmCSFEyTd1UuftqTwndd6T90dInXdXd7PUeVec\nzVLnCSFEcA9/TcYcTdN0XdfbNItXgwCAAog1ACjAa6zT0tK2JCQkFB07dmxoeHh41caNGzNlLAYA\nuMHrDxi3bNmSJmMRAMAP4zIIACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiA\nWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWAOA\nAog1ACiAWAOAAog1ACiAWAOAAog1ACiAWHtwYN9HRq/QqT4+sM/oFTpVyScHjF6hUx3c33W/Pvd9\n5DB6hduO11gXFBRMio6O/nLIkCHHs7Ozl8tY6nZxoAs/GYQQ4tDBrh3r0sMHjV6hUxV14W+2+/c5\njF7htuMx1s3Nzf6LFi16raCgYFJZWZl1y5YtaeXl5TGylgMAXOMx1ocPH743KirqRERERKXZbG6a\nNWvWO9u2bfuxrOUAAH+j6/oPHu+9917q/Pnz32h5/6233nps0aJF61reF0LoHBwcHBxtPzy191aH\nSXigaZru6eO6rmuePg4A8A2Pl0EGDhx4qqqqKrzl/aqqqnCLxVLd+WsBAG7mMdajR48+cvz48SGV\nlZURTqez27vvvvsv06ZNy5O1HADgGo+XQUwmk+u1115bNHHixD81Nzf7z5s3b31MTEy5rOUAAH/T\n1ovcLcfOnTsn3X333V9GRUUdz8rKWt7e+7kdj2+++SbcbrfvtVqtX8TGxn6ek5Pzc6N36ozD5XL5\n22y2kilTpmw3ehdfHxcuXOg1c+bMrdHR0eUxMTFlH3/88X1G7+TLY9WqVSusVusXw4YNO5qWlvbH\nq1ev3mH0Th05MjMzN/Tv37922LBhR1v+7Ny5c8HJycm7hwwZciwlJWXXhQsXehm9p68e29NPP706\nOjq6/J577vlsxowZ79fV1QV5u592DXe5XP6DBw8+UVFREeF0Os0jRowoLSsrizH6L8VXR01NTWhJ\nSYlN13Vx+fLlwKFDh37VlR5fy7FmzZp/mz179uapU6fmGb2Lr4/09PTc9evXz9V1XTQ1NZla82RQ\n5aioqIiIjIz8uiXQjz766LubNm3KMHqvjhz79u1LKi4ujrs5aMuWLfuP7OzsX+i6LrKyspYvX748\ny+g9ffXYdu3aldLc3Oyn67pYvnx5VmseW7t+3byrv/46NDT0jM1mKxVCiMDAwPqYmJjy06dPDzB6\nL1+qrq625OfnT54/f/4f9C72qp6LFy8G7d+/P2nu3LkbhLh2OS8oKOii0Xv5Ss+ePS+ZzeamxsbG\nAJfLZWpsbAwYOHDgKaP36oikpKT9vXv3vnDzn+Xl5U3LyMjIFUKIjIyM3A8//HC6Mdt1zK0eW0pK\nym4/Pz+3EELEx8d/Ul1dbfF2P+2K9alTpwaGh4dXtbxvsViqT506NbA993W7q6ysjCgpKYmLj4//\nxOhdfGnp0qWvrF69elnLF0xXUlFREdmvX7+zmZmZG0eOHFm8YMGCNxobGwOM3stXgoODzz/11FNr\nBg0a9M2AAQNO9+rVqy45ObnQ6L18rba2NiQkJKRWCCFCQkJqa2trQ4zeqTNs2LBh7uTJk/O93a5d\nsfb2+uuuor6+PjA1NXVrTk7O4sDAwHqj9/GVHTt2TOnfv/9f4uLiSrraWbUQQrhcLlNxcfHIJ598\n8nfFxcUje/To0ZCVlfVLo/fylZMnTw5eu3btksrKyojTp08PqK+vD9y8efMco/fqTJqm6V2xOytX\nrvxVt27dnLNnz/6jt9u2K9b/CK+/bmpqMs+cOfO/HnvssbenT5/+odH7+FJRUVFCXl7etMjIyIq0\ntLQte/bseSA9Pf1No/fyFYvFUm2xWKrHjBnzqRBCpKambi0uLh5p9F6+cuTIkdEJCQlFffr0OWcy\nmVyPPPLI+0VFRQlG7+VrISEhtWfOnAkVQoiampqw/v37/8XonXxp06ZNP8nPz5/c2m+07Yp1V3/9\nta7r2rx589ZbrdayJUuWrDV6H19btWrVM1VVVeEVFRWR77zzzqwHHnhgz5tvvplu9F6+EhoaeiY8\nPLzq2LFjQ4UQorCwMDk2NvYLo/fylejo6C8PHTp035UrV+7UdV0rLCxMtlqtZUbv5WvTpk3Ly83N\nzRBCiNzc3IyudNJUUFAwafXq1cu2bdv24+7du19t1Se19yec+fn5Dw0dOvSrwYMHn1i1atUKo3/i\n6stj//79iZqmuUeMGFFqs9lKbDZbyc6dOycZvVdnHA6HY1xXfDVIaWnpiNGjR3/alpdGqXRkZ2f/\nouWle+np6blOp9Ns9E4dOWbNmrUlLCzstNlsdloslqoNGzZknjt3LnjChAmFqr9077uPbf369XOj\noqKODxo06P9a+rJw4cLfebsfTde73GUgAOhy+D/FAIACiDUAKIBYA4ACiDUAKIBYA4ACiDUAKOD/\nAVmSKiM0Q3q1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d06ea50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "#heatmap = plt.pcolor(data)\n",
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.pcolor(data, cmap=plt.cm.Blues)\n",
    "#ax.set_xticks(np.arange(data.shape[0])+0.5, minor=False)\n",
    "#ax.set_yticks(np.arange(data.shape[1])+0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "#ax.invert_yaxis()\n",
    "#ax.xaxis.tick_top()\n",
    "\n",
    "#ax.set_xticklabels(X, minor=False)\n",
    "#ax.set_yticklabels(Y, minor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>oid</th>\n",
       "      <th>did</th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>start_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i   j   oid   did   pid  start   end  price  date  time  start_index\n",
       "54  5   0   202   202   202    202   202    202   202   202          202\n",
       "55  5   1   580   580   580    580   580    580   580   580          580\n",
       "56  5   2  1465  1465  1465   1465  1465   1465  1465  1465         1465\n",
       "57  5   3   337   337   337    337   337    337   337   337          337\n",
       "58  5   4   283   283   283    283   283    283   283   283          283\n",
       "59  5   5   105   105   105    105   105    105   105   105          105\n",
       "60  5   6   296   296   296    296   296    296   296   296          296\n",
       "61  5   7    44    44    44     44    44     44    44    44           44\n",
       "62  5   8    34    34    34     34    34     34    34    34           34\n",
       "63  5   9  1471  1471  1471   1471  1471   1471  1471  1471         1471\n",
       "64  5  10   254   254   254    254   254    254   254   254          254"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accept_grid[accept_grid['i']== 5] #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD9CAYAAAB6DlaSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116747110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gap_grid = gap.groupby(['i','j'], as_index=False).count()\n",
    "Xg = gap_grid['i'].tolist() \n",
    "Yg = gap_grid['j'].tolist()\n",
    "datag = gap_grid['oid'].reshape(6,11)\n",
    "heatmap = plt.pcolor(datag, cmap=mpl.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accept_by_start_index = accept.groupby(['start_index'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_index</th>\n",
       "      <th>oid</th>\n",
       "      <th>did</th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "      <td>23185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "      <td>2824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "      <td>14205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "      <td>8215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "      <td>5536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "      <td>2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "      <td>7872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "      <td>7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "      <td>3397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "      <td>28847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "      <td>7996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "      <td>3558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "      <td>2226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "      <td>7261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>28</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "      <td>16822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "      <td>2977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>34</td>\n",
       "      <td>838</td>\n",
       "      <td>838</td>\n",
       "      <td>838</td>\n",
       "      <td>838</td>\n",
       "      <td>838</td>\n",
       "      <td>838</td>\n",
       "      <td>838</td>\n",
       "      <td>838</td>\n",
       "      <td>838</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>35</td>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "      <td>970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>36</td>\n",
       "      <td>2687</td>\n",
       "      <td>2687</td>\n",
       "      <td>2687</td>\n",
       "      <td>2687</td>\n",
       "      <td>2687</td>\n",
       "      <td>2687</td>\n",
       "      <td>2687</td>\n",
       "      <td>2687</td>\n",
       "      <td>2687</td>\n",
       "      <td>2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>42</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "      <td>8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>43</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>44</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>45</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>46</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "      <td>9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>47</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>48</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "      <td>19410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>49</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>50</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>51</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "      <td>54132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>52</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>53</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>54</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "      <td>1855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>55</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>56</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>57</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>58</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>59</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>60</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>61</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>62</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>63</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>64</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>65</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>66</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "      <td>1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "      <td>14432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "      <td>24341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>9</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "      <td>3995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_index    oid    did    pid  start    end  price   date   time  \\\n",
       "0             1  23185  23185  23185  23185  23185  23185  23185  23185   \n",
       "1            10    298    298    298    298    298    298    298    298   \n",
       "2            11   2824   2824   2824   2824   2824   2824   2824   2824   \n",
       "3            12  14205  14205  14205  14205  14205  14205  14205  14205   \n",
       "4            13   1328   1328   1328   1328   1328   1328   1328   1328   \n",
       "5            14   8215   8215   8215   8215   8215   8215   8215   8215   \n",
       "6            15     80     80     80     80     80     80     80     80   \n",
       "7            16    894    894    894    894    894    894    894    894   \n",
       "8            17    522    522    522    522    522    522    522    522   \n",
       "9            18    804    804    804    804    804    804    804    804   \n",
       "10           19   5536   5536   5536   5536   5536   5536   5536   5536   \n",
       "11            2   2322   2322   2322   2322   2322   2322   2322   2322   \n",
       "12           20   7872   7872   7872   7872   7872   7872   7872   7872   \n",
       "13           21   7973   7973   7973   7973   7973   7973   7973   7973   \n",
       "14           22   3397   3397   3397   3397   3397   3397   3397   3397   \n",
       "15           23  28847  28847  28847  28847  28847  28847  28847  28847   \n",
       "16           24   7996   7996   7996   7996   7996   7996   7996   7996   \n",
       "17           25   3558   3558   3558   3558   3558   3558   3558   3558   \n",
       "18           26   2226   2226   2226   2226   2226   2226   2226   2226   \n",
       "19           27   7261   7261   7261   7261   7261   7261   7261   7261   \n",
       "20           28  16822  16822  16822  16822  16822  16822  16822  16822   \n",
       "21           29   2977   2977   2977   2977   2977   2977   2977   2977   \n",
       "22            3    292    292    292    292    292    292    292    292   \n",
       "23           30    261    261    261    261    261    261    261    261   \n",
       "24           31   1141   1141   1141   1141   1141   1141   1141   1141   \n",
       "25           32    260    260    260    260    260    260    260    260   \n",
       "26           33    860    860    860    860    860    860    860    860   \n",
       "27           34    838    838    838    838    838    838    838    838   \n",
       "28           35    970    970    970    970    970    970    970    970   \n",
       "29           36   2687   2687   2687   2687   2687   2687   2687   2687   \n",
       "..          ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "36           42   8565   8565   8565   8565   8565   8565   8565   8565   \n",
       "37           43    301    301    301    301    301    301    301    301   \n",
       "38           44     78     78     78     78     78     78     78     78   \n",
       "39           45    429    429    429    429    429    429    429    429   \n",
       "40           46   9468   9468   9468   9468   9468   9468   9468   9468   \n",
       "41           47    840    840    840    840    840    840    840    840   \n",
       "42           48  19410  19410  19410  19410  19410  19410  19410  19410   \n",
       "43           49    216    216    216    216    216    216    216    216   \n",
       "44            5    309    309    309    309    309    309    309    309   \n",
       "45           50    164    164    164    164    164    164    164    164   \n",
       "46           51  54132  54132  54132  54132  54132  54132  54132  54132   \n",
       "47           52    129    129    129    129    129    129    129    129   \n",
       "48           53    873    873    873    873    873    873    873    873   \n",
       "49           54   1855   1855   1855   1855   1855   1855   1855   1855   \n",
       "50           55    202    202    202    202    202    202    202    202   \n",
       "51           56    580    580    580    580    580    580    580    580   \n",
       "52           57   1465   1465   1465   1465   1465   1465   1465   1465   \n",
       "53           58    337    337    337    337    337    337    337    337   \n",
       "54           59    283    283    283    283    283    283    283    283   \n",
       "55            6   1561   1561   1561   1561   1561   1561   1561   1561   \n",
       "56           60    105    105    105    105    105    105    105    105   \n",
       "57           61    296    296    296    296    296    296    296    296   \n",
       "58           62     44     44     44     44     44     44     44     44   \n",
       "59           63     34     34     34     34     34     34     34     34   \n",
       "60           64   1471   1471   1471   1471   1471   1471   1471   1471   \n",
       "61           65    254    254    254    254    254    254    254    254   \n",
       "62           66   1512   1512   1512   1512   1512   1512   1512   1512   \n",
       "63            7  14432  14432  14432  14432  14432  14432  14432  14432   \n",
       "64            8  24341  24341  24341  24341  24341  24341  24341  24341   \n",
       "65            9   3995   3995   3995   3995   3995   3995   3995   3995   \n",
       "\n",
       "        i      j  \n",
       "0   23185  23185  \n",
       "1     298    298  \n",
       "2    2824   2824  \n",
       "3   14205  14205  \n",
       "4    1328   1328  \n",
       "5    8215   8215  \n",
       "6      80     80  \n",
       "7     894    894  \n",
       "8     522    522  \n",
       "9     804    804  \n",
       "10   5536   5536  \n",
       "11   2322   2322  \n",
       "12   7872   7872  \n",
       "13   7973   7973  \n",
       "14   3397   3397  \n",
       "15  28847  28847  \n",
       "16   7996   7996  \n",
       "17   3558   3558  \n",
       "18   2226   2226  \n",
       "19   7261   7261  \n",
       "20  16822  16822  \n",
       "21   2977   2977  \n",
       "22    292    292  \n",
       "23    261    261  \n",
       "24   1141   1141  \n",
       "25    260    260  \n",
       "26    860    860  \n",
       "27    838    838  \n",
       "28    970    970  \n",
       "29   2687   2687  \n",
       "..    ...    ...  \n",
       "36   8565   8565  \n",
       "37    301    301  \n",
       "38     78     78  \n",
       "39    429    429  \n",
       "40   9468   9468  \n",
       "41    840    840  \n",
       "42  19410  19410  \n",
       "43    216    216  \n",
       "44    309    309  \n",
       "45    164    164  \n",
       "46  54132  54132  \n",
       "47    129    129  \n",
       "48    873    873  \n",
       "49   1855   1855  \n",
       "50    202    202  \n",
       "51    580    580  \n",
       "52   1465   1465  \n",
       "53    337    337  \n",
       "54    283    283  \n",
       "55   1561   1561  \n",
       "56    105    105  \n",
       "57    296    296  \n",
       "58     44     44  \n",
       "59     34     34  \n",
       "60   1471   1471  \n",
       "61    254    254  \n",
       "62   1512   1512  \n",
       "63  14432  14432  \n",
       "64  24341  24341  \n",
       "65   3995   3995  \n",
       "\n",
       "[66 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accept_by_start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "ok\n",
      "yes\n",
      "yes\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "25\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "#  split the datetime into 144 bins everyday\n",
    "#  and group the order data into grid && time slot\n",
    "#  distinct_driver_nb distinct_passenger_nb avg_price grid//start_index (-> poi)  slot(->weather)  => trafic slot_order next_slot_order_nb\n",
    "\n",
    "#  construct a grid poi table\n",
    "\n",
    "\n",
    "poifile = file('../poi_data/poi_data', 'r')\n",
    "max_l1_cat = 0\n",
    "max_l2_cat = 0\n",
    "\n",
    "for line in poifile:\n",
    "    # split the line into a list of column values\n",
    "    #print line\n",
    "    col = line.split('\\n')[0]\n",
    "    \n",
    "    pois = col.split('\\t')\n",
    "    #print pois\n",
    "    # clean any whitespace off the items\n",
    "    # columns = [col.strip() for col in columns]\n",
    "\n",
    "    # ensure the column has at least one value before printing\n",
    "    i = 0\n",
    "    for i in range(1,len(pois)):\n",
    "       \n",
    "        p = pois[i].split(':')[0].split('#')\n",
    "        #print p\n",
    "        #if(len(p) == 1 and int(p[0]) > max_l1_cat):\n",
    "        if(int(p[0]) > max_l1_cat):\n",
    "            print \"yes\"\n",
    "            max_l1_cat = int(p[0])\n",
    "        if(len(p) > 1 and int(p[1]) > max_l2_cat):\n",
    "            print \"ok\"\n",
    "            max_l2_cat = int(p[1])\n",
    "                \n",
    "                \n",
    "print max_l1_cat\n",
    "print max_l2_cat\n",
    "                \n",
    "                \n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "w, h = 67, 25 * 18 \n",
    "\n",
    "poi_matrix = [[0 for x in range(h)] for y in range(w)] \n",
    "print len(poi_matrix)\n",
    "print len(poi_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a list containing 5 lists, each of 8 items, all set to 0\n",
    "\n",
    "poifile = file('../poi_data/poi_data', 'r')\n",
    "count = 1\n",
    "for line in poifile:\n",
    "    # print count \n",
    "    count = count + 1\n",
    "    # split the line into a list of column values\n",
    "    #print line\n",
    "    col = line.split('\\n')[0]\n",
    "    #print col\n",
    "    pois = col.split('\\t')\n",
    "    #print pois\n",
    "    # clean any whitespace off the items\n",
    "    # columns = [col.strip() for col in columns]\n",
    "\n",
    "    # ensure the column has at least one value before printing\n",
    "    i = 0\n",
    "    row = int(zone_dict[pois[0]])\n",
    "    #print row\n",
    "    for i in range(1,len(pois)):\n",
    "        p = pois[i].split(':')[0].split('#')\n",
    "        #print \"level1 \" + p[0]\n",
    "        if(len(p) == 1 ):\n",
    "            poi_matrix[row][(int(p[0])-1) * 18 ] = (int)(pois[i].split(':')[1])\n",
    "        if(len(p) > 1):\n",
    "            #print \"level2 \" + (p[1])\n",
    "            #print (int(p[0])-1) * 25 + int(p[1])\n",
    "            poi_matrix[row][(int(p[0])-1) * 18 + int(p[1])] =(int) (pois[i].split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poi_matrix2 = [[0 for x in range(h)] for y in range(w)] \n",
    "poifile = file('../poi_data/poi_data', 'r')\n",
    "count = 1\n",
    "for line in poifile:\n",
    "    # print count \n",
    "    count = count + 1\n",
    "    # split the line into a list of column values\n",
    "    #print line\n",
    "    col = line.split('\\n')[0]\n",
    "    #print col\n",
    "    pois = col.split('\\t')\n",
    "    #print pois\n",
    "    # clean any whitespace off the items\n",
    "    # columns = [col.strip() for col in columns]\n",
    "\n",
    "    # ensure the column has at least one value before printing\n",
    "    i = 0\n",
    "    row = int(zone_dict[pois[0]])\n",
    "    #print row\n",
    "    for i in range(1,len(pois)):\n",
    "        p = pois[i].split(':')[0].split('#')\n",
    "        #print \"level1 \" + p[0]\n",
    "        if(len(p) == 1 ):\n",
    "            poi_matrix2[row-1][(int(p[0])-1) * 18 ] = (int)(pois[i].split(':')[1])\n",
    "        if(len(p) > 1):\n",
    "            #print \"level2 \" + (p[1])\n",
    "            #print (int(p[0])-1) * 25 + int(p[1])\n",
    "            poi_matrix2[row-1][(int(p[0])-1) * 18 + int(p[1])] =(int) (pois[i].split(':')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  define a function to transform time to time_slot  timestamp 144\n",
    "def time2slot(time):\n",
    "    hms =  time.split(\":\")\n",
    "    hour = hms[0]\n",
    "    minute = hms[1]\n",
    "    second = hms[2]\n",
    "    cur = (int)(hour) * 6 + (int)(minute) / 10 + 1\n",
    "    #print time\n",
    "    return cur\n",
    "\n",
    "#a = order['time']\n",
    "#a.map(lambda x: time2slot(x))\n",
    "#a\n",
    "#print time2slot('01:10:00')\n",
    "#print time2slot(order['time'][1])\n",
    "#print time2slot(order['time'][2])\n",
    "#print time2slot(order['time'][3])\n",
    "order['slot'] = order['time'].map(lambda x : time2slot(x))\n",
    "#set(order['slot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = pd.read_table(\"../weather_data/weather_data_2016-01-01\", delim_whitespace=True, header=None)\n",
    "wea_col = ['date','time','type','tampreture','pm25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     object\n",
       "1     object\n",
       "2      int64\n",
       "3    float64\n",
       "4      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>tampreture</th>\n",
       "      <th>pm25</th>\n",
       "      <th>slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>279.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.247312</td>\n",
       "      <td>6.344086</td>\n",
       "      <td>178.157706</td>\n",
       "      <td>71.103943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.932248</td>\n",
       "      <td>3.502809</td>\n",
       "      <td>29.412415</td>\n",
       "      <td>41.525583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>35.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>106.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             type  tampreture        pm25        slot\n",
       "count  279.000000  279.000000  279.000000  279.000000\n",
       "mean     2.247312    6.344086  178.157706   71.103943\n",
       "std      1.932248    3.502809   29.412415   41.525583\n",
       "min      1.000000    2.000000  126.000000    1.000000\n",
       "25%      1.000000    3.000000  153.500000   35.500000\n",
       "50%      2.000000    7.000000  181.000000   70.000000\n",
       "75%      2.000000    9.000000  205.000000  106.500000\n",
       "max      9.000000   13.000000  232.000000  144.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns = wea_col\n",
    "weather['slot'] = weather['time'].map(lambda x: time2slot(x))\n",
    "weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  road level traffic flow\n",
    "\n",
    "def traffic2flow(string):\n",
    "    pair = string.split(\":\")\n",
    "    level = pair[0]\n",
    "    flow = pair[1]\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "      <th>grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ecbb52d73c522f184a6fc53128b1ea1</td>\n",
       "      <td>231</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>23:30:22</td>\n",
       "      <td>142</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ecbb52d73c522f184a6fc53128b1ea1</td>\n",
       "      <td>305</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>09:10:25</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bf44d327f0232325c6d5280926d7b37d</td>\n",
       "      <td>579</td>\n",
       "      <td>87</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>21:50:27</td>\n",
       "      <td>132</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bf44d327f0232325c6d5280926d7b37d</td>\n",
       "      <td>242</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>06:20:15</td>\n",
       "      <td>39</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bf44d327f0232325c6d5280926d7b37d</td>\n",
       "      <td>471</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:50:26</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              index  one two three four        date      time  \\\n",
       "0  1ecbb52d73c522f184a6fc53128b1ea1  231  33    13   10  2016-01-01  23:30:22   \n",
       "1  1ecbb52d73c522f184a6fc53128b1ea1  305  69    13   16  2016-01-01  09:10:25   \n",
       "2  bf44d327f0232325c6d5280926d7b37d  579  87    28   16  2016-01-01  21:50:27   \n",
       "3  bf44d327f0232325c6d5280926d7b37d  242  28    10    9  2016-01-01  06:20:15   \n",
       "4  bf44d327f0232325c6d5280926d7b37d  471  35    15   17  2016-01-01  00:50:26   \n",
       "\n",
       "   slot grid  \n",
       "0   142   66  \n",
       "1    56   66  \n",
       "2   132   64  \n",
       "3    39   64  \n",
       "4     6   64  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic = pd.read_table(\"../traffic_data/traffic_data_2016-01-01\", delim_whitespace=True, header=None)\n",
    "tra_col = ['index','one','two','three','four','date','time']\n",
    "traffic.columns = tra_col\n",
    "traffic['slot'] = traffic['time'].map(lambda x: time2slot(x))\n",
    "traffic['grid'] = traffic['index'].map(lambda x: zone_dict[x])\n",
    "traffic['one'] = traffic['one'].map(lambda x: traffic2flow(x))\n",
    "traffic['two'] = traffic['two'].map(lambda x: traffic2flow(x))\n",
    "traffic['three'] = traffic['three'].map(lambda x: traffic2flow(x))\n",
    "traffic['four'] = traffic['four'].map(lambda x: traffic2flow(x))\n",
    "traffic.head()\n",
    "# traffic table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>did</th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>start_index</th>\n",
       "      <th>slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97ebd0c6680f7c0535dbfdead6e51b4b</td>\n",
       "      <td>dd65fa250fca2833a3a8c16d2cf0457c</td>\n",
       "      <td>ed180d7daf639d936f1aeae4f7fb482f</td>\n",
       "      <td>4725c39a5e5f4c188d382da3910b3f3f</td>\n",
       "      <td>3e12208dd0be281c92a6ab57d9a6fb32</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>13:37:23</td>\n",
       "      <td>23</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92c3ac9251cc9b5aab90b114a1e363be</td>\n",
       "      <td>c077e0297639edcb1df6189e8cda2c3d</td>\n",
       "      <td>191a180f0a262aff3267775c4fac8972</td>\n",
       "      <td>82cc4851f9e4faa4e54309f8bb73fd7c</td>\n",
       "      <td>b05379ac3f9b7d99370d443cfd5dcc28</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>09:47:54</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abeefc3e2aec952468e2fd42a1649640</td>\n",
       "      <td>86dbc1b68de435957c61b5a523854b69</td>\n",
       "      <td>7029e813bb3de8cc73a8615e2785070c</td>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>18:24:02</td>\n",
       "      <td>32</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb31d0be64cda3cc66b46617bf49a05c</td>\n",
       "      <td>4fadfa6eeaa694742de036dddf02b0c4</td>\n",
       "      <td>21dc133ac68e4c07803d1c2f48988a83</td>\n",
       "      <td>4b7f6f4e2bf237b6cc58f57142bea5c0</td>\n",
       "      <td>4b7f6f4e2bf237b6cc58f57142bea5c0</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>22:13:27</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139d492189ae5a933122c098f63252b3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26963cc76da2d8450d8f23fc357db987</td>\n",
       "      <td>fc34648599753c9e74ab238e9a4a07ad</td>\n",
       "      <td>87285a66236346350541b8815c5fae94</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>17:00:06</td>\n",
       "      <td>27</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                oid                               did  \\\n",
       "0  97ebd0c6680f7c0535dbfdead6e51b4b  dd65fa250fca2833a3a8c16d2cf0457c   \n",
       "1  92c3ac9251cc9b5aab90b114a1e363be  c077e0297639edcb1df6189e8cda2c3d   \n",
       "2  abeefc3e2aec952468e2fd42a1649640  86dbc1b68de435957c61b5a523854b69   \n",
       "3  cb31d0be64cda3cc66b46617bf49a05c  4fadfa6eeaa694742de036dddf02b0c4   \n",
       "4  139d492189ae5a933122c098f63252b3                               NaN   \n",
       "\n",
       "                                pid                             start  \\\n",
       "0  ed180d7daf639d936f1aeae4f7fb482f  4725c39a5e5f4c188d382da3910b3f3f   \n",
       "1  191a180f0a262aff3267775c4fac8972  82cc4851f9e4faa4e54309f8bb73fd7c   \n",
       "2  7029e813bb3de8cc73a8615e2785070c  fff4e8465d1e12621bc361276b6217cf   \n",
       "3  21dc133ac68e4c07803d1c2f48988a83  4b7f6f4e2bf237b6cc58f57142bea5c0   \n",
       "4  26963cc76da2d8450d8f23fc357db987  fc34648599753c9e74ab238e9a4a07ad   \n",
       "\n",
       "                                end  price        date      time start_index  \\\n",
       "0  3e12208dd0be281c92a6ab57d9a6fb32     24  2016-01-01  13:37:23          23   \n",
       "1  b05379ac3f9b7d99370d443cfd5dcc28      2  2016-01-01  09:47:54           8   \n",
       "2  fff4e8465d1e12621bc361276b6217cf      9  2016-01-01  18:24:02          32   \n",
       "3  4b7f6f4e2bf237b6cc58f57142bea5c0     11  2016-01-01  22:13:27          13   \n",
       "4  87285a66236346350541b8815c5fae94      4  2016-01-01  17:00:06          27   \n",
       "\n",
       "   slot  \n",
       "0    82  \n",
       "1    59  \n",
       "2   111  \n",
       "3   134  \n",
       "4   103  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order table\n",
    "order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>tampreture</th>\n",
       "      <th>pm25</th>\n",
       "      <th>slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:00:28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:05:24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:10:08</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:15:27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:20:06</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time  type  tampreture  pm25  slot\n",
       "0  2016-01-01  00:00:28     1           4   177     1\n",
       "1  2016-01-01  00:05:24     1           3   177     1\n",
       "2  2016-01-01  00:10:08     1           3   177     2\n",
       "3  2016-01-01  00:15:27     1           3   177     2\n",
       "4  2016-01-01  00:20:06     1           3   177     3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weather table\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zone_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# poi table\n",
    "poi = pd.DataFrame(data = poi_matrix, columns = range(0, 25*18), index = range(1,68))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2739</td>\n",
       "      <td>498</td>\n",
       "      <td>1909</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8051</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>4814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1079</td>\n",
       "      <td>3984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245</td>\n",
       "      <td>83</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>5644</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1162</td>\n",
       "      <td>2988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332</td>\n",
       "      <td>83</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>2573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>747</td>\n",
       "      <td>1743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>249</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1     2    3    4     5    6    7     8    9   ...    440   441  442  \\\n",
       "0  2739  498  1909    0   83  8051   83    0  4814    0 ...   1079  3984    0   \n",
       "1  1245   83   913    0   83  5644  166    0   747    0 ...   1162  2988    0   \n",
       "2    83    0    83    0    0   166  332    0     0   83 ...      0   498    0   \n",
       "3   332   83   415    0  166  2573    0    0   913    0 ...    747  1743    0   \n",
       "4    83    0     0   83   83   249  415    0     0   83 ...      0   166    0   \n",
       "\n",
       "   443  444  445  446  447  448  449  \n",
       "0    0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 450 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi2 = pd.DataFrame(data = poi_matrix2, columns = range(0, 25*18), index = range(0, 67))\n",
    "poi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2739</td>\n",
       "      <td>498</td>\n",
       "      <td>1909</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8051</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>4814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1079</td>\n",
       "      <td>3984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245</td>\n",
       "      <td>83</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>5644</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1162</td>\n",
       "      <td>2988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>332</td>\n",
       "      <td>83</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>2573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>747</td>\n",
       "      <td>1743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1     2    3    4     5    6    7     8    9   ...    440   441  442  \\\n",
       "1     0    0     0    0    0     0    0    0     0    0 ...      0     0    0   \n",
       "2  2739  498  1909    0   83  8051   83    0  4814    0 ...   1079  3984    0   \n",
       "3  1245   83   913    0   83  5644  166    0   747    0 ...   1162  2988    0   \n",
       "4    83    0    83    0    0   166  332    0     0   83 ...      0   498    0   \n",
       "5   332   83   415    0  166  2573    0    0   913    0 ...    747  1743    0   \n",
       "\n",
       "   443  444  445  446  447  448  449  \n",
       "1    0    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0    0  \n",
       "5    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 450 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>747</td>\n",
       "      <td>249</td>\n",
       "      <td>581</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>3652</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>1162</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>913</td>\n",
       "      <td>2075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>166</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>166</td>\n",
       "      <td>1245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>830</td>\n",
       "      <td>166</td>\n",
       "      <td>913</td>\n",
       "      <td>249</td>\n",
       "      <td>166</td>\n",
       "      <td>1494</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>1411</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>498</td>\n",
       "      <td>1577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 450 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4     5    6    7     8    9   ...   440   441  442  \\\n",
       "63    0    0    0    0    0     0   83    0     0    0 ...     0    83    0   \n",
       "64   83    0   83    0   83   415    0   83     0    0 ...    83   747    0   \n",
       "65  747  249  581    0   83  3652  166    0  1162  166 ...   913  2075    0   \n",
       "66  166   83   83    0    0   415    0    0   332    0 ...   166  1245    0   \n",
       "67  830  166  913  249  166  1494   83   83  1411   83 ...   498  1577    0   \n",
       "\n",
       "    443  444  445  446  447  448  449  \n",
       "63    0    0    0    0    0    0    0  \n",
       "64    0    0    0    0    0    0    0  \n",
       "65    0    0    0    0    0    0    0  \n",
       "66    0    0    0    0    0    0    0  \n",
       "67    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 450 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2739</td>\n",
       "      <td>498</td>\n",
       "      <td>1909</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8051</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>4814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245</td>\n",
       "      <td>83</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>5644</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>332</td>\n",
       "      <td>83</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>2573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2  3    4     5    6  7     8   9  ...    441  442  443  444  \\\n",
       "1     0    0     0  0    0     0    0  0     0   0  ...      0    0    0    0   \n",
       "2  2739  498  1909  0   83  8051   83  0  4814   0  ...   3984    0    0    0   \n",
       "3  1245   83   913  0   83  5644  166  0   747   0  ...   2988    0    0    0   \n",
       "4    83    0    83  0    0   166  332  0     0  83  ...    498    0    0    0   \n",
       "5   332   83   415  0  166  2573    0  0   913   0  ...   1743    0    0    0   \n",
       "\n",
       "   445  446  447  448  449  grid  \n",
       "1    0    0    0    0    0     1  \n",
       "2    0    0    0    0    0     2  \n",
       "3    0    0    0    0    0     3  \n",
       "4    0    0    0    0    0     4  \n",
       "5    0    0    0    0    0     5  \n",
       "\n",
       "[5 rows x 451 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi['grid'] = poi.index\n",
    "poi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2739</td>\n",
       "      <td>498</td>\n",
       "      <td>1909</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8051</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>4814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245</td>\n",
       "      <td>83</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>5644</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332</td>\n",
       "      <td>83</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>2573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>249</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2   3    4     5    6  7     8   9  ...    441  442  443  \\\n",
       "0  2739  498  1909   0   83  8051   83  0  4814   0  ...   3984    0    0   \n",
       "1  1245   83   913   0   83  5644  166  0   747   0  ...   2988    0    0   \n",
       "2    83    0    83   0    0   166  332  0     0  83  ...    498    0    0   \n",
       "3   332   83   415   0  166  2573    0  0   913   0  ...   1743    0    0   \n",
       "4    83    0     0  83   83   249  415  0     0  83  ...    166    0    0   \n",
       "\n",
       "   444  445  446  447  448  449  grid  \n",
       "0    0    0    0    0    0    0     1  \n",
       "1    0    0    0    0    0    0     2  \n",
       "2    0    0    0    0    0    0     3  \n",
       "3    0    0    0    0    0    0     4  \n",
       "4    0    0    0    0    0    0     5  \n",
       "\n",
       "[5 rows x 451 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi2['grid'] = poi2.index +1\n",
    "poi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oid</th>\n",
       "      <th>did</th>\n",
       "      <th>pid</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>start_index</th>\n",
       "      <th>slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97ebd0c6680f7c0535dbfdead6e51b4b</td>\n",
       "      <td>dd65fa250fca2833a3a8c16d2cf0457c</td>\n",
       "      <td>ed180d7daf639d936f1aeae4f7fb482f</td>\n",
       "      <td>4725c39a5e5f4c188d382da3910b3f3f</td>\n",
       "      <td>3e12208dd0be281c92a6ab57d9a6fb32</td>\n",
       "      <td>24</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>13:37:23</td>\n",
       "      <td>23</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92c3ac9251cc9b5aab90b114a1e363be</td>\n",
       "      <td>c077e0297639edcb1df6189e8cda2c3d</td>\n",
       "      <td>191a180f0a262aff3267775c4fac8972</td>\n",
       "      <td>82cc4851f9e4faa4e54309f8bb73fd7c</td>\n",
       "      <td>b05379ac3f9b7d99370d443cfd5dcc28</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>09:47:54</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abeefc3e2aec952468e2fd42a1649640</td>\n",
       "      <td>86dbc1b68de435957c61b5a523854b69</td>\n",
       "      <td>7029e813bb3de8cc73a8615e2785070c</td>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>18:24:02</td>\n",
       "      <td>32</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cb31d0be64cda3cc66b46617bf49a05c</td>\n",
       "      <td>4fadfa6eeaa694742de036dddf02b0c4</td>\n",
       "      <td>21dc133ac68e4c07803d1c2f48988a83</td>\n",
       "      <td>4b7f6f4e2bf237b6cc58f57142bea5c0</td>\n",
       "      <td>4b7f6f4e2bf237b6cc58f57142bea5c0</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>22:13:27</td>\n",
       "      <td>13</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17c1c85144ab532947c7ea724fdcc945</td>\n",
       "      <td>115ac9b23f00a2e6d8a3041e23469f41</td>\n",
       "      <td>2f206d28eb6d7daa6d058304c00782de</td>\n",
       "      <td>a5609739c6b5c2719a3752327c5e33a7</td>\n",
       "      <td>a5609739c6b5c2719a3752327c5e33a7</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>17:34:33</td>\n",
       "      <td>19</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                oid                               did  \\\n",
       "0  97ebd0c6680f7c0535dbfdead6e51b4b  dd65fa250fca2833a3a8c16d2cf0457c   \n",
       "1  92c3ac9251cc9b5aab90b114a1e363be  c077e0297639edcb1df6189e8cda2c3d   \n",
       "2  abeefc3e2aec952468e2fd42a1649640  86dbc1b68de435957c61b5a523854b69   \n",
       "3  cb31d0be64cda3cc66b46617bf49a05c  4fadfa6eeaa694742de036dddf02b0c4   \n",
       "6  17c1c85144ab532947c7ea724fdcc945  115ac9b23f00a2e6d8a3041e23469f41   \n",
       "\n",
       "                                pid                             start  \\\n",
       "0  ed180d7daf639d936f1aeae4f7fb482f  4725c39a5e5f4c188d382da3910b3f3f   \n",
       "1  191a180f0a262aff3267775c4fac8972  82cc4851f9e4faa4e54309f8bb73fd7c   \n",
       "2  7029e813bb3de8cc73a8615e2785070c  fff4e8465d1e12621bc361276b6217cf   \n",
       "3  21dc133ac68e4c07803d1c2f48988a83  4b7f6f4e2bf237b6cc58f57142bea5c0   \n",
       "6  2f206d28eb6d7daa6d058304c00782de  a5609739c6b5c2719a3752327c5e33a7   \n",
       "\n",
       "                                end  price        date      time start_index  \\\n",
       "0  3e12208dd0be281c92a6ab57d9a6fb32     24  2016-01-01  13:37:23          23   \n",
       "1  b05379ac3f9b7d99370d443cfd5dcc28      2  2016-01-01  09:47:54           8   \n",
       "2  fff4e8465d1e12621bc361276b6217cf      9  2016-01-01  18:24:02          32   \n",
       "3  4b7f6f4e2bf237b6cc58f57142bea5c0     11  2016-01-01  22:13:27          13   \n",
       "6  a5609739c6b5c2719a3752327c5e33a7      6  2016-01-01  17:34:33          19   \n",
       "\n",
       "   slot  \n",
       "0    82  \n",
       "1    59  \n",
       "2   111  \n",
       "3   134  \n",
       "6   106  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptorder = order[order['did'].notnull()]\n",
    "acceptorder.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accept_acc = acceptorder.groupby(['start_index','slot'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acceptgb = acceptorder.groupby(['start_index','slot'], as_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function merge in module pandas.tools.merge:\n",
      "\n",
      "merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True)\n",
      "    Merge DataFrame objects by performing a database-style join operation by\n",
      "    columns or indexes.\n",
      "    \n",
      "    If joining columns on columns, the DataFrame indexes *will be\n",
      "    ignored*. Otherwise if joining indexes on indexes or indexes on a column or\n",
      "    columns, the index will be passed on.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    left : DataFrame\n",
      "    right : DataFrame\n",
      "    how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      "        * left: use only keys from left frame (SQL: left outer join)\n",
      "        * right: use only keys from right frame (SQL: right outer join)\n",
      "        * outer: use union of keys from both frames (SQL: full outer join)\n",
      "        * inner: use intersection of keys from both frames (SQL: inner join)\n",
      "    on : label or list\n",
      "        Field names to join on. Must be found in both DataFrames. If on is\n",
      "        None and not merging on indexes, then it merges on the intersection of\n",
      "        the columns by default.\n",
      "    left_on : label or list, or array-like\n",
      "        Field names to join on in left DataFrame. Can be a vector or list of\n",
      "        vectors of the length of the DataFrame to use a particular vector as\n",
      "        the join key instead of columns\n",
      "    right_on : label or list, or array-like\n",
      "        Field names to join on in right DataFrame or vector/list of vectors per\n",
      "        left_on docs\n",
      "    left_index : boolean, default False\n",
      "        Use the index from the left DataFrame as the join key(s). If it is a\n",
      "        MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "        or a number of columns) must match the number of levels\n",
      "    right_index : boolean, default False\n",
      "        Use the index from the right DataFrame as the join key. Same caveats as\n",
      "        left_index\n",
      "    sort : boolean, default False\n",
      "        Sort the join keys lexicographically in the result DataFrame\n",
      "    suffixes : 2-length sequence (tuple, list, ...)\n",
      "        Suffix to apply to overlapping column names in the left and right\n",
      "        side, respectively\n",
      "    copy : boolean, default True\n",
      "        If False, do not copy data unnecessarily\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    >>> A              >>> B\n",
      "        lkey value         rkey value\n",
      "    0   foo  1         0   foo  5\n",
      "    1   bar  2         1   bar  6\n",
      "    2   baz  3         2   qux  7\n",
      "    3   foo  4         3   bar  8\n",
      "    \n",
      "    >>> merge(A, B, left_on='lkey', right_on='rkey', how='outer')\n",
      "       lkey  value_x  rkey  value_y\n",
      "    0  foo   1        foo   5\n",
      "    1  foo   4        foo   5\n",
      "    2  bar   2        bar   6\n",
      "    3  bar   2        bar   8\n",
      "    4  baz   3        NaN   NaN\n",
      "    5  NaN   NaN      qux   7\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    merged : DataFrame\n",
      "        The output type will the be same as 'left', if it is a subclass\n",
      "        of DataFrame.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_index</th>\n",
       "      <th>slot</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.365169</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15.424084</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.516484</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16.395210</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>17.171053</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_index  slot  avg_price  count\n",
       "0           1     1  19.365169    178\n",
       "1           1     2  15.424084    191\n",
       "2           1     3  16.516484    182\n",
       "3           1     4  16.395210    167\n",
       "4           1     5  17.171053    152"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgprice = acceptgb['price'].agg({'avg_price':np.mean})\n",
    "count = acceptgb['time'].agg({'count':np.count_nonzero})\n",
    "orderinfo = pd.merge(avgprice, count, how='outer', on=['start_index', 'slot'])\n",
    "orderinfo.head()   # start index 1-66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7905\n"
     ]
    }
   ],
   "source": [
    "print orderinfo.size / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function roll_mean in module pandas.algos:\n",
      "\n",
      "roll_mean(arg, window, min_periods=None, freq=None, center=False, how=None, **kwargs)\n",
      "    Moving mean.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    arg : Series, DataFrame\n",
      "    window : int\n",
      "        Size of the moving window. This is the number of observations used for\n",
      "        calculating the statistic.\n",
      "    min_periods : int, default None\n",
      "        Minimum number of observations in window required to have a value\n",
      "        (otherwise result is NA).\n",
      "    freq : string or DateOffset object, optional (default None)\n",
      "        Frequency to conform the data to before computing the statistic. Specified\n",
      "        as a frequency string or DateOffset object.\n",
      "    center : boolean, default False\n",
      "        Set the labels at the center of the window.\n",
      "    how : string, default 'None'\n",
      "        Method for down- or re-sampling\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    y : type of input argument\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    By default, the result is set to the right edge of the window. This can be\n",
      "    changed to the center of the window by setting ``center=True``.\n",
      "    \n",
      "    The `freq` keyword is used to conform time series data to a specified\n",
      "    frequency by resampling the data. This is done with the default parameters\n",
      "    of :meth:`~pandas.Series.resample` (i.e. using the `mean`).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.rolling_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#orderinfo3 = pd.rolling_mean(orderinfo['avg_price'], 3)\n",
    "#orderinfo3.head()\n",
    "#print orderinfo3.size\n",
    "orderinfo['avg_price_3'] = pd.rolling_mean(orderinfo['avg_price'],3).shift(1)\n",
    "orderinfo['avg_count_3'] = pd.rolling_mean(orderinfo['count'], 3).shift(1)\n",
    "orderinfo['price_delta_1'] = orderinfo['avg_price'] / orderinfo['avg_price'].shift(1) - 1\n",
    "orderinfo['price_delta_3'] = pd.rolling_mean(orderinfo['price_delta_1'],2).shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataFrame in module pandas.core.frame object:\n",
      "\n",
      "class DataFrame(pandas.core.generic.NDFrame)\n",
      " |  Two-dimensional size-mutable, potentially heterogeneous tabular data\n",
      " |  structure with labeled axes (rows and columns). Arithmetic operations\n",
      " |  align on both row and column labels. Can be thought of as a dict-like\n",
      " |  container for Series objects. The primary pandas data structure\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  data : numpy ndarray (structured or homogeneous), dict, or DataFrame\n",
      " |      Dict can contain Series, arrays, constants, or list-like objects\n",
      " |  index : Index or array-like\n",
      " |      Index to use for resulting frame. Will default to np.arange(n) if\n",
      " |      no indexing information part of input data and no index provided\n",
      " |  columns : Index or array-like\n",
      " |      Column labels to use for resulting frame. Will default to\n",
      " |      np.arange(n) if no column labels are provided\n",
      " |  dtype : dtype, default None\n",
      " |      Data type to force, otherwise infer\n",
      " |  copy : boolean, default False\n",
      " |      Copy data from inputs. Only affects DataFrame / 2d ndarray input\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> d = {'col1': ts1, 'col2': ts2}\n",
      " |  >>> df = DataFrame(data=d, index=index)\n",
      " |  >>> df2 = DataFrame(np.random.randn(10, 5))\n",
      " |  >>> df3 = DataFrame(np.random.randn(10, 5),\n",
      " |  ...                 columns=['a', 'b', 'c', 'd', 'e'])\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DataFrame.from_records : constructor from tuples, also record arrays\n",
      " |  DataFrame.from_dict : from dicts of Series, arrays, or dicts\n",
      " |  DataFrame.from_csv : from CSV files\n",
      " |  DataFrame.from_items : from sequence of (key, value) pairs\n",
      " |  pandas.read_csv, pandas.read_table, pandas.read_clipboard\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataFrame\n",
      " |      pandas.core.generic.NDFrame\n",
      " |      pandas.core.base.PandasObject\n",
      " |      pandas.core.base.StringMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __add__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __and__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __and__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __div__ = __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Wrapper for comparison method __eq__\n",
      " |  \n",
      " |  __floordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __floordiv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Wrapper for comparison method __ge__\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Wrapper for comparison method __gt__\n",
      " |  \n",
      " |  __iadd__ = f(self, other)\n",
      " |  \n",
      " |  __idiv__ = __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __imul__ = f(self, other)\n",
      " |  \n",
      " |  __init__(self, data=None, index=None, columns=None, dtype=None, copy=False)\n",
      " |  \n",
      " |  __ipow__ = f(self, other)\n",
      " |  \n",
      " |  __isub__ = f(self, other)\n",
      " |  \n",
      " |  __itruediv__ = f(self, other)\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Wrapper for comparison method __le__\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns length of info axis, but here we use the index\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Wrapper for comparison method __lt__\n",
      " |  \n",
      " |  __mod__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __mod__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __mul__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __mul__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Wrapper for comparison method __ne__\n",
      " |  \n",
      " |  __or__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __or__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __pow__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __pow__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __radd__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __radd__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rand__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __rand__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rdiv__ = __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rtruediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rfloordiv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rfloordiv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rmod__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rmod__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rmul__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rmul__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __ror__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __ror__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rpow__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rpow__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rsub__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rsub__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rtruediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __rtruediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __rxor__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __rxor__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  __sub__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __sub__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __truediv__(self, other, axis=None, level=None, fill_value=None)\n",
      " |      Binary operator __truediv__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  __unicode__(self)\n",
      " |      Return a string representation for a particular DataFrame\n",
      " |      \n",
      " |      Invoked by unicode(df) in py2 only. Yields a Unicode String in both\n",
      " |      py2/py3.\n",
      " |  \n",
      " |  __xor__(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator __xor__ with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  add(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator add with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  all(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      " |      Return whether all elements are True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean data. If None, will attempt to use everything,\n",
      " |          then use only boolean data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      all : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  any(self, axis=None, bool_only=None, skipna=None, level=None, **kwargs)\n",
      " |      Return whether any element is True over requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      bool_only : boolean, default None\n",
      " |          Include only boolean data. If None, will attempt to use everything,\n",
      " |          then use only boolean data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      any : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  append(self, other, ignore_index=False, verify_integrity=False)\n",
      " |      Append rows of `other` to the end of this frame, returning a new\n",
      " |      object. Columns not in this frame are added as new columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series/dict-like object, or list of these\n",
      " |          The data to append.\n",
      " |      ignore_index : boolean, default False\n",
      " |          If True, do not use the index labels.\n",
      " |      verify_integrity : boolean, default False\n",
      " |          If True, raise ValueError on creating index with duplicates.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      appended : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If a list of dict/series is passed and the keys are all contained in the\n",
      " |      DataFrame's index, the order of the columns in the resulting DataFrame\n",
      " |      will be unchanged.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      pandas.concat : General function to concatenate DataFrame, Series\n",
      " |          or Panel objects\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
      " |      >>> df\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
      " |      >>> df.append(df2)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      0  5  6\n",
      " |      1  7  8\n",
      " |      \n",
      " |      With `ignore_index` set to True:\n",
      " |      \n",
      " |      >>> df.append(df2, ignore_index=True)\n",
      " |         A  B\n",
      " |      0  1  2\n",
      " |      1  3  4\n",
      " |      2  5  6\n",
      " |      3  7  8\n",
      " |  \n",
      " |  apply(self, func, axis=0, broadcast=False, raw=False, reduce=None, args=(), **kwds)\n",
      " |      Applies function along input axis of DataFrame.\n",
      " |      \n",
      " |      Objects passed to functions are Series objects having index\n",
      " |      either the DataFrame's index (axis=0) or the columns (axis=1).\n",
      " |      Return type depends on whether passed function aggregates, or the\n",
      " |      reduce argument if the DataFrame is empty.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Function to apply to each column/row\n",
      " |      axis : {0, 1}\n",
      " |          * 0 : apply function to each column\n",
      " |          * 1 : apply function to each row\n",
      " |      broadcast : boolean, default False\n",
      " |          For aggregation functions, return object of same size with values\n",
      " |          propagated\n",
      " |      reduce : boolean or None, default None\n",
      " |          Try to apply reduction procedures. If the DataFrame is empty,\n",
      " |          apply will use reduce to determine whether the result should be a\n",
      " |          Series or a DataFrame. If reduce is None (the default), apply's\n",
      " |          return value will be guessed by calling func an empty Series (note:\n",
      " |          while guessing, exceptions raised by func will be ignored). If\n",
      " |          reduce is True a Series will always be returned, and if False a\n",
      " |          DataFrame will always be returned.\n",
      " |      raw : boolean, default False\n",
      " |          If False, convert each row or column into a Series. If raw=True the\n",
      " |          passed function will receive ndarray objects instead. If you are\n",
      " |          just applying a NumPy reduction function this will achieve much\n",
      " |          better performance\n",
      " |      args : tuple\n",
      " |          Positional arguments to pass to function in addition to the\n",
      " |          array/series\n",
      " |      Additional keyword arguments will be passed as keywords to the function\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      In the current implementation apply calls func twice on the\n",
      " |      first column/row to decide whether it can take a fast or slow\n",
      " |      code path. This can lead to unexpected behavior if func has\n",
      " |      side-effects, as they will take effect twice for the first\n",
      " |      column/row.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df.apply(numpy.sqrt) # returns DataFrame\n",
      " |      >>> df.apply(numpy.sum, axis=0) # equiv to df.sum(0)\n",
      " |      >>> df.apply(numpy.sum, axis=1) # equiv to df.sum(1)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.applymap: For elementwise operations\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : Series or DataFrame\n",
      " |  \n",
      " |  applymap(self, func)\n",
      " |      Apply a function to a DataFrame that is intended to operate\n",
      " |      elementwise, i.e. like doing map(func, series) for each series in the\n",
      " |      DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      func : function\n",
      " |          Python function, returns a single value from a single value\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      applied : DataFrame\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.apply : For operations on rows/columns\n",
      " |  \n",
      " |  assign(self, **kwargs)\n",
      " |      Assign new columns to a DataFrame, returning a new object\n",
      " |      (a copy) with all the original columns in addition to the new ones.\n",
      " |      \n",
      " |      .. versionadded:: 0.16.0\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kwargs : keyword, value pairs\n",
      " |          keywords are the column names. If the values are\n",
      " |          callable, they are computed on the DataFrame and\n",
      " |          assigned to the new columns. If the values are\n",
      " |          not callable, (e.g. a Series, scalar, or array),\n",
      " |          they are simply assigned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      df : DataFrame\n",
      " |          A new DataFrame with the new columns in addition to\n",
      " |          all the existing columns.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Since ``kwargs`` is a dictionary, the order of your\n",
      " |      arguments may not be preserved, and so the order of the\n",
      " |      new columns is not well defined. Assigning multiple\n",
      " |      columns within the same ``assign`` is possible, but you cannot\n",
      " |      reference other columns created within the same ``assign`` call.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = DataFrame({'A': range(1, 11), 'B': np.random.randn(10)})\n",
      " |      \n",
      " |      Where the value is a callable, evaluated on `df`:\n",
      " |      \n",
      " |      >>> df.assign(ln_A = lambda x: np.log(x.A))\n",
      " |          A         B      ln_A\n",
      " |      0   1  0.426905  0.000000\n",
      " |      1   2 -0.780949  0.693147\n",
      " |      2   3 -0.418711  1.098612\n",
      " |      3   4 -0.269708  1.386294\n",
      " |      4   5 -0.274002  1.609438\n",
      " |      5   6 -0.500792  1.791759\n",
      " |      6   7  1.649697  1.945910\n",
      " |      7   8 -1.495604  2.079442\n",
      " |      8   9  0.549296  2.197225\n",
      " |      9  10 -0.758542  2.302585\n",
      " |      \n",
      " |      Where the value already exists and is inserted:\n",
      " |      \n",
      " |      >>> newcol = np.log(df['A'])\n",
      " |      >>> df.assign(ln_A=newcol)\n",
      " |          A         B      ln_A\n",
      " |      0   1  0.426905  0.000000\n",
      " |      1   2 -0.780949  0.693147\n",
      " |      2   3 -0.418711  1.098612\n",
      " |      3   4 -0.269708  1.386294\n",
      " |      4   5 -0.274002  1.609438\n",
      " |      5   6 -0.500792  1.791759\n",
      " |      6   7  1.649697  1.945910\n",
      " |      7   8 -1.495604  2.079442\n",
      " |      8   9  0.549296  2.197225\n",
      " |      9  10 -0.758542  2.302585\n",
      " |  \n",
      " |  boxplot(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, **kwds)\n",
      " |      Make a box plot from DataFrame column optionally grouped by some columns or\n",
      " |      other inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : the pandas object holding the data\n",
      " |      column : column name or list of names, or vector\n",
      " |          Can be any valid input to groupby\n",
      " |      by : string or sequence\n",
      " |          Column in the DataFrame to group by\n",
      " |      ax : Matplotlib axes object, optional\n",
      " |      fontsize : int or string\n",
      " |      rot : label rotation angle\n",
      " |      figsize : A tuple (width, height) in inches\n",
      " |      grid : Setting this to True will show the grid\n",
      " |      layout : tuple (optional)\n",
      " |          (rows, columns) for the layout of the plot\n",
      " |      return_type : {'axes', 'dict', 'both'}, default 'dict'\n",
      " |          The kind of object to return. 'dict' returns a dictionary\n",
      " |          whose values are the matplotlib Lines of the boxplot;\n",
      " |          'axes' returns the matplotlib axes the boxplot is drawn on;\n",
      " |          'both' returns a namedtuple with the axes and dict.\n",
      " |      \n",
      " |          When grouping with ``by``, a dict mapping columns to ``return_type``\n",
      " |          is returned.\n",
      " |      \n",
      " |      kwds : other plotting keyword arguments to be passed to matplotlib boxplot\n",
      " |             function\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      lines : dict\n",
      " |      ax : matplotlib Axes\n",
      " |      (ax, lines): namedtuple\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use ``return_type='dict'`` when you want to tweak the appearance\n",
      " |      of the lines after plotting. In this case a dict containing the Lines\n",
      " |      making up the boxes, caps, fliers, medians, and whiskers is returned.\n",
      " |  \n",
      " |  combine(self, other, func, fill_value=None, overwrite=True)\n",
      " |      Add two DataFrame objects and do not propagate NaN values, so if for a\n",
      " |      (column, time) one frame is missing a value, it will default to the\n",
      " |      other frame's value (which might be NaN as well)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      func : function\n",
      " |      fill_value : scalar value\n",
      " |      overwrite : boolean, default True\n",
      " |          If True then overwrite values for common keys in the calling frame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  combineAdd(self, other)\n",
      " |      Add two DataFrame objects and do not propagate\n",
      " |      NaN values, so if for a (column, time) one frame is missing a\n",
      " |      value, it will default to the other frame's value (which might\n",
      " |      be NaN as well)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |  \n",
      " |  combineMult(self, other)\n",
      " |      Multiply two DataFrame objects and do not propagate NaN values, so if\n",
      " |      for a (column, time) one frame is missing a value, it will default to\n",
      " |      the other frame's value (which might be NaN as well)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |  \n",
      " |  combine_first(self, other)\n",
      " |      Combine two DataFrame objects and default to non-null values in frame\n",
      " |      calling the method. Result index columns will be the union of the\n",
      " |      respective indexes and columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      a's values prioritized, use values from b to fill holes:\n",
      " |      \n",
      " |      >>> a.combine_first(b)\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      combined : DataFrame\n",
      " |  \n",
      " |  compound(self, axis=None, skipna=None, level=None)\n",
      " |      Return the compound percentage of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      compounded : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  corr(self, method='pearson', min_periods=1)\n",
      " |      Compute pairwise correlation of columns, excluding NA/null values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'pearson', 'kendall', 'spearman'}\n",
      " |          * pearson : standard correlation coefficient\n",
      " |          * kendall : Kendall Tau correlation coefficient\n",
      " |          * spearman : Spearman rank correlation\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result. Currently only available for pearson\n",
      " |          and spearman correlation\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |  \n",
      " |  corrwith(self, other, axis=0, drop=False)\n",
      " |      Compute pairwise correlation between rows or columns of two DataFrame\n",
      " |      objects.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame\n",
      " |      axis : {0, 1}\n",
      " |          0 to compute column-wise, 1 for row-wise\n",
      " |      drop : boolean, default False\n",
      " |          Drop missing indices from result, default returns union of all\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      correls : Series\n",
      " |  \n",
      " |  count(self, axis=0, level=None, numeric_only=False)\n",
      " |      Return Series with number of non-NA/null observations over requested\n",
      " |      axis. Works with non-floating point data as well (detects NaN and None)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0, 1}\n",
      " |          0 for row-wise, 1 for column-wise\n",
      " |      level : int or level name, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), count along a\n",
      " |          particular level, collapsing into a DataFrame\n",
      " |      numeric_only : boolean, default False\n",
      " |          Include only float, int, boolean data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      count : Series (or DataFrame if level specified)\n",
      " |  \n",
      " |  cov(self, min_periods=None)\n",
      " |      Compute pairwise covariance of columns, excluding NA/null values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      min_periods : int, optional\n",
      " |          Minimum number of observations required per pair of columns\n",
      " |          to have a valid result.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      `y` contains the covariance matrix of the DataFrame's time series.\n",
      " |      The covariance is normalized by N-1 (unbiased estimator).\n",
      " |  \n",
      " |  cummax = max(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)\n",
      " |      Return cumulative max over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : Series\n",
      " |  \n",
      " |  cummin = min(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)\n",
      " |      Return cumulative min over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : Series\n",
      " |  \n",
      " |  cumprod = prod(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)\n",
      " |      Return cumulative prod over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : Series\n",
      " |  \n",
      " |  cumsum = sum(self, axis=None, dtype=None, out=None, skipna=True, **kwargs)\n",
      " |      Return cumulative sum over requested axis.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : Series\n",
      " |  \n",
      " |  diff(self, periods=1)\n",
      " |      1st discrete difference of object\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming difference\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      diffed : DataFrame\n",
      " |  \n",
      " |  div = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator truediv with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  divide = truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator truediv with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  dot(self, other)\n",
      " |      Matrix multiplication with DataFrame or Series objects\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dot_product : DataFrame or Series\n",
      " |  \n",
      " |  drop_duplicates(*args, **kwargs)\n",
      " |      Return DataFrame with duplicate rows removed, optionally only\n",
      " |      considering certain columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns\n",
      " |      take_last : boolean, default False\n",
      " |          Take the last observed row in a row. Defaults to the first row\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to drop duplicates in place or to return a copy\n",
      " |      cols : kwargs only argument of subset [deprecated]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      deduplicated : DataFrame\n",
      " |  \n",
      " |  dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
      " |      Return object with labels on given axis omitted where alternately any\n",
      " |      or all of the data are missing\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0, 1}, or tuple/list thereof\n",
      " |          Pass tuple or list to drop on multiple axes\n",
      " |      how : {'any', 'all'}\n",
      " |          * any : if any NA values are present, drop that label\n",
      " |          * all : if all values are NA, drop that label\n",
      " |      thresh : int, default None\n",
      " |          int value : require that many non-NA values\n",
      " |      subset : array-like\n",
      " |          Labels along other axis to consider, e.g. if you are dropping rows\n",
      " |          these would be a list of columns to include\n",
      " |      inplace : boolean, defalt False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : DataFrame\n",
      " |  \n",
      " |  duplicated(*args, **kwargs)\n",
      " |      Return boolean Series denoting duplicate rows, optionally only\n",
      " |      considering certain columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      subset : column label or sequence of labels, optional\n",
      " |          Only consider certain columns for identifying duplicates, by\n",
      " |          default use all of the columns\n",
      " |      take_last : boolean, default False\n",
      " |          For a set of distinct duplicate rows, flag all but the last row as\n",
      " |          duplicated. Default is for all but the first row to be flagged\n",
      " |      cols : kwargs only argument of subset [deprecated]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      duplicated : Series\n",
      " |  \n",
      " |  eq(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods eq\n",
      " |  \n",
      " |  eval(self, expr, **kwargs)\n",
      " |      Evaluate an expression in the context of the calling DataFrame\n",
      " |      instance.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : string\n",
      " |          The expression string to evaluate.\n",
      " |      kwargs : dict\n",
      " |          See the documentation for :func:`~pandas.eval` for complete details\n",
      " |          on the keyword arguments accepted by\n",
      " |          :meth:`~pandas.DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ret : ndarray, scalar, or pandas object\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.query\n",
      " |      pandas.eval\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For more details see the API documentation for :func:`~pandas.eval`.\n",
      " |      For detailed examples see :ref:`enhancing performance with eval\n",
      " |      <enhancingperf.eval>`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from numpy.random import randn\n",
      " |      >>> from pandas import DataFrame\n",
      " |      >>> df = DataFrame(randn(10, 2), columns=list('ab'))\n",
      " |      >>> df.eval('a + b')\n",
      " |      >>> df.eval('c = a + b')\n",
      " |  \n",
      " |  first_valid_index(self)\n",
      " |      Return label for first non-NA/null value\n",
      " |  \n",
      " |  floordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator floordiv with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  ge(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods ge\n",
      " |  \n",
      " |  get_value(self, index, col, takeable=False)\n",
      " |      Quickly retrieve single value at passed column and index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : row label\n",
      " |      col : column label\n",
      " |      takeable : interpret the index/col as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : scalar value\n",
      " |  \n",
      " |  gt(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods gt\n",
      " |  \n",
      " |  hist = hist_frame(data, column=None, by=None, grid=True, xlabelsize=None, xrot=None, ylabelsize=None, yrot=None, ax=None, sharex=False, sharey=False, figsize=None, layout=None, bins=10, **kwds)\n",
      " |      Draw histogram of the DataFrame's series using matplotlib / pylab.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |      column : string or sequence\n",
      " |          If passed, will be used to limit data to a subset of columns\n",
      " |      by : object, optional\n",
      " |          If passed, then used to form histograms for separate groups\n",
      " |      grid : boolean, default True\n",
      " |          Whether to show axis grid lines\n",
      " |      xlabelsize : int, default None\n",
      " |          If specified changes the x-axis label size\n",
      " |      xrot : float, default None\n",
      " |          rotation of x axis labels\n",
      " |      ylabelsize : int, default None\n",
      " |          If specified changes the y-axis label size\n",
      " |      yrot : float, default None\n",
      " |          rotation of y axis labels\n",
      " |      ax : matplotlib axes object, default None\n",
      " |      sharex : bool, if True, the X axis will be shared amongst all subplots.\n",
      " |      sharey : bool, if True, the Y axis will be shared amongst all subplots.\n",
      " |      figsize : tuple\n",
      " |          The size of the figure to create in inches by default\n",
      " |      layout: (optional) a tuple (rows, columns) for the layout of the histograms\n",
      " |      bins: integer, default 10\n",
      " |          Number of histogram bins to be used\n",
      " |      kwds : other plotting keyword arguments\n",
      " |          To be passed to hist function\n",
      " |  \n",
      " |  icol(self, i)\n",
      " |  \n",
      " |  idxmax(self, axis=0, skipna=True)\n",
      " |      Return index of first occurrence of maximum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0, 1}\n",
      " |          0 for row-wise, 1 for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be first index.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmax : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmax``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmax\n",
      " |  \n",
      " |  idxmin(self, axis=0, skipna=True)\n",
      " |      Return index of first occurrence of minimum over requested axis.\n",
      " |      NA/null values are excluded.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0, 1}\n",
      " |          0 for row-wise, 1 for column-wise\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      idxmin : Series\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This method is the DataFrame version of ``ndarray.argmin``.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      Series.idxmin\n",
      " |  \n",
      " |  iget_value(self, i, j)\n",
      " |  \n",
      " |  info(self, verbose=None, buf=None, max_cols=None, memory_usage=None, null_counts=None)\n",
      " |      Concise summary of a DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      verbose : {None, True, False}, optional\n",
      " |          Whether to print the full summary.\n",
      " |          None follows the `display.max_info_columns` setting.\n",
      " |          True or False overrides the `display.max_info_columns` setting.\n",
      " |      buf : writable buffer, defaults to sys.stdout\n",
      " |      max_cols : int, default None\n",
      " |          Determines whether full summary or short summary is printed.\n",
      " |          None follows the `display.max_info_columns` setting.\n",
      " |      memory_usage : boolean, default None\n",
      " |          Specifies whether total memory usage of the DataFrame\n",
      " |          elements (including index) should be displayed. None follows\n",
      " |          the `display.memory_usage` setting. True or False overrides\n",
      " |          the `display.memory_usage` setting. Memory usage is shown in\n",
      " |          human-readable units (base-2 representation).\n",
      " |      null_counts : boolean, default None\n",
      " |          Whether to show the non-null counts\n",
      " |          If None, then only show if the frame is smaller than max_info_rows and max_info_columns.\n",
      " |          If True, always show counts.\n",
      " |          If False, never show counts.\n",
      " |  \n",
      " |  insert(self, loc, column, value, allow_duplicates=False)\n",
      " |      Insert column into DataFrame at specified location.\n",
      " |      \n",
      " |      If `allow_duplicates` is False, raises Exception if column\n",
      " |      is already contained in the DataFrame.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      loc : int\n",
      " |          Must have 0 <= loc <= len(columns)\n",
      " |      column : object\n",
      " |      value : int, Series, or array-like\n",
      " |  \n",
      " |  irow(self, i, copy=False)\n",
      " |  \n",
      " |  isin(self, values)\n",
      " |      Return boolean DataFrame showing whether each element in the\n",
      " |      DataFrame is contained in values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      values : iterable, Series, DataFrame or dictionary\n",
      " |          The result will only be true at a location if all the\n",
      " |          labels match. If `values` is a Series, that's the index. If\n",
      " |          `values` is a dictionary, the keys must be the column names,\n",
      " |          which must match. If `values` is a DataFrame,\n",
      " |          then both the index and column labels must match.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      \n",
      " |      DataFrame of booleans\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      When ``values`` is a list:\n",
      " |      \n",
      " |      >>> df = DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      " |      >>> df.isin([1, 3, 12, 'a'])\n",
      " |             A      B\n",
      " |      0   True   True\n",
      " |      1  False  False\n",
      " |      2   True  False\n",
      " |      \n",
      " |      When ``values`` is a dict:\n",
      " |      \n",
      " |      >>> df = DataFrame({'A': [1, 2, 3], 'B': [1, 4, 7]})\n",
      " |      >>> df.isin({'A': [1, 3], 'B': [4, 7, 12]})\n",
      " |             A      B\n",
      " |      0   True  False  # Note that B didn't match the 1 here.\n",
      " |      1  False   True\n",
      " |      2   True   True\n",
      " |      \n",
      " |      When ``values`` is a Series or DataFrame:\n",
      " |      \n",
      " |      >>> df = DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'f']})\n",
      " |      >>> other = DataFrame({'A': [1, 3, 3, 2], 'B': ['e', 'f', 'f', 'e']})\n",
      " |      >>> df.isin(other)\n",
      " |             A      B\n",
      " |      0   True  False\n",
      " |      1  False  False  # Column A in `other` has a 3, but not at index 1.\n",
      " |      2   True   True\n",
      " |  \n",
      " |  iteritems(self)\n",
      " |      Iterator over (column, series) pairs\n",
      " |  \n",
      " |  iterrows(self)\n",
      " |      Iterate over rows of DataFrame as (index, Series) pairs.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      * ``iterrows`` does **not** preserve dtypes across the rows (dtypes\n",
      " |        are preserved across columns for DataFrames). For example,\n",
      " |      \n",
      " |          >>> df = DataFrame([[1, 1.0]], columns=['x', 'y'])\n",
      " |          >>> row = next(df.iterrows())[1]\n",
      " |          >>> print(row['x'].dtype)\n",
      " |          float64\n",
      " |          >>> print(df['x'].dtype)\n",
      " |          int64\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      it : generator\n",
      " |          A generator that iterates over the rows of the frame.\n",
      " |  \n",
      " |  itertuples(self, index=True)\n",
      " |      Iterate over rows of DataFrame as tuples, with index value\n",
      " |      as first element of the tuple\n",
      " |  \n",
      " |  join(self, other, on=None, how='left', lsuffix='', rsuffix='', sort=False)\n",
      " |      Join columns with other DataFrame either on index or on a key\n",
      " |      column. Efficiently Join multiple DataFrame objects by index at once by\n",
      " |      passing a list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, Series with name field set, or list of DataFrame\n",
      " |          Index should be similar to one of the columns in this one. If a\n",
      " |          Series is passed, its name attribute must be set, and that will be\n",
      " |          used as the column name in the resulting joined DataFrame\n",
      " |      on : column name, tuple/list of column names, or array-like\n",
      " |          Column(s) to use for joining, otherwise join on index. If multiples\n",
      " |          columns given, the passed DataFrame must have a MultiIndex. Can\n",
      " |          pass an array as the join key if not already contained in the\n",
      " |          calling DataFrame. Like an Excel VLOOKUP operation\n",
      " |      how : {'left', 'right', 'outer', 'inner'}\n",
      " |          How to handle indexes of the two objects. Default: 'left'\n",
      " |          for joining on index, None otherwise\n",
      " |      \n",
      " |          * left: use calling frame's index\n",
      " |          * right: use input frame's index\n",
      " |          * outer: form union of indexes\n",
      " |          * inner: use intersection of indexes\n",
      " |      lsuffix : string\n",
      " |          Suffix to use from left frame's overlapping columns\n",
      " |      rsuffix : string\n",
      " |          Suffix to use from right frame's overlapping columns\n",
      " |      sort : boolean, default False\n",
      " |          Order result DataFrame lexicographically by the join key. If False,\n",
      " |          preserves the index order of the calling (left) DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      on, lsuffix, and rsuffix options are not supported when passing a list\n",
      " |      of DataFrame objects\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      joined : DataFrame\n",
      " |  \n",
      " |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased kurtosis over requested axis using Fishers definition of\n",
      " |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      kurt : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  last_valid_index(self)\n",
      " |      Return label for last non-NA/null value\n",
      " |  \n",
      " |  le(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods le\n",
      " |  \n",
      " |  lookup(self, row_labels, col_labels)\n",
      " |      Label-based \"fancy indexing\" function for DataFrame.\n",
      " |      Given equal-length arrays of row and column labels, return an\n",
      " |      array of the values corresponding to each (row, col) pair.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      row_labels : sequence\n",
      " |          The row labels to use for lookup\n",
      " |      col_labels : sequence\n",
      " |          The column labels to use for lookup\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Akin to::\n",
      " |      \n",
      " |          result = []\n",
      " |          for row, col in zip(row_labels, col_labels):\n",
      " |              result.append(df.get_value(row, col))\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      values : ndarray\n",
      " |          The found values\n",
      " |  \n",
      " |  lt(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods lt\n",
      " |  \n",
      " |  mad(self, axis=None, skipna=None, level=None)\n",
      " |      Return the mean absolute deviation of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mad : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the maximum of the values in the object. If you\n",
      " |      want the *index* of the maximum, use ``idxmax``. This is the\n",
      " |      equivalent of the ``numpy.ndarray`` method ``argmax``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      max : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the mean of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      mean : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the median of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      median : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  memory_usage(self, index=False)\n",
      " |      Memory usage of DataFrame columns.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : bool\n",
      " |          Specifies whether to include memory usage of DataFrame's\n",
      " |          index in returned Series. If `index=True` (default is False)\n",
      " |          the first index of the Series is `Index`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sizes : Series\n",
      " |          A series with column names as index and memory usage of\n",
      " |          columns with units of bytes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Memory usage does not include memory consumed by elements that\n",
      " |      are not components of the array.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      numpy.ndarray.nbytes\n",
      " |  \n",
      " |  merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True)\n",
      " |      Merge DataFrame objects by performing a database-style join operation by\n",
      " |      columns or indexes.\n",
      " |      \n",
      " |      If joining columns on columns, the DataFrame indexes *will be\n",
      " |      ignored*. Otherwise if joining indexes on indexes or indexes on a column or\n",
      " |      columns, the index will be passed on.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      right : DataFrame\n",
      " |      how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      " |          * left: use only keys from left frame (SQL: left outer join)\n",
      " |          * right: use only keys from right frame (SQL: right outer join)\n",
      " |          * outer: use union of keys from both frames (SQL: full outer join)\n",
      " |          * inner: use intersection of keys from both frames (SQL: inner join)\n",
      " |      on : label or list\n",
      " |          Field names to join on. Must be found in both DataFrames. If on is\n",
      " |          None and not merging on indexes, then it merges on the intersection of\n",
      " |          the columns by default.\n",
      " |      left_on : label or list, or array-like\n",
      " |          Field names to join on in left DataFrame. Can be a vector or list of\n",
      " |          vectors of the length of the DataFrame to use a particular vector as\n",
      " |          the join key instead of columns\n",
      " |      right_on : label or list, or array-like\n",
      " |          Field names to join on in right DataFrame or vector/list of vectors per\n",
      " |          left_on docs\n",
      " |      left_index : boolean, default False\n",
      " |          Use the index from the left DataFrame as the join key(s). If it is a\n",
      " |          MultiIndex, the number of keys in the other DataFrame (either the index\n",
      " |          or a number of columns) must match the number of levels\n",
      " |      right_index : boolean, default False\n",
      " |          Use the index from the right DataFrame as the join key. Same caveats as\n",
      " |          left_index\n",
      " |      sort : boolean, default False\n",
      " |          Sort the join keys lexicographically in the result DataFrame\n",
      " |      suffixes : 2-length sequence (tuple, list, ...)\n",
      " |          Suffix to apply to overlapping column names in the left and right\n",
      " |          side, respectively\n",
      " |      copy : boolean, default True\n",
      " |          If False, do not copy data unnecessarily\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> A              >>> B\n",
      " |          lkey value         rkey value\n",
      " |      0   foo  1         0   foo  5\n",
      " |      1   bar  2         1   bar  6\n",
      " |      2   baz  3         2   qux  7\n",
      " |      3   foo  4         3   bar  8\n",
      " |      \n",
      " |      >>> merge(A, B, left_on='lkey', right_on='rkey', how='outer')\n",
      " |         lkey  value_x  rkey  value_y\n",
      " |      0  foo   1        foo   5\n",
      " |      1  foo   4        foo   5\n",
      " |      2  bar   2        bar   6\n",
      " |      3  bar   2        bar   8\n",
      " |      4  baz   3        NaN   NaN\n",
      " |      5  NaN   NaN      qux   7\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      merged : DataFrame\n",
      " |          The output type will the be same as 'left', if it is a subclass\n",
      " |          of DataFrame.\n",
      " |  \n",
      " |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      This method returns the minimum of the values in the object. If you\n",
      " |      want the *index* of the minimum, use ``idxmin``. This is the\n",
      " |      equivalent of the ``numpy.ndarray`` method ``argmin``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      min : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  mod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator mod with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  mode(self, axis=0, numeric_only=False)\n",
      " |      Gets the mode of each element along the axis selected. Empty if nothing\n",
      " |      has 2+ occurrences. Adds a row for each mode per label, fills in gaps\n",
      " |      with nan.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0, 1, 'index', 'columns'} (default 0)\n",
      " |          * 0/'index' : get mode of each column\n",
      " |          * 1/'columns' : get mode of each row\n",
      " |      numeric_only : boolean, default False\n",
      " |          if True, only apply to numeric columns\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      modes : DataFrame (sorted)\n",
      " |  \n",
      " |  mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator mul with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  multiply = mul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator mul with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  ne(self, other, axis='columns', level=None)\n",
      " |      Wrapper for flexible comparison methods ne\n",
      " |  \n",
      " |  pivot(self, index=None, columns=None, values=None)\n",
      " |      Reshape data (produce a \"pivot\" table) based on column values. Uses\n",
      " |      unique values from index / columns to form axes and return either\n",
      " |      DataFrame or Panel, depending on whether you request a single value\n",
      " |      column (DataFrame) or all columns (Panel)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : string or object\n",
      " |          Column name to use to make new frame's index\n",
      " |      columns : string or object\n",
      " |          Column name to use to make new frame's columns\n",
      " |      values : string or object, optional\n",
      " |          Column name to use for populating new frame's values\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For finer-tuned control, see hierarchical indexing documentation along\n",
      " |      with the related stack/unstack methods\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |          foo   bar  baz\n",
      " |      0   one   A    1.\n",
      " |      1   one   B    2.\n",
      " |      2   one   C    3.\n",
      " |      3   two   A    4.\n",
      " |      4   two   B    5.\n",
      " |      5   two   C    6.\n",
      " |      \n",
      " |      >>> df.pivot('foo', 'bar', 'baz')\n",
      " |           A   B   C\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      >>> df.pivot('foo', 'bar')['baz']\n",
      " |           A   B   C\n",
      " |      one  1   2   3\n",
      " |      two  4   5   6\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      pivoted : DataFrame\n",
      " |          If no values column specified, will have hierarchically indexed\n",
      " |          columns\n",
      " |  \n",
      " |  pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True)\n",
      " |      Create a spreadsheet-style pivot table as a DataFrame. The levels in the\n",
      " |      pivot table will be stored in MultiIndex objects (hierarchical indexes) on\n",
      " |      the index and columns of the result DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |      values : column to aggregate, optional\n",
      " |      index : a column, Grouper, array which has the same length as data, or list of them.\n",
      " |          Keys to group by on the pivot table index.\n",
      " |          If an array is passed, it is being used as the same manner as column values.\n",
      " |      columns : a column, Grouper, array which has the same length as data, or list of them.\n",
      " |          Keys to group by on the pivot table column.\n",
      " |          If an array is passed, it is being used as the same manner as column values.\n",
      " |      aggfunc : function, default numpy.mean, or list of functions\n",
      " |          If list of functions passed, the resulting pivot table will have\n",
      " |          hierarchical columns whose top level are the function names (inferred\n",
      " |          from the function objects themselves)\n",
      " |      fill_value : scalar, default None\n",
      " |          Value to replace missing values with\n",
      " |      margins : boolean, default False\n",
      " |          Add all row / columns (e.g. for subtotal / grand totals)\n",
      " |      dropna : boolean, default True\n",
      " |          Do not include columns whose entries are all NaN\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A   B   C      D\n",
      " |      0  foo one small  1\n",
      " |      1  foo one large  2\n",
      " |      2  foo one large  2\n",
      " |      3  foo two small  3\n",
      " |      4  foo two small  3\n",
      " |      5  bar one large  4\n",
      " |      6  bar one small  5\n",
      " |      7  bar two small  6\n",
      " |      8  bar two large  7\n",
      " |      \n",
      " |      >>> table = pivot_table(df, values='D', index=['A', 'B'],\n",
      " |      ...                     columns=['C'], aggfunc=np.sum)\n",
      " |      >>> table\n",
      " |                small  large\n",
      " |      foo  one  1      4\n",
      " |           two  6      NaN\n",
      " |      bar  one  5      4\n",
      " |           two  6      7\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      table : DataFrame\n",
      " |  \n",
      " |  plot = plot_frame(data, x=None, y=None, kind='line', ax=None, subplots=False, sharex=True, sharey=False, layout=None, figsize=None, use_index=True, title=None, grid=None, legend=True, style=None, logx=False, logy=False, loglog=False, xticks=None, yticks=None, xlim=None, ylim=None, rot=None, fontsize=None, colormap=None, table=False, yerr=None, xerr=None, secondary_y=False, sort_columns=False, **kwds)\n",
      " |      Make plots of DataFrame using matplotlib / pylab.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : DataFrame\n",
      " |      x : label or position, default None\n",
      " |      y : label or position, default None\n",
      " |          Allows plotting of one column versus another\n",
      " |      kind : str\n",
      " |          - 'line' : line plot (default)\n",
      " |          - 'bar' : vertical bar plot\n",
      " |          - 'barh' : horizontal bar plot\n",
      " |          - 'hist' : histogram\n",
      " |          - 'box' : boxplot\n",
      " |          - 'kde' : Kernel Density Estimation plot\n",
      " |          - 'density' : same as 'kde'\n",
      " |          - 'area' : area plot\n",
      " |          - 'pie' : pie plot\n",
      " |          - 'scatter' : scatter plot\n",
      " |          - 'hexbin' : hexbin plot\n",
      " |      ax : matplotlib axes object, default None\n",
      " |      subplots : boolean, default False\n",
      " |          Make separate subplots for each column\n",
      " |      sharex : boolean, default True\n",
      " |          In case subplots=True, share x axis\n",
      " |      sharey : boolean, default False\n",
      " |          In case subplots=True, share y axis\n",
      " |      layout : tuple (optional)\n",
      " |          (rows, columns) for the layout of subplots\n",
      " |      figsize : a tuple (width, height) in inches\n",
      " |      use_index : boolean, default True\n",
      " |          Use index as ticks for x axis\n",
      " |      title : string\n",
      " |          Title to use for the plot\n",
      " |      grid : boolean, default None (matlab style default)\n",
      " |          Axis grid lines\n",
      " |      legend : False/True/'reverse'\n",
      " |          Place legend on axis subplots\n",
      " |      style : list or dict\n",
      " |          matplotlib line style per column\n",
      " |      logx : boolean, default False\n",
      " |          Use log scaling on x axis\n",
      " |      logy : boolean, default False\n",
      " |          Use log scaling on y axis\n",
      " |      loglog : boolean, default False\n",
      " |          Use log scaling on both x and y axes\n",
      " |      xticks : sequence\n",
      " |          Values to use for the xticks\n",
      " |      yticks : sequence\n",
      " |          Values to use for the yticks\n",
      " |      xlim : 2-tuple/list\n",
      " |      ylim : 2-tuple/list\n",
      " |      rot : int, default None\n",
      " |          Rotation for ticks (xticks for vertical, yticks for horizontal plots)\n",
      " |      fontsize : int, default None\n",
      " |          Font size for xticks and yticks\n",
      " |      colormap : str or matplotlib colormap object, default None\n",
      " |          Colormap to select colors from. If string, load colormap with that name\n",
      " |          from matplotlib.\n",
      " |      colorbar : boolean, optional\n",
      " |          If True, plot colorbar (only relevant for 'scatter' and 'hexbin' plots)\n",
      " |      position : float\n",
      " |          Specify relative alignments for bar plot layout.\n",
      " |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5 (center)\n",
      " |      layout : tuple (optional)\n",
      " |          (rows, columns) for the layout of the plot\n",
      " |      table : boolean, Series or DataFrame, default False\n",
      " |          If True, draw a table using the data in the DataFrame and the data will\n",
      " |          be transposed to meet matplotlib's default layout.\n",
      " |          If a Series or DataFrame is passed, use passed data to draw a table.\n",
      " |      yerr : DataFrame, Series, array-like, dict and str\n",
      " |          See :ref:`Plotting with Error Bars <visualization.errorbars>` for detail.\n",
      " |      xerr : same types as yerr.\n",
      " |      stacked : boolean, default False in line and\n",
      " |          bar plots, and True in area plot. If True, create stacked plot.\n",
      " |      sort_columns : boolean, default False\n",
      " |          Sort column names to determine plot ordering\n",
      " |      secondary_y : boolean or sequence, default False\n",
      " |          Whether to plot on the secondary y-axis\n",
      " |          If a list/tuple, which columns to plot on secondary y-axis\n",
      " |      mark_right : boolean, default True\n",
      " |          When using a secondary_y axis, automatically mark the column\n",
      " |          labels with \"(right)\" in the legend\n",
      " |      kwds : keywords\n",
      " |          Options to pass to matplotlib plotting method\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      axes : matplotlib.AxesSubplot or np.array of them\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      - See matplotlib documentation online for more on this subject\n",
      " |      - If `kind` = 'bar' or 'barh', you can specify relative alignments\n",
      " |        for bar plot layout by `position` keyword.\n",
      " |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5 (center)\n",
      " |      - If `kind` = 'scatter' and the argument `c` is the name of a dataframe\n",
      " |        column, the values of that column are used to color each point.\n",
      " |      - If `kind` = 'hexbin', you can control the size of the bins with the\n",
      " |        `gridsize` argument. By default, a histogram of the counts around each\n",
      " |        `(x, y)` point is computed. You can specify alternative aggregations\n",
      " |        by passing values to the `C` and `reduce_C_function` arguments.\n",
      " |        `C` specifies the value at each `(x, y)` point and `reduce_C_function`\n",
      " |        is a function of one argument that reduces all the values in a bin to\n",
      " |        a single number (e.g. `mean`, `max`, `sum`, `std`).\n",
      " |  \n",
      " |  pow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator pow with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the product of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prod : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |  \n",
      " |  quantile(self, q=0.5, axis=0, numeric_only=True)\n",
      " |      Return values at the given quantile over requested axis, a la\n",
      " |      numpy.percentile.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      q : float or array-like, default 0.5 (50% quantile)\n",
      " |          0 <= q <= 1, the quantile(s) to compute\n",
      " |      axis : {0, 1}\n",
      " |          0 for row-wise, 1 for column-wise\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      quantiles : Series or DataFrame\n",
      " |          If ``q`` is an array, a DataFrame will be returned where the\n",
      " |          index is ``q``, the columns are the columns of self, and the\n",
      " |          values are the quantiles.\n",
      " |          If ``q`` is a float, a Series will be returned where the\n",
      " |          index is the columns of self and the values are the quantiles.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      >>> df = DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\n",
      " |                        columns=['a', 'b'])\n",
      " |      >>> df.quantile(.1)\n",
      " |      a    1.3\n",
      " |      b    3.7\n",
      " |      dtype: float64\n",
      " |      >>> df.quantile([.1, .5])\n",
      " |             a     b\n",
      " |      0.1  1.3   3.7\n",
      " |      0.5  2.5  55.0\n",
      " |  \n",
      " |  query(self, expr, **kwargs)\n",
      " |      Query the columns of a frame with a boolean expression.\n",
      " |      \n",
      " |      .. versionadded:: 0.13\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      expr : string\n",
      " |          The query string to evaluate.  You can refer to variables\n",
      " |          in the environment by prefixing them with an '@' character like\n",
      " |          ``@a + b``.\n",
      " |      kwargs : dict\n",
      " |          See the documentation for :func:`pandas.eval` for complete details\n",
      " |          on the keyword arguments accepted by :meth:`DataFrame.query`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      q : DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The result of the evaluation of this expression is first passed to\n",
      " |      :attr:`DataFrame.loc` and if that fails because of a\n",
      " |      multidimensional key (e.g., a DataFrame) then the result will be passed\n",
      " |      to :meth:`DataFrame.__getitem__`.\n",
      " |      \n",
      " |      This method uses the top-level :func:`pandas.eval` function to\n",
      " |      evaluate the passed query.\n",
      " |      \n",
      " |      The :meth:`~pandas.DataFrame.query` method uses a slightly\n",
      " |      modified Python syntax by default. For example, the ``&`` and ``|``\n",
      " |      (bitwise) operators have the precedence of their boolean cousins,\n",
      " |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\n",
      " |      however the semantics are different.\n",
      " |      \n",
      " |      You can change the semantics of the expression by passing the keyword\n",
      " |      argument ``parser='python'``. This enforces the same semantics as\n",
      " |      evaluation in Python space. Likewise, you can pass ``engine='python'``\n",
      " |      to evaluate an expression using Python itself as a backend. This is not\n",
      " |      recommended as it is inefficient compared to using ``numexpr`` as the\n",
      " |      engine.\n",
      " |      \n",
      " |      The :attr:`DataFrame.index` and\n",
      " |      :attr:`DataFrame.columns` attributes of the\n",
      " |      :class:`~pandas.DataFrame` instance are placed in the query namespace\n",
      " |      by default, which allows you to treat both the index and columns of the\n",
      " |      frame as a column in the frame.\n",
      " |      The identifier ``index`` is used for the frame index; you can also\n",
      " |      use the name of the index to identify it in a query.\n",
      " |      \n",
      " |      For further details and examples see the ``query`` documentation in\n",
      " |      :ref:`indexing <indexing.query>`.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.eval\n",
      " |      DataFrame.eval\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from numpy.random import randn\n",
      " |      >>> from pandas import DataFrame\n",
      " |      >>> df = DataFrame(randn(10, 2), columns=list('ab'))\n",
      " |      >>> df.query('a > b')\n",
      " |      >>> df[df.a > df.b]  # same result as the previous expression\n",
      " |  \n",
      " |  radd(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator radd with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  rank(self, axis=0, numeric_only=None, method='average', na_option='keep', ascending=True, pct=False)\n",
      " |      Compute numerical data ranks (1 through n) along axis. Equal values are\n",
      " |      assigned a rank that is the average of the ranks of those values\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0, 1}, default 0\n",
      " |          Ranks over columns (0) or rows (1)\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data\n",
      " |      method : {'average', 'min', 'max', 'first', 'dense'}\n",
      " |          * average: average rank of group\n",
      " |          * min: lowest rank in group\n",
      " |          * max: highest rank in group\n",
      " |          * first: ranks assigned in order they appear in the array\n",
      " |          * dense: like 'min', but rank always increases by 1 between groups\n",
      " |      na_option : {'keep', 'top', 'bottom'}\n",
      " |          * keep: leave NA values where they are\n",
      " |          * top: smallest rank if ascending\n",
      " |          * bottom: smallest rank if descending\n",
      " |      ascending : boolean, default True\n",
      " |          False for ranks by high (1) to low (N)\n",
      " |      pct : boolean, default False\n",
      " |          Computes percentage rank of data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ranks : DataFrame\n",
      " |  \n",
      " |  rdiv = rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator rtruediv with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  reindex(self, index=None, columns=None, **kwargs)\n",
      " |      Conform DataFrame to new index with optional filling logic, placing\n",
      " |      NA/NaN in locations having no value in the previous index. A new object\n",
      " |      is produced unless the new index is equivalent to the current one and\n",
      " |      copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index, columns : array-like, optional (can be specified in order, or as\n",
      " |          keywords)\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          Method to use for filling holes in reindexed DataFrame:\n",
      " |            * default: don't fill gaps\n",
      " |            * pad / ffill: propagate last valid observation forward to next valid\n",
      " |            * backfill / bfill: use next valid observation to fill gap\n",
      " |            * nearest: use nearest valid observations to fill gap\n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df.reindex(index=[date1, date2, date3], columns=['A', 'B', 'C'])\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : DataFrame\n",
      " |  \n",
      " |  reindex_axis(self, labels, axis=0, method=None, level=None, copy=True, limit=None, fill_value=nan)\n",
      " |      Conform input object to new index with optional filling logic,\n",
      " |      placing NA/NaN in locations having no value in the previous index. A\n",
      " |      new object is produced unless the new index is equivalent to the\n",
      " |      current one and copy=False\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : array-like\n",
      " |          New labels / index to conform to. Preferably an Index object to\n",
      " |          avoid duplicating data\n",
      " |      axis : {0,1,'index','columns'}\n",
      " |      method : {None, 'backfill'/'bfill', 'pad'/'ffill', 'nearest'}, optional\n",
      " |          Method to use for filling holes in reindexed DataFrame:\n",
      " |            * default: don't fill gaps\n",
      " |            * pad / ffill: propagate last valid observation forward to next valid\n",
      " |            * backfill / bfill: use next valid observation to fill gap\n",
      " |            * nearest: use nearest valid observations to fill gap\n",
      " |      copy : boolean, default True\n",
      " |          Return a new object, even if the passed indexes are the same\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df.reindex_axis(['A', 'B', 'C'], axis=1)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      reindex, reindex_like\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : DataFrame\n",
      " |  \n",
      " |  rename(self, index=None, columns=None, **kwargs)\n",
      " |      Alter axes input function or functions. Function / dict values must be\n",
      " |      unique (1-to-1). Labels not contained in a dict / Series will be left\n",
      " |      as-is.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index, columns : dict-like or function, optional\n",
      " |          Transformation to apply to that axis values\n",
      " |      \n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to return a new DataFrame. If True then value of copy is\n",
      " |          ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : DataFrame (new object)\n",
      " |  \n",
      " |  reorder_levels(self, order, axis=0)\n",
      " |      Rearrange index levels using input order.\n",
      " |      May not drop or duplicate levels\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      order : list of int or list of str\n",
      " |          List representing new level order. Reference level by number\n",
      " |          (position) or by key (label).\n",
      " |      axis : int\n",
      " |          Where to reorder levels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      type of caller (new object)\n",
      " |  \n",
      " |  reset_index(self, level=None, drop=False, inplace=False, col_level=0, col_fill='')\n",
      " |      For DataFrame with multi-level index, return new DataFrame with\n",
      " |      labeling information in the columns under the index names, defaulting\n",
      " |      to 'level_0', 'level_1', etc. if any are None. For a standard index,\n",
      " |      the index name will be used (if set), otherwise a default 'index' or\n",
      " |      'level_0' (if 'index' is already taken) will be used.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, str, tuple, or list, default None\n",
      " |          Only remove the given levels from the index. Removes all levels by\n",
      " |          default\n",
      " |      drop : boolean, default False\n",
      " |          Do not try to insert index into dataframe columns. This resets\n",
      " |          the index to the default integer index.\n",
      " |      inplace : boolean, default False\n",
      " |          Modify the DataFrame in place (do not create a new object)\n",
      " |      col_level : int or str, default 0\n",
      " |          If the columns have multiple levels, determines which level the\n",
      " |          labels are inserted into. By default it is inserted into the first\n",
      " |          level.\n",
      " |      col_fill : object, default ''\n",
      " |          If the columns have multiple levels, determines how the other\n",
      " |          levels are named. If None then the index name is repeated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      resetted : DataFrame\n",
      " |  \n",
      " |  rfloordiv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator rfloordiv with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  rmod(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator rmod with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  rmul(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator rmul with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  rpow(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator rpow with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  rsub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator rsub with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  rtruediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator rtruediv with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  select_dtypes(self, include=None, exclude=None)\n",
      " |      Return a subset of a DataFrame including/excluding columns based on\n",
      " |      their ``dtype``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      include, exclude : list-like\n",
      " |          A list of dtypes or strings to be included/excluded. You must pass\n",
      " |          in a non-empty sequence for at least one of these.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          * If both of ``include`` and ``exclude`` are empty\n",
      " |          * If ``include`` and ``exclude`` have overlapping elements\n",
      " |          * If any kind of string dtype is passed in.\n",
      " |      TypeError\n",
      " |          * If either of ``include`` or ``exclude`` is not a sequence\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : DataFrame\n",
      " |          The subset of the frame including the dtypes in ``include`` and\n",
      " |          excluding the dtypes in ``exclude``.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * To select all *numeric* types use the numpy dtype ``numpy.number``\n",
      " |      * To select strings you must use the ``object`` dtype, but note that\n",
      " |        this will return *all* object dtype columns\n",
      " |      * See the `numpy dtype hierarchy\n",
      " |        <http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__\n",
      " |      * To select Pandas categorical dtypes, use 'category'\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df = pd.DataFrame({'a': np.random.randn(6).astype('f4'),\n",
      " |      ...                    'b': [True, False] * 3,\n",
      " |      ...                    'c': [1.0, 2.0] * 3})\n",
      " |      >>> df\n",
      " |              a      b  c\n",
      " |      0  0.3962   True  1\n",
      " |      1  0.1459  False  2\n",
      " |      2  0.2623   True  1\n",
      " |      3  0.0764  False  2\n",
      " |      4 -0.9703   True  1\n",
      " |      5 -1.2094  False  2\n",
      " |      >>> df.select_dtypes(include=['float64'])\n",
      " |         c\n",
      " |      0  1\n",
      " |      1  2\n",
      " |      2  1\n",
      " |      3  2\n",
      " |      4  1\n",
      " |      5  2\n",
      " |      >>> df.select_dtypes(exclude=['floating'])\n",
      " |             b\n",
      " |      0   True\n",
      " |      1  False\n",
      " |      2   True\n",
      " |      3  False\n",
      " |      4   True\n",
      " |      5  False\n",
      " |  \n",
      " |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard error of the mean over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sem : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  set_index(self, keys, drop=True, append=False, inplace=False, verify_integrity=False)\n",
      " |      Set the DataFrame index (row labels) using one or more existing\n",
      " |      columns. By default yields a new object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      keys : column label or list of column labels / arrays\n",
      " |      drop : boolean, default True\n",
      " |          Delete columns to be used as the new index\n",
      " |      append : boolean, default False\n",
      " |          Whether to append columns to existing index\n",
      " |      inplace : boolean, default False\n",
      " |          Modify the DataFrame in place (do not create a new object)\n",
      " |      verify_integrity : boolean, default False\n",
      " |          Check the new index for duplicates. Otherwise defer the check until\n",
      " |          necessary. Setting to False will improve the performance of this\n",
      " |          method\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> indexed_df = df.set_index(['A', 'B'])\n",
      " |      >>> indexed_df2 = df.set_index(['A', [0, 1, 2, 0, 1, 2]])\n",
      " |      >>> indexed_df3 = df.set_index([[0, 1, 2, 0, 1, 2]])\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dataframe : DataFrame\n",
      " |  \n",
      " |  set_value(self, index, col, value, takeable=False)\n",
      " |      Put single value at passed column and index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : row label\n",
      " |      col : column label\n",
      " |      value : scalar value\n",
      " |      takeable : interpret the index/col as indexers, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      frame : DataFrame\n",
      " |          If label pair is contained, will be reference to calling DataFrame,\n",
      " |          otherwise a new object\n",
      " |  \n",
      " |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return unbiased skew over requested axis\n",
      " |      Normalized by N-1\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      skew : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sort(self, columns=None, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort DataFrame either by labels (along either axis) or by the values in\n",
      " |      column(s)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns : object\n",
      " |          Column name(s) in frame. Accepts a column name or a list\n",
      " |          for a nested sort. A tuple will be interpreted as the\n",
      " |          levels of a multi-index.\n",
      " |      ascending : boolean or list, default True\n",
      " |          Sort ascending vs. descending. Specify list for multiple sort\n",
      " |          orders\n",
      " |      axis : {0, 1}\n",
      " |          Sort index/rows versus columns\n",
      " |      inplace : boolean, default False\n",
      " |          Sort the DataFrame without creating a new instance\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, optional\n",
      " |          This option is only applied when sorting on a single column or label.\n",
      " |      na_position : {'first', 'last'} (optional, default='last')\n",
      " |          'first' puts NaNs at the beginning\n",
      " |          'last' puts NaNs at the end\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> result = df.sort(['A', 'B'], ascending=[1, 0])\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : DataFrame\n",
      " |  \n",
      " |  sort_index(self, axis=0, by=None, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
      " |      Sort DataFrame either by labels (along either axis) or by the values in\n",
      " |      a column\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {0, 1}\n",
      " |          Sort index/rows versus columns\n",
      " |      by : object\n",
      " |          Column name(s) in frame. Accepts a column name or a list\n",
      " |          for a nested sort. A tuple will be interpreted as the\n",
      " |          levels of a multi-index.\n",
      " |      ascending : boolean or list, default True\n",
      " |          Sort ascending vs. descending. Specify list for multiple sort\n",
      " |          orders\n",
      " |      inplace : boolean, default False\n",
      " |          Sort the DataFrame without creating a new instance\n",
      " |      na_position : {'first', 'last'} (optional, default='last')\n",
      " |          'first' puts NaNs at the beginning\n",
      " |          'last' puts NaNs at the end\n",
      " |      kind : {'quicksort', 'mergesort', 'heapsort'}, optional\n",
      " |          This option is only applied when sorting on a single column or label.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> result = df.sort_index(by=['A', 'B'], ascending=[True, False])\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : DataFrame\n",
      " |  \n",
      " |  sortlevel(self, level=0, axis=0, ascending=True, inplace=False, sort_remaining=True)\n",
      " |      Sort multilevel index by chosen axis and primary level. Data will be\n",
      " |      lexicographically sorted by the chosen level followed by the other\n",
      " |      levels (in order)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int\n",
      " |      axis : {0, 1}\n",
      " |      ascending : boolean, default True\n",
      " |      inplace : boolean, default False\n",
      " |          Sort the DataFrame without creating a new instance\n",
      " |      sort_remaining : boolean, default True\n",
      " |          Sort by the other levels too.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sorted : DataFrame\n",
      " |  \n",
      " |  stack(self, level=-1, dropna=True)\n",
      " |      Pivot a level of the (possibly hierarchical) column labels, returning a\n",
      " |      DataFrame (or Series in the case of an object with a single level of\n",
      " |      column labels) having a hierarchical index with a new inner-most level\n",
      " |      of row labels.\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default last level\n",
      " |          Level(s) to stack, can pass level name\n",
      " |      dropna : boolean, default True\n",
      " |          Whether to drop rows in the resulting Frame/Series with no valid\n",
      " |          values\n",
      " |      \n",
      " |      Examples\n",
      " |      ----------\n",
      " |      >>> s\n",
      " |           a   b\n",
      " |      one  1.  2.\n",
      " |      two  3.  4.\n",
      " |      \n",
      " |      >>> s.stack()\n",
      " |      one a    1\n",
      " |          b    2\n",
      " |      two a    3\n",
      " |          b    4\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      stacked : DataFrame or Series\n",
      " |  \n",
      " |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased standard deviation over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      std : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator sub with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  subtract = sub(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator sub with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)\n",
      " |      Return the sum of the values for the requested axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sum : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  swaplevel(self, i, j, axis=0)\n",
      " |      Swap levels i and j in a MultiIndex on a particular axis\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      i, j : int, string (can be mixed)\n",
      " |          Level of index to be swapped. Can pass level name as string.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      swapped : type of caller (new object)\n",
      " |  \n",
      " |  to_csv(self, path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=False, date_format=None, doublequote=True, escapechar=None, decimal='.', **kwds)\n",
      " |      Write DataFrame to a comma-separated values (csv) file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : string or file handle, default None\n",
      " |          File path or object, if None is provided the result is returned as\n",
      " |          a string.\n",
      " |      sep : character, default \",\"\n",
      " |          Field delimiter for the output file.\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out column names. If a list of string is given it is assumed\n",
      " |          to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, or False, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.  If\n",
      " |          False do not print fields for index names. Use index_label=False\n",
      " |          for easier importing in R\n",
      " |      nanRep : None\n",
      " |          deprecated, use na_rep\n",
      " |      mode : str\n",
      " |          Python write mode, default 'w'\n",
      " |      encoding : string, optional\n",
      " |          A string representing the encoding to use in the output file,\n",
      " |          defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      " |      line_terminator : string, default '\\\\n'\n",
      " |          The newline character or character sequence to use in the output\n",
      " |          file\n",
      " |      quoting : optional constant from csv module\n",
      " |          defaults to csv.QUOTE_MINIMAL\n",
      " |      quotechar : string (length 1), default '\"'\n",
      " |          character used to quote fields\n",
      " |      doublequote : boolean, default True\n",
      " |          Control quoting of `quotechar` inside a field\n",
      " |      escapechar : string (length 1), default None\n",
      " |          character used to escape `sep` and `quotechar` when appropriate\n",
      " |      chunksize : int or None\n",
      " |          rows to write at a time\n",
      " |      tupleize_cols : boolean, default False\n",
      " |          write multi_index columns as a list of tuples (if True)\n",
      " |          or new (expanded format) if False)\n",
      " |      date_format : string, default None\n",
      " |          Format string for datetime objects\n",
      " |      decimal: string, default '.'\n",
      " |          Character recognized as decimal separator. E.g. use ',' for European data\n",
      " |  \n",
      " |  to_dict(*args, **kwargs)\n",
      " |      Convert DataFrame to dictionary.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      orient : str {'dict', 'list', 'series', 'split', 'records'}\n",
      " |          Determines the type of the values of the dictionary.\n",
      " |      \n",
      " |          - dict (default) : dict like {column -> {index -> value}}\n",
      " |          - list : dict like {column -> [values]}\n",
      " |          - series : dict like {column -> Series(values)}\n",
      " |          - split : dict like\n",
      " |            {index -> [index], columns -> [columns], data -> [values]}\n",
      " |          - records : list like\n",
      " |            [{column -> value}, ... , {column -> value}]\n",
      " |      \n",
      " |          Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      " |          indicates `split`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : dict like {column -> {index -> value}}\n",
      " |  \n",
      " |  to_excel(self, excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf')\n",
      " |      Write DataFrame to a excel sheet\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel_writer : string or ExcelWriter object\n",
      " |          File path or existing ExcelWriter\n",
      " |      sheet_name : string, default 'Sheet1'\n",
      " |          Name of sheet which will contain DataFrame\n",
      " |      na_rep : string, default ''\n",
      " |          Missing data representation\n",
      " |      float_format : string, default None\n",
      " |          Format string for floating point numbers\n",
      " |      columns : sequence, optional\n",
      " |          Columns to write\n",
      " |      header : boolean or list of string, default True\n",
      " |          Write out column names. If a list of string is given it is\n",
      " |          assumed to be aliases for the column names\n",
      " |      index : boolean, default True\n",
      " |          Write row names (index)\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s) if desired. If None is given, and\n",
      " |          `header` and `index` are True, then the index names are used. A\n",
      " |          sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      startrow :\n",
      " |          upper left cell row to dump data frame\n",
      " |      startcol :\n",
      " |          upper left cell column to dump data frame\n",
      " |      engine : string, default None\n",
      " |          write engine to use - you can also set this via the options\n",
      " |          ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and\n",
      " |          ``io.excel.xlsm.writer``.\n",
      " |      merge_cells : boolean, default True\n",
      " |          Write MultiIndex and Hierarchical Rows as merged cells.\n",
      " |      encoding: string, default None\n",
      " |          encoding of the resulting excel file. Only necessary for xlwt,\n",
      " |          other writers support unicode natively.\n",
      " |      inf_rep : string, default 'inf'\n",
      " |          Representation for infinity (there is no native representation for\n",
      " |          infinity in Excel)\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If passing an existing ExcelWriter object, then the sheet will be added\n",
      " |      to the existing workbook.  This can be used to save different\n",
      " |      DataFrames to one workbook:\n",
      " |      \n",
      " |      >>> writer = ExcelWriter('output.xlsx')\n",
      " |      >>> df1.to_excel(writer,'Sheet1')\n",
      " |      >>> df2.to_excel(writer,'Sheet2')\n",
      " |      >>> writer.save()\n",
      " |  \n",
      " |  to_gbq(self, destination_table, project_id=None, chunksize=10000, verbose=True, reauth=False)\n",
      " |      Write a DataFrame to a Google BigQuery table.\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY\n",
      " |      \n",
      " |      If the table exists, the dataframe will be written to the table using\n",
      " |      the defined table schema and column types. For simplicity, this method\n",
      " |      uses the Google BigQuery streaming API. The to_gbq method chunks data\n",
      " |      into a default chunk size of 10,000. Failures return the complete error\n",
      " |      response which can be quite long depending on the size of the insert.\n",
      " |      There are several important limitations of the Google streaming API\n",
      " |      which are detailed at:\n",
      " |      https://developers.google.com/bigquery/streaming-data-into-bigquery.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dataframe : DataFrame\n",
      " |          DataFrame to be written\n",
      " |      destination_table : string\n",
      " |          Name of table to be written, in the form 'dataset.tablename'\n",
      " |      project_id : str\n",
      " |          Google BigQuery Account project ID.\n",
      " |      chunksize : int (default 10000)\n",
      " |          Number of rows to be inserted in each chunk from the dataframe.\n",
      " |      verbose : boolean (default True)\n",
      " |          Show percentage complete\n",
      " |      reauth : boolean (default False)\n",
      " |          Force Google BigQuery to reauthenticate the user. This is useful\n",
      " |          if multiple accounts are used.\n",
      " |  \n",
      " |  to_html(self, buf=None, columns=None, col_space=None, colSpace=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, bold_rows=True, classes=None, escape=True, max_rows=None, max_cols=None, show_dimensions=False)\n",
      " |      Render a DataFrame as an HTML table.\n",
      " |      \n",
      " |      `to_html`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default True\n",
      " |          Make the row labels bold in the output\n",
      " |      classes : str or list or tuple, default None\n",
      " |          CSS class(es) to apply to the resulting html table\n",
      " |      escape : boolean, default True\n",
      " |          Convert the characters <, >, and & to HTML-safe sequences.=\n",
      " |      max_rows : int, optional\n",
      " |          Maximum number of rows to show before truncating. If None, show\n",
      " |          all.\n",
      " |      max_cols : int, optional\n",
      " |          Maximum number of columns to show before truncating. If None, show\n",
      " |          all.\n",
      " |      \n",
      " |      \n",
      " |       Parameters\n",
      " |       ----------\n",
      " |       frame : DataFrame\n",
      " |           object to render\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      columns : sequence, optional\n",
      " |          the subset of columns to write; default None writes all columns\n",
      " |      col_space : int, optional\n",
      " |          the minimum width of each column\n",
      " |      header : bool, optional\n",
      " |          whether to print column labels, default True\n",
      " |      index : bool, optional\n",
      " |          whether to print index (row) labels, default True\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      formatters : list or dict of one-parameter functions, optional\n",
      " |          formatter functions to apply to columns' elements by position or name,\n",
      " |          default None. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats,\n",
      " |          default None. The result of this function must be a unicode string.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print every\n",
      " |          multiindex key at each row, default True\n",
      " |      justify : {'left', 'right'}, default None\n",
      " |          Left or right-justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box.\n",
      " |      index_names : bool, optional\n",
      " |          Prints the names of the indexes, default True\n",
      " |      force_unicode : bool, default False\n",
      " |          Always return a unicode result. Deprecated in v0.10.0 as string\n",
      " |          formatting is now rendered to unicode by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (or unicode, depending on data and options)\n",
      " |  \n",
      " |  to_latex(self, buf=None, columns=None, col_space=None, colSpace=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=True, longtable=False, escape=True)\n",
      " |      Render a DataFrame to a tabular environment table. You can splice\n",
      " |      this into a LaTeX document. Requires \\usepackage{booktabs}.\n",
      " |      \n",
      " |      `to_latex`-specific options:\n",
      " |      \n",
      " |      bold_rows : boolean, default True\n",
      " |          Make the row labels bold in the output\n",
      " |      longtable : boolean, default False\n",
      " |          Use a longtable environment instead of tabular. Requires adding\n",
      " |          a \\usepackage{longtable} to your LaTeX preamble.\n",
      " |      escape : boolean, default True\n",
      " |          When set to False prevents from escaping latex special\n",
      " |          characters in column names.\n",
      " |      \n",
      " |      \n",
      " |       Parameters\n",
      " |       ----------\n",
      " |       frame : DataFrame\n",
      " |           object to render\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      columns : sequence, optional\n",
      " |          the subset of columns to write; default None writes all columns\n",
      " |      col_space : int, optional\n",
      " |          the minimum width of each column\n",
      " |      header : bool, optional\n",
      " |          whether to print column labels, default True\n",
      " |      index : bool, optional\n",
      " |          whether to print index (row) labels, default True\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      formatters : list or dict of one-parameter functions, optional\n",
      " |          formatter functions to apply to columns' elements by position or name,\n",
      " |          default None. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats,\n",
      " |          default None. The result of this function must be a unicode string.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print every\n",
      " |          multiindex key at each row, default True\n",
      " |      justify : {'left', 'right'}, default None\n",
      " |          Left or right-justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box.\n",
      " |      index_names : bool, optional\n",
      " |          Prints the names of the indexes, default True\n",
      " |      force_unicode : bool, default False\n",
      " |          Always return a unicode result. Deprecated in v0.10.0 as string\n",
      " |          formatting is now rendered to unicode by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (or unicode, depending on data and options)\n",
      " |  \n",
      " |  to_panel(self)\n",
      " |      Transform long (stacked) format (DataFrame) into wide (3D, Panel)\n",
      " |      format.\n",
      " |      \n",
      " |      Currently the index of the DataFrame must be a 2-level MultiIndex. This\n",
      " |      may be generalized later\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      panel : Panel\n",
      " |  \n",
      " |  to_period(self, freq=None, axis=0, copy=True)\n",
      " |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired\n",
      " |      frequency (inferred from index if not passed)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default\n",
      " |      axis : {0, 1}, default 0\n",
      " |          The axis to convert (the index by default)\n",
      " |      copy : boolean, default True\n",
      " |          If False then underlying input data is not copied\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ts : TimeSeries with PeriodIndex\n",
      " |  \n",
      " |  to_records(self, index=True, convert_datetime64=True)\n",
      " |      Convert DataFrame to record array. Index will be put in the\n",
      " |      'index' field of the record array if requested\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      index : boolean, default True\n",
      " |          Include index in resulting record array, stored in 'index' field\n",
      " |      convert_datetime64 : boolean, default True\n",
      " |          Whether to convert the index to datetime.datetime if it is a\n",
      " |          DatetimeIndex\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : recarray\n",
      " |  \n",
      " |  to_sparse(self, fill_value=None, kind='block')\n",
      " |      Convert to SparseDataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fill_value : float, default NaN\n",
      " |      kind : {'block', 'integer'}\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : SparseDataFrame\n",
      " |  \n",
      " |  to_stata(self, fname, convert_dates=None, write_index=True, encoding='latin-1', byteorder=None, time_stamp=None, data_label=None)\n",
      " |      A class for writing Stata binary dta files from array-like objects\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : file path or buffer\n",
      " |          Where to save the dta file.\n",
      " |      convert_dates : dict\n",
      " |          Dictionary mapping column of datetime types to the stata internal\n",
      " |          format that you want to use for the dates. Options are\n",
      " |          'tc', 'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either a\n",
      " |          number or a name.\n",
      " |      encoding : str\n",
      " |          Default is latin-1. Note that Stata does not support unicode.\n",
      " |      byteorder : str\n",
      " |          Can be \">\", \"<\", \"little\", or \"big\". The default is None which uses\n",
      " |          `sys.byteorder`\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> writer = StataWriter('./data_file.dta', data)\n",
      " |      >>> writer.write_file()\n",
      " |      \n",
      " |      Or with dates\n",
      " |      \n",
      " |      >>> writer = StataWriter('./date_data_file.dta', data, {2 : 'tw'})\n",
      " |      >>> writer.write_file()\n",
      " |  \n",
      " |  to_string(self, buf=None, columns=None, col_space=None, colSpace=None, header=True, index=True, na_rep='NaN', formatters=None, float_format=None, sparsify=None, index_names=True, justify=None, line_width=None, max_rows=None, max_cols=None, show_dimensions=False)\n",
      " |      Render a DataFrame to a console-friendly tabular output.\n",
      " |      \n",
      " |       Parameters\n",
      " |       ----------\n",
      " |       frame : DataFrame\n",
      " |           object to render\n",
      " |      buf : StringIO-like, optional\n",
      " |          buffer to write to\n",
      " |      columns : sequence, optional\n",
      " |          the subset of columns to write; default None writes all columns\n",
      " |      col_space : int, optional\n",
      " |          the minimum width of each column\n",
      " |      header : bool, optional\n",
      " |          whether to print column labels, default True\n",
      " |      index : bool, optional\n",
      " |          whether to print index (row) labels, default True\n",
      " |      na_rep : string, optional\n",
      " |          string representation of NAN to use, default 'NaN'\n",
      " |      formatters : list or dict of one-parameter functions, optional\n",
      " |          formatter functions to apply to columns' elements by position or name,\n",
      " |          default None. The result of each function must be a unicode string.\n",
      " |          List must be of length equal to the number of columns.\n",
      " |      float_format : one-parameter function, optional\n",
      " |          formatter function to apply to columns' elements if they are floats,\n",
      " |          default None. The result of this function must be a unicode string.\n",
      " |      sparsify : bool, optional\n",
      " |          Set to False for a DataFrame with a hierarchical index to print every\n",
      " |          multiindex key at each row, default True\n",
      " |      justify : {'left', 'right'}, default None\n",
      " |          Left or right-justify the column labels. If None uses the option from\n",
      " |          the print configuration (controlled by set_option), 'right' out\n",
      " |          of the box.\n",
      " |      index_names : bool, optional\n",
      " |          Prints the names of the indexes, default True\n",
      " |      force_unicode : bool, default False\n",
      " |          Always return a unicode result. Deprecated in v0.10.0 as string\n",
      " |          formatting is now rendered to unicode by default.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      formatted : string (or unicode, depending on data and options)\n",
      " |  \n",
      " |  to_timestamp(self, freq=None, how='start', axis=0, copy=True)\n",
      " |      Cast to DatetimeIndex of timestamps, at *beginning* of period\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : string, default frequency of PeriodIndex\n",
      " |          Desired frequency\n",
      " |      how : {'s', 'e', 'start', 'end'}\n",
      " |          Convention for converting period to timestamp; start of period\n",
      " |          vs. end\n",
      " |      axis : {0, 1} default 0\n",
      " |          The axis to convert (the index by default)\n",
      " |      copy : boolean, default True\n",
      " |          If false then underlying input data is not copied\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      df : DataFrame with DatetimeIndex\n",
      " |  \n",
      " |  to_wide = wrapper(*args, **kwargs)\n",
      " |  \n",
      " |  transpose(self)\n",
      " |      Transpose index and columns\n",
      " |  \n",
      " |  truediv(self, other, axis='columns', level=None, fill_value=None)\n",
      " |      Binary operator truediv with support to substitute a fill_value for missing data in\n",
      " |      one of the inputs\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Series, DataFrame, or constant\n",
      " |      axis : {0, 1, 'index', 'columns'}\n",
      " |          For Series input, axis to match Series index on\n",
      " |      fill_value : None or float value, default None\n",
      " |          Fill missing (NaN) values with this value. If both DataFrame locations are\n",
      " |          missing, the result will be missing\n",
      " |      level : int or name\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Mismatched indices will be unioned together\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : DataFrame\n",
      " |  \n",
      " |  unstack(self, level=-1)\n",
      " |      Pivot a level of the (necessarily hierarchical) index labels, returning\n",
      " |      a DataFrame having a new level of column labels whose inner-most level\n",
      " |      consists of the pivoted index labels. If the index is not a MultiIndex,\n",
      " |      the output will be a Series (the analogue of stack when the columns are\n",
      " |      not a MultiIndex).\n",
      " |      The level involved will automatically get sorted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      level : int, string, or list of these, default -1 (last level)\n",
      " |          Level(s) of index to unstack, can pass level name\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.pivot : Pivot a table based on column values.\n",
      " |      DataFrame.stack : Pivot a level of the column labels (inverse operation\n",
      " |          from `unstack`).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\n",
      " |      ...                                    ('two', 'a'), ('two', 'b')])\n",
      " |      >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\n",
      " |      >>> s\n",
      " |      one  a   1\n",
      " |           b   2\n",
      " |      two  a   3\n",
      " |           b   4\n",
      " |      dtype: float64\n",
      " |      \n",
      " |      >>> s.unstack(level=-1)\n",
      " |           a   b\n",
      " |      one  1  2\n",
      " |      two  3  4\n",
      " |      \n",
      " |      >>> s.unstack(level=0)\n",
      " |         one  two\n",
      " |      a  1   3\n",
      " |      b  2   4\n",
      " |      \n",
      " |      >>> df = s.unstack(level=0)\n",
      " |      >>> df.unstack()\n",
      " |      one  a  1.\n",
      " |           b  3.\n",
      " |      two  a  2.\n",
      " |           b  4.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      unstacked : DataFrame or Series\n",
      " |  \n",
      " |  update(self, other, join='left', overwrite=True, filter_func=None, raise_conflict=False)\n",
      " |      Modify DataFrame in place using non-NA values from passed\n",
      " |      DataFrame. Aligns on indices\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame, or object coercible into a DataFrame\n",
      " |      join : {'left'}, default 'left'\n",
      " |      overwrite : boolean, default True\n",
      " |          If True then overwrite values for common keys in the calling frame\n",
      " |      filter_func : callable(1d-array) -> 1d-array<boolean>, default None\n",
      " |          Can choose to replace values other than NA. Return True for values\n",
      " |          that should be updated\n",
      " |      raise_conflict : boolean\n",
      " |          If True, will raise an error if the DataFrame and other both\n",
      " |          contain data in the same place.\n",
      " |  \n",
      " |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)\n",
      " |      Return unbiased variance over requested axis.\n",
      " |      \n",
      " |      Normalized by N-1 by default. This can be changed using the ddof argument\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      axis : {index (0), columns (1)}\n",
      " |      skipna : boolean, default True\n",
      " |          Exclude NA/null values. If an entire row/column is NA, the result\n",
      " |          will be NA\n",
      " |      level : int or level name, default None\n",
      " |              If the axis is a MultiIndex (hierarchical), count along a\n",
      " |              particular level, collapsing into a Series\n",
      " |      numeric_only : boolean, default None\n",
      " |          Include only float, int, boolean data. If None, will attempt to use\n",
      " |          everything, then use only numeric data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      var : Series or DataFrame (if level specified)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_csv(cls, path, header=0, sep=',', index_col=0, parse_dates=True, encoding=None, tupleize_cols=False, infer_datetime_format=False) from __builtin__.type\n",
      " |      Read delimited file into DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string file path or file handle / StringIO\n",
      " |      header : int, default 0\n",
      " |          Row to use at header (skip prior rows)\n",
      " |      sep : string, default ','\n",
      " |          Field delimiter\n",
      " |      index_col : int or sequence, default 0\n",
      " |          Column to use for index. If a sequence is given, a MultiIndex\n",
      " |          is used. Different default from read_table\n",
      " |      parse_dates : boolean, default True\n",
      " |          Parse dates. Different default from read_table\n",
      " |      tupleize_cols : boolean, default False\n",
      " |          write multi_index columns as a list of tuples (if True)\n",
      " |          or new (expanded format) if False)\n",
      " |      infer_datetime_format: boolean, default False\n",
      " |          If True and `parse_dates` is True for a column, try to infer the\n",
      " |          datetime format based on the first datetime string. If the format\n",
      " |          can be inferred, there often will be a large parsing speed-up.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Preferable to use read_table for most general purposes but from_csv\n",
      " |      makes for an easy roundtrip to and from file, especially with a\n",
      " |      DataFrame of time series data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : DataFrame\n",
      " |  \n",
      " |  from_dict(cls, data, orient='columns', dtype=None) from __builtin__.type\n",
      " |      Construct DataFrame from dict of array-like or dicts\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : dict\n",
      " |          {field : array-like} or {field : dict}\n",
      " |      orient : {'columns', 'index'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the passed dict\n",
      " |          should be the columns of the resulting DataFrame, pass 'columns'\n",
      " |          (default). Otherwise if the keys should be rows, pass 'index'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      DataFrame\n",
      " |  \n",
      " |  from_items(cls, items, columns=None, orient='columns') from __builtin__.type\n",
      " |      Convert (key, value) pairs to DataFrame. The keys will be the axis\n",
      " |      index (usually the columns, but depends on the specified\n",
      " |      orientation). The values should be arrays or Series.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : sequence of (key, value) pairs\n",
      " |          Values should be arrays or Series.\n",
      " |      columns : sequence of column labels, optional\n",
      " |          Must be passed if orient='index'.\n",
      " |      orient : {'columns', 'index'}, default 'columns'\n",
      " |          The \"orientation\" of the data. If the keys of the\n",
      " |          input correspond to column labels, pass 'columns'\n",
      " |          (default). Otherwise if the keys correspond to the index,\n",
      " |          pass 'index'.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      frame : DataFrame\n",
      " |  \n",
      " |  from_records(cls, data, index=None, exclude=None, columns=None, coerce_float=False, nrows=None) from __builtin__.type\n",
      " |      Convert structured or record ndarray to DataFrame\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : ndarray (structured dtype), list of tuples, dict, or DataFrame\n",
      " |      index : string, list of fields, array-like\n",
      " |          Field of array to use as the index, alternately a specific set of\n",
      " |          input labels to use\n",
      " |      exclude : sequence, default None\n",
      " |          Columns or fields to exclude\n",
      " |      columns : sequence, default None\n",
      " |          Column names to use. If the passed data do not have names\n",
      " |          associated with them, this argument provides names for the\n",
      " |          columns. Otherwise this argument indicates the order of the columns\n",
      " |          in the result (any names not found in the data will become all-NA\n",
      " |          columns)\n",
      " |      coerce_float : boolean, default False\n",
      " |          Attempt to convert values to non-string, non-numeric objects (like\n",
      " |          decimal.Decimal) to floating point, useful for SQL result sets\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      df : DataFrame\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  T\n",
      " |      Transpose index and columns\n",
      " |  \n",
      " |  axes\n",
      " |  \n",
      " |  columns\n",
      " |  \n",
      " |  index\n",
      " |  \n",
      " |  shape\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  __abs__(self)\n",
      " |  \n",
      " |  __array__(self, dtype=None)\n",
      " |  \n",
      " |  __array_wrap__(self, result, context=None)\n",
      " |  \n",
      " |  __bool__ = __nonzero__(self)\n",
      " |  \n",
      " |  __contains__(self, key)\n",
      " |      True if the key is in the info axis\n",
      " |  \n",
      " |  __delitem__(self, key)\n",
      " |      Delete item\n",
      " |  \n",
      " |  __finalize__(self, other, method=None, **kwargs)\n",
      " |      propagate metadata from other to self\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : the object from which to get the attributes that we are going\n",
      " |          to propagate\n",
      " |      method : optional, a passed method name ; possibly to take different\n",
      " |          types of propagation actions based on this\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |      After regular attribute access, try looking up the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |  \n",
      " |  __invert__(self)\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate over infor axis\n",
      " |  \n",
      " |  __neg__(self)\n",
      " |  \n",
      " |  __nonzero__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      After regular attribute access, try setting the name\n",
      " |      This allows simpler access to columns for interactive use.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  abs(self)\n",
      " |      Return an object with absolute value taken. Only applicable to objects\n",
      " |      that are all numeric\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      abs: type of caller\n",
      " |  \n",
      " |  add_prefix(self, prefix)\n",
      " |      Concatenate prefix string with panel items names.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prefix : string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      with_prefix : type of caller\n",
      " |  \n",
      " |  add_suffix(self, suffix)\n",
      " |      Concatenate suffix string with panel items names\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      suffix : string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      with_suffix : type of caller\n",
      " |  \n",
      " |  align(self, other, join='outer', axis=None, level=None, copy=True, fill_value=None, method=None, limit=None, fill_axis=0)\n",
      " |      Align two object on their axes with the\n",
      " |      specified join method for each axis Index\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : DataFrame or Series\n",
      " |      join : {'outer', 'inner', 'left', 'right'}, default 'outer'\n",
      " |      axis : allowed axis of the other object, default None\n",
      " |          Align on index (0), columns (1), or both (None)\n",
      " |      level : int or level name, default None\n",
      " |          Broadcast across a level, matching Index values on the\n",
      " |          passed MultiIndex level\n",
      " |      copy : boolean, default True\n",
      " |          Always returns new objects. If copy=False and no reindexing is\n",
      " |          required then original objects are returned.\n",
      " |      fill_value : scalar, default np.NaN\n",
      " |          Value to use for missing values. Defaults to NaN, but can be any\n",
      " |          \"compatible\" value\n",
      " |      method : str, default None\n",
      " |      limit : int, default None\n",
      " |      fill_axis : {0, 1}, default 0\n",
      " |          Filling axis, method and limit\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (left, right) : (type of input, type of other)\n",
      " |          Aligned objects\n",
      " |  \n",
      " |  as_blocks(self)\n",
      " |      Convert the frame to a dict of dtype -> Constructor Types that each has\n",
      " |      a homogeneous dtype.\n",
      " |      \n",
      " |      NOTE: the dtypes of the blocks WILL BE PRESERVED HERE (unlike in\n",
      " |            as_matrix)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : a dict of dtype -> Constructor Types\n",
      " |  \n",
      " |  as_matrix(self, columns=None)\n",
      " |      Convert the frame to its Numpy-array representation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      columns: list, optional, default:None\n",
      " |          If None, return all columns, otherwise, returns specified columns.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values : ndarray\n",
      " |          If the caller is heterogeneous and contains booleans or objects,\n",
      " |          the result will be of dtype=object. See Notes.\n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Return is NOT a Numpy-matrix, rather, a Numpy-array.\n",
      " |      \n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32.\n",
      " |      \n",
      " |      This method is provided for backwards compatibility. Generally,\n",
      " |      it is recommended to use '.values'.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      pandas.DataFrame.values\n",
      " |  \n",
      " |  asfreq(self, freq, method=None, how=None, normalize=False)\n",
      " |      Convert all TimeSeries inside to specified frequency using DateOffset\n",
      " |      objects. Optionally provide fill method to pad/backfill missing values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      freq : DateOffset object, or string\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill method\n",
      " |      how : {'start', 'end'}, default end\n",
      " |          For PeriodIndex only, see PeriodIndex.asfreq\n",
      " |      normalize : bool, default False\n",
      " |          Whether to reset output index to midnight\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : type of caller\n",
      " |  \n",
      " |  astype(self, dtype, copy=True, raise_on_error=True, **kwargs)\n",
      " |      Cast object to input numpy.dtype\n",
      " |      Return a copy when copy = True (be really careful with this!)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      dtype : numpy.dtype or Python type\n",
      " |      raise_on_error : raise on invalid input\n",
      " |      kwargs : keyword arguments to pass on to the constructor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      casted : type of caller\n",
      " |  \n",
      " |  at_time(self, time, asof=False)\n",
      " |      Select values at particular time of day (e.g. 9:30AM)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime.time or string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_at_time : type of caller\n",
      " |  \n",
      " |  between_time(self, start_time, end_time, include_start=True, include_end=True)\n",
      " |      Select values between particular times of the day (e.g., 9:00-9:30 AM)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_time : datetime.time or string\n",
      " |      end_time : datetime.time or string\n",
      " |      include_start : boolean, default True\n",
      " |      include_end : boolean, default True\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      values_between_time : type of caller\n",
      " |  \n",
      " |  bfill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for NDFrame.fillna(method='bfill')\n",
      " |  \n",
      " |  bool(self)\n",
      " |      Return the bool of a single element PandasObject\n",
      " |      This must be a boolean scalar value, either True or False\n",
      " |      \n",
      " |      Raise a ValueError if the PandasObject does not have exactly\n",
      " |      1 element, or that element is not boolean\n",
      " |  \n",
      " |  clip(self, lower=None, upper=None, out=None)\n",
      " |      Trim values at input threshold(s)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lower : float, default None\n",
      " |      upper : float, default None\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : Series\n",
      " |  \n",
      " |  clip_lower(self, threshold)\n",
      " |      Return copy of the input with values below given value truncated\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  clip_upper(self, threshold)\n",
      " |      Return copy of input with values above given value truncated\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      clip\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      clipped : same type as input\n",
      " |  \n",
      " |  consolidate(self, inplace=False)\n",
      " |      Compute NDFrame with \"consolidated\" internals (data of each dtype\n",
      " |      grouped together in a single ndarray). Mainly an internal API function,\n",
      " |      but available here to the savvy user\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      inplace : boolean, default False\n",
      " |          If False return new object, otherwise modify existing object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      consolidated : type of caller\n",
      " |  \n",
      " |  convert_objects(self, convert_dates=True, convert_numeric=False, convert_timedeltas=True, copy=True)\n",
      " |      Attempt to infer better dtype for object columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      convert_dates : if True, attempt to soft convert dates, if 'coerce',\n",
      " |          force conversion (and non-convertibles get NaT)\n",
      " |      convert_numeric : if True attempt to coerce to numbers (including\n",
      " |          strings), non-convertibles get NaN\n",
      " |      convert_timedeltas : if True, attempt to soft convert timedeltas, if 'coerce',\n",
      " |          force conversion (and non-convertibles get NaT)\n",
      " |      copy : Boolean, if True, return copy even if no copy is necessary\n",
      " |          (e.g. no conversion was done), default is True.\n",
      " |          It is meant for internal use, not to be confused with `inplace` kw.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      converted : asm as input object\n",
      " |  \n",
      " |  copy(self, deep=True)\n",
      " |      Make a copy of this object\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean or string, default True\n",
      " |          Make a deep copy, i.e. also copy data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      copy : type of caller\n",
      " |  \n",
      " |  describe(self, percentile_width=None, percentiles=None, include=None, exclude=None)\n",
      " |      Generate various summary statistics, excluding NaN values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      percentile_width : float, deprecated\n",
      " |          The ``percentile_width`` argument will be removed in a future\n",
      " |          version. Use ``percentiles`` instead.\n",
      " |          width of the desired uncertainty interval, default is 50,\n",
      " |          which corresponds to lower=25, upper=75\n",
      " |      percentiles : array-like, optional\n",
      " |          The percentiles to include in the output. Should all\n",
      " |          be in the interval [0, 1]. By default `percentiles` is\n",
      " |          [.25, .5, .75], returning the 25th, 50th, and 75th percentiles.\n",
      " |      include, exclude : list-like, 'all', or None (default)\n",
      " |          Specify the form of the returned result. Either:\n",
      " |      \n",
      " |          - None to both (default). The result will include only numeric-typed\n",
      " |            columns or, if none are, only categorical columns.\n",
      " |          - A list of dtypes or strings to be included/excluded.\n",
      " |            To select all numeric types use numpy numpy.number. To select\n",
      " |            categorical objects use type object. See also the select_dtypes\n",
      " |            documentation. eg. df.describe(include=['O'])\n",
      " |          - If include is the string 'all', the output column-set will\n",
      " |            match the input one.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      summary: NDFrame of summary statistics\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The output DataFrame index depends on the requested dtypes:\n",
      " |      \n",
      " |      For numeric dtypes, it will include: count, mean, std, min,\n",
      " |      max, and lower, 50, and upper percentiles.\n",
      " |      \n",
      " |      For object dtypes (e.g. timestamps or strings), the index\n",
      " |      will include the count, unique, most common, and frequency of the\n",
      " |      most common. Timestamps also include the first and last items.\n",
      " |      \n",
      " |      For mixed dtypes, the index will be the union of the corresponding\n",
      " |      output types. Non-applicable entries will be filled with NaN.\n",
      " |      Note that mixed-dtype outputs can only be returned from mixed-dtype\n",
      " |      inputs and appropriate use of the include/exclude arguments.\n",
      " |      \n",
      " |      If multiple values have the highest count, then the\n",
      " |      `count` and `most common` pair will be arbitrarily chosen from\n",
      " |      among those with the highest count.\n",
      " |      \n",
      " |      The include, exclude arguments are ignored for Series.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      DataFrame.select_dtypes\n",
      " |  \n",
      " |  drop(self, labels, axis=0, level=None, inplace=False)\n",
      " |      Return new object with labels in requested axis removed\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      labels : single label or list-like\n",
      " |      axis : int or axis name\n",
      " |      level : int or level name, default None\n",
      " |          For MultiIndex\n",
      " |      inplace : bool, default False\n",
      " |          If True, do operation inplace and return None.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dropped : type of caller\n",
      " |  \n",
      " |  equals(self, other)\n",
      " |      Determines if two NDFrame objects contain the same elements. NaNs in the\n",
      " |      same location are considered equal.\n",
      " |  \n",
      " |  ffill(self, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Synonym for NDFrame.fillna(method='ffill')\n",
      " |  \n",
      " |  fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None)\n",
      " |      Fill NA/NaN values using the specified method\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None\n",
      " |          Method to use for filling holes in reindexed Series\n",
      " |          pad / ffill: propagate last valid observation forward to next valid\n",
      " |          backfill / bfill: use NEXT valid observation to fill gap\n",
      " |      value : scalar, dict, Series, or DataFrame\n",
      " |          Value to use to fill holes (e.g. 0), alternately a dict/Series/DataFrame of\n",
      " |          values specifying which value to use for each index (for a Series) or\n",
      " |          column (for a DataFrame). (values not in the dict/Series/DataFrame will not be\n",
      " |          filled). This value cannot be a list.\n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      inplace : boolean, default False\n",
      " |          If True, fill in place. Note: this will modify any\n",
      " |          other views on this object, (e.g. a no-copy slice for a column in a\n",
      " |          DataFrame).\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill\n",
      " |      downcast : dict, default is None\n",
      " |          a dict of item->dtype of what to downcast if possible,\n",
      " |          or the string 'infer' which will try to downcast to an appropriate\n",
      " |          equal type (e.g. float64 to int64 if possible)\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      reindex, asfreq\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : same type as caller\n",
      " |  \n",
      " |  filter(self, items=None, like=None, regex=None, axis=None)\n",
      " |      Restrict the info axis to set of items or wildcard\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      items : list-like\n",
      " |          List of info axis to restrict to (must not all be present)\n",
      " |      like : string\n",
      " |          Keep info axis where \"arg in col == True\"\n",
      " |      regex : string (regular expression)\n",
      " |          Keep info axis with re.search(regex, col) == True\n",
      " |      axis : int or None\n",
      " |          The axis to filter on. By default this is the info axis. The \"info\n",
      " |          axis\" is the axis that is used when indexing with ``[]``. For\n",
      " |          example, ``df = DataFrame({'a': [1, 2, 3, 4]]}); df['a']``. So,\n",
      " |          the ``DataFrame`` columns are the info axis.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Arguments are mutually exclusive, but this is not checked for\n",
      " |  \n",
      " |  first(self, offset)\n",
      " |      Convenience method for subsetting initial periods of time series data\n",
      " |      based on a date offset\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ts.last('10D') -> First 10 days\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |  \n",
      " |  get(self, key, default=None)\n",
      " |      Get item from object for given key (DataFrame column, Panel slice,\n",
      " |      etc.). Returns default value if not found\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value : type of items contained in object\n",
      " |  \n",
      " |  get_dtype_counts(self)\n",
      " |      Return the counts of dtypes in this object\n",
      " |  \n",
      " |  get_ftype_counts(self)\n",
      " |      Return the counts of ftypes in this object\n",
      " |  \n",
      " |  get_values(self)\n",
      " |      same as values (but handles sparseness conversions)\n",
      " |  \n",
      " |  groupby(self, by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False)\n",
      " |      Group series using mapper (dict or key function, apply given function\n",
      " |      to group, return result as series) or by a series of columns\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      by : mapping function / list of functions, dict, Series, or tuple /\n",
      " |          list of column names.\n",
      " |          Called on each element of the object index to determine the groups.\n",
      " |          If a dict or Series is passed, the Series or dict VALUES will be\n",
      " |          used to determine the groups\n",
      " |      axis : int, default 0\n",
      " |      level : int, level name, or sequence of such, default None\n",
      " |          If the axis is a MultiIndex (hierarchical), group by a particular\n",
      " |          level or levels\n",
      " |      as_index : boolean, default True\n",
      " |          For aggregated output, return object with group labels as the\n",
      " |          index. Only relevant for DataFrame input. as_index=False is\n",
      " |          effectively \"SQL-style\" grouped output\n",
      " |      sort : boolean, default True\n",
      " |          Sort group keys. Get better performance by turning this off\n",
      " |      group_keys : boolean, default True\n",
      " |          When calling apply, add group keys to index to identify pieces\n",
      " |      squeeze : boolean, default False\n",
      " |          reduce the dimensionaility of the return type if possible,\n",
      " |          otherwise return a consistent type\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      # DataFrame result\n",
      " |      >>> data.groupby(func, axis=0).mean()\n",
      " |      \n",
      " |      # DataFrame result\n",
      " |      >>> data.groupby(['col1', 'col2'])['col3'].mean()\n",
      " |      \n",
      " |      # DataFrame with hierarchical index\n",
      " |      >>> data.groupby(['col1', 'col2']).mean()\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      GroupBy object\n",
      " |  \n",
      " |  head(self, n=5)\n",
      " |      Returns first n rows\n",
      " |  \n",
      " |  interpolate(self, method='linear', axis=0, limit=None, inplace=False, downcast=None, **kwargs)\n",
      " |      Interpolate values according to different methods.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : {'linear', 'time', 'index', 'values', 'nearest', 'zero',\n",
      " |                'slinear', 'quadratic', 'cubic', 'barycentric', 'krogh',\n",
      " |                'polynomial', 'spline' 'piecewise_polynomial', 'pchip'}\n",
      " |      \n",
      " |          * 'linear': ignore the index and treat the values as equally\n",
      " |            spaced. default\n",
      " |          * 'time': interpolation works on daily and higher resolution\n",
      " |            data to interpolate given length of interval\n",
      " |          * 'index', 'values': use the actual numerical values of the index\n",
      " |          * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic',\n",
      " |            'barycentric', 'polynomial' is passed to\n",
      " |            `scipy.interpolate.interp1d` with the order given both\n",
      " |            'polynomial' and 'spline' requre that you also specify and order\n",
      " |            (int) e.g. df.interpolate(method='polynomial', order=4)\n",
      " |          * 'krogh', 'piecewise_polynomial', 'spline', and 'pchip' are all\n",
      " |            wrappers around the scipy interpolation methods of similar\n",
      " |            names. See the scipy documentation for more on their behavior:\n",
      " |            http://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation\n",
      " |            http://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html\n",
      " |      \n",
      " |      axis : {0, 1}, default 0\n",
      " |          * 0: fill column-by-column\n",
      " |          * 1: fill row-by-row\n",
      " |      limit : int, default None.\n",
      " |          Maximum number of consecutive NaNs to fill.\n",
      " |      inplace : bool, default False\n",
      " |          Update the NDFrame in place if possible.\n",
      " |      downcast : optional, 'infer' or None, defaults to None\n",
      " |          Downcast dtypes if possible.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Series or DataFrame of same shape interpolated at the NaNs\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      reindex, replace, fillna\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      \n",
      " |      # Filling in NaNs:\n",
      " |      >>> s = pd.Series([0, 1, np.nan, 3])\n",
      " |      >>> s.interpolate()\n",
      " |      0    0\n",
      " |      1    1\n",
      " |      2    2\n",
      " |      3    3\n",
      " |      dtype: float64\n",
      " |  \n",
      " |  isnull(self)\n",
      " |      Return a boolean same-sized object indicating if the values are null\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      notnull : boolean inverse of isnull\n",
      " |  \n",
      " |  iterkv(self, *args, **kwargs)\n",
      " |      iteritems alias used to get around 2to3. Deprecated\n",
      " |  \n",
      " |  keys(self)\n",
      " |      Get the 'info axis' (see Indexing for more)\n",
      " |      \n",
      " |      This is index for Series, columns for DataFrame and major_axis for\n",
      " |      Panel.\n",
      " |  \n",
      " |  last(self, offset)\n",
      " |      Convenience method for subsetting final periods of time series data\n",
      " |      based on a date offset\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      offset : string, DateOffset, dateutil.relativedelta\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      ts.last('5M') -> Last 5 months\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      subset : type of caller\n",
      " |  \n",
      " |  load(self, path)\n",
      " |      Deprecated. Use read_pickle instead.\n",
      " |  \n",
      " |  mask(self, cond)\n",
      " |      Returns copy whose values are replaced with nan if the\n",
      " |      inverted condition is True\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame or array\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh: same as input\n",
      " |  \n",
      " |  notnull(self)\n",
      " |      Return a boolean same-sized object indicating if the values are\n",
      " |      not null\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      isnull : boolean inverse of notnull\n",
      " |  \n",
      " |  pct_change(self, periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
      " |      Percent change over given number of periods.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int, default 1\n",
      " |          Periods to shift for forming percent change\n",
      " |      fill_method : str, default 'pad'\n",
      " |          How to handle NAs before computing percent changes\n",
      " |      limit : int, default None\n",
      " |          The number of consecutive NAs to fill before stopping\n",
      " |      freq : DateOffset, timedelta, or offset alias string, optional\n",
      " |          Increment to use from time series API (e.g. 'M' or BDay())\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      chg : NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      \n",
      " |      By default, the percentage change is calculated along the stat\n",
      " |      axis: 0, or ``Index``, for ``DataFrame`` and 1, or ``minor`` for\n",
      " |      ``Panel``. You can change this with the ``axis`` keyword argument.\n",
      " |  \n",
      " |  pop(self, item)\n",
      " |      Return item and drop from frame. Raise KeyError if not found.\n",
      " |  \n",
      " |  reindex_like(self, other, method=None, copy=True, limit=None)\n",
      " |      return an object with matching indicies to myself\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : Object\n",
      " |      method : string or None\n",
      " |      copy : boolean, default True\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Like calling s.reindex(index=other.index, columns=other.columns,\n",
      " |                             method=...)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      reindexed : same as input\n",
      " |  \n",
      " |  rename_axis(self, mapper, axis=0, copy=True, inplace=False)\n",
      " |      Alter index and / or columns using input function or functions.\n",
      " |      Function / dict values must be unique (1-to-1). Labels not contained in\n",
      " |      a dict / Series will be left as-is.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      mapper : dict-like or function, optional\n",
      " |      axis : int or string, default 0\n",
      " |      copy : boolean, default True\n",
      " |          Also copy underlying data\n",
      " |      inplace : boolean, default False\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      renamed : type of caller\n",
      " |  \n",
      " |  replace(self, to_replace=None, value=None, inplace=False, limit=None, regex=False, method='pad', axis=None)\n",
      " |      Replace values given in 'to_replace' with 'value'.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      to_replace : str, regex, list, dict, Series, numeric, or None\n",
      " |      \n",
      " |          * str or regex:\n",
      " |      \n",
      " |              - str: string exactly matching `to_replace` will be replaced\n",
      " |                with `value`\n",
      " |              - regex: regexs matching `to_replace` will be replaced with\n",
      " |                `value`\n",
      " |      \n",
      " |          * list of str, regex, or numeric:\n",
      " |      \n",
      " |              - First, if `to_replace` and `value` are both lists, they\n",
      " |                **must** be the same length.\n",
      " |              - Second, if ``regex=True`` then all of the strings in **both**\n",
      " |                lists will be interpreted as regexs otherwise they will match\n",
      " |                directly. This doesn't matter much for `value` since there\n",
      " |                are only a few possible substitution regexes you can use.\n",
      " |              - str and regex rules apply as above.\n",
      " |      \n",
      " |          * dict:\n",
      " |      \n",
      " |              - Nested dictionaries, e.g., {'a': {'b': nan}}, are read as\n",
      " |                follows: look in column 'a' for the value 'b' and replace it\n",
      " |                with nan. You can nest regular expressions as well. Note that\n",
      " |                column names (the top-level dictionary keys in a nested\n",
      " |                dictionary) **cannot** be regular expressions.\n",
      " |              - Keys map to column names and values map to substitution\n",
      " |                values. You can treat this as a special case of passing two\n",
      " |                lists except that you are specifying the column to search in.\n",
      " |      \n",
      " |          * None:\n",
      " |      \n",
      " |              - This means that the ``regex`` argument must be a string,\n",
      " |                compiled regular expression, or list, dict, ndarray or Series\n",
      " |                of such elements. If `value` is also ``None`` then this\n",
      " |                **must** be a nested dictionary or ``Series``.\n",
      " |      \n",
      " |          See the examples section for examples of each of these.\n",
      " |      value : scalar, dict, list, str, regex, default None\n",
      " |          Value to use to fill holes (e.g. 0), alternately a dict of values\n",
      " |          specifying which value to use for each column (columns not in the\n",
      " |          dict will not be filled). Regular expressions, strings and lists or\n",
      " |          dicts of such objects are also allowed.\n",
      " |      inplace : boolean, default False\n",
      " |          If True, in place. Note: this will modify any\n",
      " |          other views on this object (e.g. a column form a DataFrame).\n",
      " |          Returns the caller if this is True.\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to forward or backward fill\n",
      " |      regex : bool or same types as `to_replace`, default False\n",
      " |          Whether to interpret `to_replace` and/or `value` as regular\n",
      " |          expressions. If this is ``True`` then `to_replace` *must* be a\n",
      " |          string. Otherwise, `to_replace` must be ``None`` because this\n",
      " |          parameter will be interpreted as a regular expression or a list,\n",
      " |          dict, or array of regular expressions.\n",
      " |      method : string, optional, {'pad', 'ffill', 'bfill'}\n",
      " |          The method to use when for replacement, when ``to_replace`` is a\n",
      " |          ``list``.\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      NDFrame.reindex\n",
      " |      NDFrame.asfreq\n",
      " |      NDFrame.fillna\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      filled : NDFrame\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AssertionError\n",
      " |          * If `regex` is not a ``bool`` and `to_replace` is not ``None``.\n",
      " |      TypeError\n",
      " |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,\n",
      " |            ``dict``, ``ndarray``, or ``Series``\n",
      " |          * If `to_replace` is ``None`` and `regex` is not compilable into a\n",
      " |            regular expression or is a list, dict, ndarray, or Series.\n",
      " |      ValueError\n",
      " |          * If `to_replace` and `value` are ``list`` s or ``ndarray`` s, but\n",
      " |            they are not the same length.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      * Regex substitution is performed under the hood with ``re.sub``. The\n",
      " |        rules for substitution for ``re.sub`` are the same.\n",
      " |      * Regular expressions will only substitute on strings, meaning you\n",
      " |        cannot provide, for example, a regular expression matching floating\n",
      " |        point numbers and expect the columns in your frame that have a\n",
      " |        numeric dtype to be matched. However, if those floating point numbers\n",
      " |        *are* strings, then you can do this.\n",
      " |      * This method has *a lot* of options. You are encouraged to experiment\n",
      " |        and play with this method to gain intuition about how it works.\n",
      " |  \n",
      " |  resample(self, rule, how=None, axis=0, fill_method=None, closed=None, label=None, convention='start', kind=None, loffset=None, limit=None, base=0)\n",
      " |      Convenience method for frequency conversion and resampling of regular\n",
      " |      time-series data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rule : string\n",
      " |          the offset string or object representing target conversion\n",
      " |      how : string\n",
      " |          method for down- or re-sampling, default to 'mean' for\n",
      " |          downsampling\n",
      " |      axis : int, optional, default 0\n",
      " |      fill_method : string, default None\n",
      " |          fill_method for upsampling\n",
      " |      closed : {'right', 'left'}\n",
      " |          Which side of bin interval is closed\n",
      " |      label : {'right', 'left'}\n",
      " |          Which bin edge label to label bucket with\n",
      " |      convention : {'start', 'end', 's', 'e'}\n",
      " |      kind : \"period\"/\"timestamp\"\n",
      " |      loffset : timedelta\n",
      " |          Adjust the resampled time labels\n",
      " |      limit : int, default None\n",
      " |          Maximum size gap to when reindexing with fill_method\n",
      " |      base : int, default 0\n",
      " |          For frequencies that evenly subdivide 1 day, the \"origin\" of the\n",
      " |          aggregated intervals. For example, for '5min' frequency, base could\n",
      " |          range from 0 through 4. Defaults to 0\n",
      " |  \n",
      " |  save(self, path)\n",
      " |      Deprecated. Use to_pickle instead\n",
      " |  \n",
      " |  select(self, crit, axis=0)\n",
      " |      Return data corresponding to axis labels matching criteria\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      crit : function\n",
      " |          To be called on each index (label). Should return True or False\n",
      " |      axis : int\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      selection : type of caller\n",
      " |  \n",
      " |  set_axis(self, axis, labels)\n",
      " |      public verson of axis assignment\n",
      " |  \n",
      " |  shift(self, periods=1, freq=None, axis=0, **kwargs)\n",
      " |      Shift index by desired number of periods with an optional time freq\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, optional\n",
      " |          Increment to use from datetools module or time rule (e.g. 'EOM').\n",
      " |          See Notes.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is specified then the index values are shifted but the data\n",
      " |      is not realigned. That is, use freq if you would like to extend the\n",
      " |      index when shifting and preserve the original data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  slice_shift(self, periods=1, axis=0)\n",
      " |      Equivalent to `shift` without copying data. The shifted data will\n",
      " |      not include the dropped periods and the shifted axis will be smaller\n",
      " |      than the original.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      While the `slice_shift` is faster than `shift`, you may pay for it\n",
      " |      later during alignment.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : same type as caller\n",
      " |  \n",
      " |  squeeze(self)\n",
      " |      squeeze length 1 dimensions\n",
      " |  \n",
      " |  swapaxes(self, axis1, axis2, copy=True)\n",
      " |      Interchange axes and swap values axes appropriately\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : same as input\n",
      " |  \n",
      " |  tail(self, n=5)\n",
      " |      Returns last n rows\n",
      " |  \n",
      " |  take(self, indices, axis=0, convert=True, is_copy=True)\n",
      " |      Analogous to ndarray.take\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      indices : list / array of ints\n",
      " |      axis : int, default 0\n",
      " |      convert : translate neg to pos indices (default)\n",
      " |      is_copy : mark the returned frame as a copy\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      taken : type of caller\n",
      " |  \n",
      " |  to_clipboard(self, excel=None, sep=None, **kwargs)\n",
      " |      Attempt to write text representation of object to the system clipboard\n",
      " |      This can be pasted into Excel, for example.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      excel : boolean, defaults to True\n",
      " |              if True, use the provided separator, writing in a csv\n",
      " |              format for allowing easy pasting into excel.\n",
      " |              if False, write a string representation of the object\n",
      " |              to the clipboard\n",
      " |      sep : optional, defaults to tab\n",
      " |      other keywords are passed to to_csv\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Requirements for your platform\n",
      " |        - Linux: xclip, or xsel (with gtk or PyQt4 modules)\n",
      " |        - Windows: none\n",
      " |        - OS X: none\n",
      " |  \n",
      " |  to_dense(self)\n",
      " |      Return dense representation of NDFrame (as opposed to sparse)\n",
      " |  \n",
      " |  to_hdf(self, path_or_buf, key, **kwargs)\n",
      " |      activate the HDFStore\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : the path (string) or buffer to put the store\n",
      " |      key : string\n",
      " |          indentifier for the group in the store\n",
      " |      mode : optional, {'a', 'w', 'r', 'r+'}, default 'a'\n",
      " |      \n",
      " |        ``'r'``\n",
      " |            Read-only; no data can be modified.\n",
      " |        ``'w'``\n",
      " |            Write; a new file is created (an existing file with the same\n",
      " |            name would be deleted).\n",
      " |        ``'a'``\n",
      " |            Append; an existing file is opened for reading and writing,\n",
      " |            and if the file does not exist it is created.\n",
      " |        ``'r+'``\n",
      " |            It is similar to ``'a'``, but the file must already exist.\n",
      " |      format   : 'fixed(f)|table(t)', default is 'fixed'\n",
      " |          fixed(f) : Fixed format\n",
      " |                     Fast writing/reading. Not-appendable, nor searchable\n",
      " |          table(t) : Table format\n",
      " |                     Write as a PyTables Table structure which may perform\n",
      " |                     worse but allow more flexible operations like searching\n",
      " |                     / selecting subsets of the data\n",
      " |      append   : boolean, default False\n",
      " |          For Table formats, append the input data to the existing\n",
      " |      complevel : int, 1-9, default 0\n",
      " |          If a complib is specified compression will be applied\n",
      " |          where possible\n",
      " |      complib : {'zlib', 'bzip2', 'lzo', 'blosc', None}, default None\n",
      " |          If complevel is > 0 apply compression to objects written\n",
      " |          in the store wherever possible\n",
      " |      fletcher32 : bool, default False\n",
      " |          If applying compression use the fletcher32 checksum\n",
      " |  \n",
      " |  to_json(self, path_or_buf=None, orient=None, date_format='epoch', double_precision=10, force_ascii=True, date_unit='ms', default_handler=None)\n",
      " |      Convert the object to a JSON string.\n",
      " |      \n",
      " |      Note NaN's and None will be converted to null and datetime objects\n",
      " |      will be converted to UNIX timestamps.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path_or_buf : the path or buffer to write the result string\n",
      " |          if this is None, return a StringIO of the converted string\n",
      " |      orient : string\n",
      " |      \n",
      " |          * Series\n",
      " |      \n",
      " |            - default is 'index'\n",
      " |            - allowed values are: {'split','records','index'}\n",
      " |      \n",
      " |          * DataFrame\n",
      " |      \n",
      " |            - default is 'columns'\n",
      " |            - allowed values are:\n",
      " |              {'split','records','index','columns','values'}\n",
      " |      \n",
      " |          * The format of the JSON string\n",
      " |      \n",
      " |            - split : dict like\n",
      " |              {index -> [index], columns -> [columns], data -> [values]}\n",
      " |            - records : list like\n",
      " |              [{column -> value}, ... , {column -> value}]\n",
      " |            - index : dict like {index -> {column -> value}}\n",
      " |            - columns : dict like {column -> {index -> value}}\n",
      " |            - values : just the values array\n",
      " |      \n",
      " |      date_format : {'epoch', 'iso'}\n",
      " |          Type of date conversion. `epoch` = epoch milliseconds,\n",
      " |          `iso`` = ISO8601, default is epoch.\n",
      " |      double_precision : The number of decimal places to use when encoding\n",
      " |          floating point values, default 10.\n",
      " |      force_ascii : force encoded string to be ASCII, default True.\n",
      " |      date_unit : string, default 'ms' (milliseconds)\n",
      " |          The time unit to encode to, governs timestamp and ISO8601\n",
      " |          precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      " |          microsecond, and nanosecond respectively.\n",
      " |      default_handler : callable, default None\n",
      " |          Handler to call if object cannot otherwise be converted to a\n",
      " |          suitable format for JSON. Should receive a single argument which is\n",
      " |          the object to convert and return a serialisable object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      same type as input object with filtered info axis\n",
      " |  \n",
      " |  to_msgpack(self, path_or_buf=None, **kwargs)\n",
      " |      msgpack (serialize) object to input file path\n",
      " |      \n",
      " |      THIS IS AN EXPERIMENTAL LIBRARY and the storage format\n",
      " |      may not be stable until a future release.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string File path, buffer-like, or None\n",
      " |          if None, return generated string\n",
      " |      append : boolean whether to append to an existing msgpack\n",
      " |          (default is False)\n",
      " |      compress : type of compressor (zlib or blosc), default to None (no\n",
      " |          compression)\n",
      " |  \n",
      " |  to_pickle(self, path)\n",
      " |      Pickle (serialize) object to input file path\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      path : string\n",
      " |          File path\n",
      " |  \n",
      " |  to_sql(self, name, con, flavor='sqlite', schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None)\n",
      " |      Write records stored in a DataFrame to a SQL database.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      name : string\n",
      " |          Name of SQL table\n",
      " |      con : SQLAlchemy engine or DBAPI2 connection (legacy mode)\n",
      " |          Using SQLAlchemy makes it possible to use any DB supported by that\n",
      " |          library.\n",
      " |          If a DBAPI2 object, only sqlite3 is supported.\n",
      " |      flavor : {'sqlite', 'mysql'}, default 'sqlite'\n",
      " |          The flavor of SQL to use. Ignored when using SQLAlchemy engine.\n",
      " |          'mysql' is deprecated and will be removed in future versions, but it\n",
      " |          will be further supported through SQLAlchemy engines.\n",
      " |      schema : string, default None\n",
      " |          Specify the schema (if database flavor supports this). If None, use\n",
      " |          default schema.\n",
      " |      if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      " |          - fail: If table exists, do nothing.\n",
      " |          - replace: If table exists, drop it, recreate it, and insert data.\n",
      " |          - append: If table exists, insert data. Create if does not exist.\n",
      " |      index : boolean, default True\n",
      " |          Write DataFrame index as a column.\n",
      " |      index_label : string or sequence, default None\n",
      " |          Column label for index column(s). If None is given (default) and\n",
      " |          `index` is True, then the index names are used.\n",
      " |          A sequence should be given if the DataFrame uses MultiIndex.\n",
      " |      chunksize : int, default None\n",
      " |          If not None, then rows will be written in batches of this size at a\n",
      " |          time.  If None, all rows will be written at once.\n",
      " |      dtype : dict of column name to SQL type, default None\n",
      " |          Optional specifying the datatype for columns. The SQL type should\n",
      " |          be a SQLAlchemy type, or a string for sqlite3 fallback connection.\n",
      " |  \n",
      " |  truncate(self, before=None, after=None, axis=None, copy=True)\n",
      " |      Truncates a sorted NDFrame before and/or after some particular\n",
      " |      dates.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      before : date\n",
      " |          Truncate before date\n",
      " |      after : date\n",
      " |          Truncate after date\n",
      " |      axis : the truncation axis, defaults to the stat axis\n",
      " |      copy : boolean, default is True,\n",
      " |          return a copy of the truncated section\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      truncated : type of caller\n",
      " |  \n",
      " |  tshift(self, periods=1, freq=None, axis=0, **kwargs)\n",
      " |      Shift the time index, using the index's frequency if available\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      periods : int\n",
      " |          Number of periods to move, can be positive or negative\n",
      " |      freq : DateOffset, timedelta, or time rule string, default None\n",
      " |          Increment to use from datetools module or time rule (e.g. 'EOM')\n",
      " |      axis : int or basestring\n",
      " |          Corresponds to the axis that contains the Index\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If freq is not specified then tries to use the freq or inferred_freq\n",
      " |      attributes of the index. If neither of those attributes exist, a\n",
      " |      ValueError is thrown\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      shifted : NDFrame\n",
      " |  \n",
      " |  tz_convert(self, tz, axis=0, level=None, copy=True)\n",
      " |      Convert the axis to target time zone. If it is time zone naive, it\n",
      " |      will be localized to the passed time zone.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to convert\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, convert a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |  \n",
      " |  tz_localize(*args, **kwargs)\n",
      " |      Localize tz-naive TimeSeries to target time zone\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      tz : string or pytz.timezone object\n",
      " |      axis : the axis to localize\n",
      " |      level : int, str, default None\n",
      " |          If axis ia a MultiIndex, localize a specific level. Otherwise\n",
      " |          must be None\n",
      " |      copy : boolean, default True\n",
      " |          Also make a copy of the underlying data\n",
      " |      ambiguous : 'infer', bool-ndarray, 'NaT', default 'raise'\n",
      " |          - 'infer' will attempt to infer fall dst-transition hours based on order\n",
      " |          - bool-ndarray where True signifies a DST time, False designates\n",
      " |            a non-DST time (note that this flag is only applicable for ambiguous times)\n",
      " |          - 'NaT' will return NaT where there are ambiguous times\n",
      " |          - 'raise' will raise an AmbiguousTimeError if there are ambiguous times\n",
      " |      infer_dst : boolean, default False (DEPRECATED)\n",
      " |          Attempt to infer fall dst-transition hours based on order\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |  \n",
      " |  where(self, cond, other=nan, inplace=False, axis=None, level=None, try_cast=False, raise_on_error=True)\n",
      " |      Return an object of same shape as self and whose corresponding\n",
      " |      entries are from self where cond is True and otherwise are from other.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      cond : boolean NDFrame or array\n",
      " |      other : scalar or NDFrame\n",
      " |      inplace : boolean, default False\n",
      " |          Whether to perform the operation in place on the data\n",
      " |      axis : alignment axis if needed, default None\n",
      " |      level : alignment level if needed, default None\n",
      " |      try_cast : boolean, default False\n",
      " |          try to cast the result back to the input type (if possible),\n",
      " |      raise_on_error : boolean, default True\n",
      " |          Whether to raise on invalid data types (e.g. trying to where on\n",
      " |          strings)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      wh : same type as caller\n",
      " |  \n",
      " |  xs(self, key, axis=0, level=None, copy=None, drop_level=True)\n",
      " |      Returns a cross-section (row(s) or column(s)) from the Series/DataFrame.\n",
      " |      Defaults to cross-section on the rows (axis=0).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : object\n",
      " |          Some label contained in the index, or partially in a MultiIndex\n",
      " |      axis : int, default 0\n",
      " |          Axis to retrieve cross-section on\n",
      " |      level : object, defaults to first n levels (n=1 or len(key))\n",
      " |          In case of a key partially contained in a MultiIndex, indicate\n",
      " |          which levels are used. Levels can be referred by label or position.\n",
      " |      copy : boolean [deprecated]\n",
      " |          Whether to make a copy of the data\n",
      " |      drop_level : boolean, default True\n",
      " |          If False, returns object with same levels as self.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> df\n",
      " |         A  B  C\n",
      " |      a  4  5  2\n",
      " |      b  4  0  9\n",
      " |      c  9  7  3\n",
      " |      >>> df.xs('a')\n",
      " |      A    4\n",
      " |      B    5\n",
      " |      C    2\n",
      " |      Name: a\n",
      " |      >>> df.xs('C', axis=1)\n",
      " |      a    2\n",
      " |      b    9\n",
      " |      c    3\n",
      " |      Name: C\n",
      " |      \n",
      " |      >>> df\n",
      " |                          A  B  C  D\n",
      " |      first second third\n",
      " |      bar   one    1      4  1  8  9\n",
      " |            two    1      7  5  5  0\n",
      " |      baz   one    1      6  6  8  0\n",
      " |            three  2      5  3  5  3\n",
      " |      >>> df.xs(('baz', 'three'))\n",
      " |             A  B  C  D\n",
      " |      third\n",
      " |      2      5  3  5  3\n",
      " |      >>> df.xs('one', level=1)\n",
      " |                   A  B  C  D\n",
      " |      first third\n",
      " |      bar   1      4  1  8  9\n",
      " |      baz   1      6  6  8  0\n",
      " |      >>> df.xs(('baz', 2), level=[0, 'third'])\n",
      " |              A  B  C  D\n",
      " |      second\n",
      " |      three   5  3  5  3\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      xs : Series or DataFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      xs is only for getting, not setting values.\n",
      " |      \n",
      " |      MultiIndex Slicers is a generic way to get/set values on any level or levels\n",
      " |      it is a superset of xs functionality, see :ref:`MultiIndex Slicers <advanced.mi_slicers>`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  at\n",
      " |      Fast label-based scalar accessor\n",
      " |      \n",
      " |      Similarly to ``loc``, ``at`` provides **label** based scalar lookups.\n",
      " |      You can also set using these indexers.\n",
      " |  \n",
      " |  blocks\n",
      " |      Internal property, property synonym for as_blocks()\n",
      " |  \n",
      " |  dtypes\n",
      " |      Return the dtypes in this object\n",
      " |  \n",
      " |  empty\n",
      " |      True if NDFrame is entirely empty [no items]\n",
      " |  \n",
      " |  ftypes\n",
      " |      Return the ftypes (indication of sparse/dense and dtype)\n",
      " |      in this object.\n",
      " |  \n",
      " |  iat\n",
      " |      Fast integer location scalar accessor.\n",
      " |      \n",
      " |      Similarly to ``iloc``, ``iat`` provides **integer** based lookups.\n",
      " |      You can also set using these indexers.\n",
      " |  \n",
      " |  iloc\n",
      " |      Purely integer-location based indexing for selection by position.\n",
      " |      \n",
      " |      ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |      ``length-1`` of the axis), but may also be used with a boolean\n",
      " |      array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - An integer, e.g. ``5``.\n",
      " |      - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |      - A slice object with ints, e.g. ``1:7``.\n",
      " |      - A boolean array.\n",
      " |      \n",
      " |      ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |      out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |      indexing (this conforms with python/numpy *slice* semantics).\n",
      " |      \n",
      " |      See more at :ref:`Selection by Position <indexing.integer>`\n",
      " |  \n",
      " |  ix\n",
      " |      A primarily label-location based indexer, with integer position\n",
      " |      fallback.\n",
      " |      \n",
      " |      ``.ix[]`` supports mixed integer and label based access. It is\n",
      " |      primarily label based, but will fall back to integer positional\n",
      " |      access unless the corresponding axis is of integer type.\n",
      " |      \n",
      " |      ``.ix`` is the most general indexer and will support any of the\n",
      " |      inputs in ``.loc`` and ``.iloc``. ``.ix`` also supports floating\n",
      " |      point label schemes. ``.ix`` is exceptionally useful when dealing\n",
      " |      with mixed positional and label based hierachical indexes.\n",
      " |      \n",
      " |      However, when an axis is integer based, ONLY label based access\n",
      " |      and not positional access is supported. Thus, in such cases, it's\n",
      " |      usually better to be explicit and use ``.iloc`` or ``.loc``.\n",
      " |      \n",
      " |      See more at :ref:`Advanced Indexing <advanced>`.\n",
      " |  \n",
      " |  loc\n",
      " |      Purely label-location based indexer for selection by label.\n",
      " |      \n",
      " |      ``.loc[]`` is primarily label based, but may also be used with a\n",
      " |      boolean array.\n",
      " |      \n",
      " |      Allowed inputs are:\n",
      " |      \n",
      " |      - A single label, e.g. ``5`` or ``'a'``, (note that ``5`` is\n",
      " |        interpreted as a *label* of the index, and **never** as an\n",
      " |        integer position along the index).\n",
      " |      - A list or array of labels, e.g. ``['a', 'b', 'c']``.\n",
      " |      - A slice object with labels, e.g. ``'a':'f'`` (note that contrary\n",
      " |        to usual python slices, **both** the start and the stop are included!).\n",
      " |      - A boolean array.\n",
      " |      \n",
      " |      ``.loc`` will raise a ``KeyError`` when the items are not found.\n",
      " |      \n",
      " |      See more at :ref:`Selection by Label <indexing.label>`\n",
      " |  \n",
      " |  ndim\n",
      " |      Number of axes / array dimensions\n",
      " |  \n",
      " |  size\n",
      " |      number of elements in the NDFrame\n",
      " |  \n",
      " |  values\n",
      " |      Numpy representation of NDFrame\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The dtype will be a lower-common-denominator dtype (implicit\n",
      " |      upcasting); that is to say if the dtypes (even of numeric types)\n",
      " |      are mixed, the one that accommodates all will be chosen. Use this\n",
      " |      with care if you are not dealing with the blocks.\n",
      " |      \n",
      " |      e.g. If the dtypes are float16 and float32, dtype will be upcast to\n",
      " |      float32.  If dtypes are int32 and uint8, dtype will be upcase to\n",
      " |      int32.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pandas.core.generic.NDFrame:\n",
      " |  \n",
      " |  is_copy = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.PandasObject:\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Provide method name lookup and completion\n",
      " |      Only provide 'public' methods\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __bytes__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Invoked by bytes(obj) in py3 only.\n",
      " |      Yields a bytestring in both py2/py3.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return a string representation for a particular object.\n",
      " |      \n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return a string representation for a particular Object\n",
      " |      \n",
      " |      Invoked by str(df) in both py2/py3.\n",
      " |      Yields Bytestring in Py2, Unicode String in py3.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas.core.base.StringMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(orderinfo.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_index</th>\n",
       "      <th>slot</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>count</th>\n",
       "      <th>grid</th>\n",
       "      <th>avg_price_3</th>\n",
       "      <th>avg_count_3</th>\n",
       "      <th>price_delta_1</th>\n",
       "      <th>price_delta_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.365169</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15.424084</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.203514</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.516484</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16.395210</td>\n",
       "      <td>167</td>\n",
       "      <td>1</td>\n",
       "      <td>17.101912</td>\n",
       "      <td>183.666667</td>\n",
       "      <td>-0.007343</td>\n",
       "      <td>-0.066345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>17.171053</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>16.111926</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.047321</td>\n",
       "      <td>0.031741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_index  slot  avg_price  count  grid  avg_price_3  avg_count_3  \\\n",
       "0           1     1  19.365169    178     1          NaN          NaN   \n",
       "1           1     2  15.424084    191     1          NaN          NaN   \n",
       "2           1     3  16.516484    182     1          NaN          NaN   \n",
       "3           1     4  16.395210    167     1    17.101912   183.666667   \n",
       "4           1     5  17.171053    152     1    16.111926   180.000000   \n",
       "\n",
       "   price_delta_1  price_delta_3  \n",
       "0            NaN            NaN  \n",
       "1      -0.203514            NaN  \n",
       "2       0.070824            NaN  \n",
       "3      -0.007343      -0.066345  \n",
       "4       0.047321       0.031741  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#o = orderinfo.dropna(how = 'any')\n",
    "#o.head()\n",
    "orderinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slot</th>\n",
       "      <th>grid</th>\n",
       "      <th>avg_price_3</th>\n",
       "      <th>avg_count_3</th>\n",
       "      <th>price_delta_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17.101912</td>\n",
       "      <td>183.666667</td>\n",
       "      <td>-0.066345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>16.111926</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.031741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16.694249</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.019989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>17.142953</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.043798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>17.549274</td>\n",
       "      <td>136.666667</td>\n",
       "      <td>0.013183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slot  grid  avg_price_3  avg_count_3  price_delta_3\n",
       "3     4     1    17.101912   183.666667      -0.066345\n",
       "4     5     1    16.111926   180.000000       0.031741\n",
       "5     6     1    16.694249   167.000000       0.019989\n",
       "6     7     1    17.142953   150.000000       0.043798\n",
       "7     8     1    17.549274   136.666667       0.013183"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = orderinfo.dropna(how = 'any')\n",
    "del o['start_index']\n",
    "del o['avg_price']\n",
    "del o['count']\n",
    "del o['price_delta_1']\n",
    "o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39525\n",
      "5012870\n"
     ]
    }
   ],
   "source": [
    "print orderinfo.size  # 7905 * 4 = 31620  complete 66 * 144 = 9504\n",
    "print order.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1296\n"
     ]
    }
   ],
   "source": [
    "print 9*144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(orderinfo['start_index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2739</td>\n",
       "      <td>498</td>\n",
       "      <td>1909</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8051</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>4814</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245</td>\n",
       "      <td>83</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>5644</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>747</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332</td>\n",
       "      <td>83</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>2573</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>249</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 451 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1     2   3    4     5    6  7     8   9  ...    441  442  443  \\\n",
       "0  2739  498  1909   0   83  8051   83  0  4814   0  ...   3984    0    0   \n",
       "1  1245   83   913   0   83  5644  166  0   747   0  ...   2988    0    0   \n",
       "2    83    0    83   0    0   166  332  0     0  83  ...    498    0    0   \n",
       "3   332   83   415   0  166  2573    0  0   913   0  ...   1743    0    0   \n",
       "4    83    0     0  83   83   249  415  0     0  83  ...    166    0    0   \n",
       "\n",
       "   444  445  446  447  448  449  grid  \n",
       "0    0    0    0    0    0    0     1  \n",
       "1    0    0    0    0    0    0     2  \n",
       "2    0    0    0    0    0    0     3  \n",
       "3    0    0    0    0    0    0     4  \n",
       "4    0    0    0    0    0    0     5  \n",
       "\n",
       "[5 rows x 451 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orderinfo['grid'] = orderinfo['start_index'].map(lambda x: (int)(x))\n",
    "\n",
    "#orderinfo.drop(['start_index'])\n",
    "#orderpoi = pd.merge(orderinfo, poi2, how='left', on=['grid'])\n",
    "poi2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_index     object\n",
       "slot             int64\n",
       "avg_price      float64\n",
       "count            int64\n",
       "avg_count      float64\n",
       "grid             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orderinfo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>tampreture</th>\n",
       "      <th>pm25</th>\n",
       "      <th>slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:00:28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:05:24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:10:08</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:15:27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>00:20:06</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date      time  type  tampreture  pm25  slot\n",
       "0  2016-01-01  00:00:28     1           4   177     1\n",
       "1  2016-01-01  00:05:24     1           3   177     1\n",
       "2  2016-01-01  00:10:08     1           3   177     2\n",
       "3  2016-01-01  00:15:27     1           3   177     2\n",
       "4  2016-01-01  00:20:06     1           3   177     3"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           object\n",
       "time           object\n",
       "type            int64\n",
       "tampreture    float64\n",
       "pm25            int64\n",
       "slot            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n",
      "142\n",
      "142\n"
     ]
    }
   ],
   "source": [
    "weather.size\n",
    "print 1674 / 6\n",
    "wgb = weather.groupby(['slot'], as_index=False)\n",
    "wtype = wgb['type'].agg({'wtype':np.max})\n",
    "wtemp = wgb['tampreture'].agg({'wtemp':np.mean})\n",
    "wpm25 = wgb['pm25'].agg({'wpm25':np.mean})\n",
    "wea1 = pd.merge(wtype, wtemp, how ='outer' , on = ['slot'])\n",
    "wea = pd.merge(wea1, wpm25, how = 'outer', on = ['slot'])\n",
    "print wea.size / 4\n",
    "print len(set(weather['slot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_index</th>\n",
       "      <th>slot</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_count</th>\n",
       "      <th>grid</th>\n",
       "      <th>wtype</th>\n",
       "      <th>wtemp</th>\n",
       "      <th>wpm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.365169</td>\n",
       "      <td>178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15.424084</td>\n",
       "      <td>191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.516484</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16.395210</td>\n",
       "      <td>167</td>\n",
       "      <td>183.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>17.171053</td>\n",
       "      <td>152</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_index  slot  avg_price  count   avg_count  grid  wtype  wtemp  wpm25\n",
       "0           1     1  19.365169    178         NaN     1      1    3.5    177\n",
       "1           1     2  15.424084    191         NaN     1      1    3.0    177\n",
       "2           1     3  16.516484    182         NaN     1      1    3.0    177\n",
       "3           1     4  16.395210    167  183.666667     1      1    3.0    177\n",
       "4           1     5  17.171053    152  180.000000     1      1    3.0    177"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orderweather = pd.merge(orderinfo, wea, how='left', on=['slot'])\n",
    "orderweather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    object\n",
       "one      object\n",
       "two      object\n",
       "three    object\n",
       "four     object\n",
       "date     object\n",
       "time     object\n",
       "slot      int64\n",
       "grid      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic['grid'] = traffic['grid'].map(lambda x : (int) (x))\n",
    "traffic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_index</th>\n",
       "      <th>slot</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_count</th>\n",
       "      <th>grid</th>\n",
       "      <th>wtype</th>\n",
       "      <th>wtemp</th>\n",
       "      <th>wpm25</th>\n",
       "      <th>index</th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>19.346154</td>\n",
       "      <td>26</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>126</td>\n",
       "      <td>b702e920dcd2765e624dc1ce3a770512</td>\n",
       "      <td>583</td>\n",
       "      <td>95</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>23:10:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7713</th>\n",
       "      <td>9</td>\n",
       "      <td>141</td>\n",
       "      <td>21.916667</td>\n",
       "      <td>12</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>126</td>\n",
       "      <td>b702e920dcd2765e624dc1ce3a770512</td>\n",
       "      <td>574</td>\n",
       "      <td>83</td>\n",
       "      <td>42</td>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>23:20:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7714</th>\n",
       "      <td>9</td>\n",
       "      <td>142</td>\n",
       "      <td>20.526316</td>\n",
       "      <td>19</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>126</td>\n",
       "      <td>b702e920dcd2765e624dc1ce3a770512</td>\n",
       "      <td>529</td>\n",
       "      <td>82</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>23:30:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7715</th>\n",
       "      <td>9</td>\n",
       "      <td>143</td>\n",
       "      <td>15.285714</td>\n",
       "      <td>28</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>131</td>\n",
       "      <td>b702e920dcd2765e624dc1ce3a770512</td>\n",
       "      <td>554</td>\n",
       "      <td>79</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>23:40:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7716</th>\n",
       "      <td>9</td>\n",
       "      <td>144</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>8</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>131</td>\n",
       "      <td>b702e920dcd2765e624dc1ce3a770512</td>\n",
       "      <td>485</td>\n",
       "      <td>83</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>23:50:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     start_index  slot  avg_price  count  avg_count  grid  wtype  wtemp  \\\n",
       "7712           9   140  19.346154     26  21.333333     9      2      8   \n",
       "7713           9   141  21.916667     12  21.000000     9      2      8   \n",
       "7714           9   142  20.526316     19  18.333333     9      2      8   \n",
       "7715           9   143  15.285714     28  19.000000     9      2      8   \n",
       "7716           9   144  15.750000      8  19.666667     9      2      8   \n",
       "\n",
       "      wpm25                             index  one  two  three  four  \\\n",
       "7712    126  b702e920dcd2765e624dc1ce3a770512  583   95     31    26   \n",
       "7713    126  b702e920dcd2765e624dc1ce3a770512  574   83     42    26   \n",
       "7714    126  b702e920dcd2765e624dc1ce3a770512  529   82     34    26   \n",
       "7715    131  b702e920dcd2765e624dc1ce3a770512  554   79     20    20   \n",
       "7716    131  b702e920dcd2765e624dc1ce3a770512  485   83     38    14   \n",
       "\n",
       "            date      time  \n",
       "7712  2016-01-01  23:10:24  \n",
       "7713  2016-01-01  23:20:23  \n",
       "7714  2016-01-01  23:30:22  \n",
       "7715  2016-01-01  23:40:21  \n",
       "7716  2016-01-01  23:50:20  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic['one'] = traffic['one'].map(lambda x: (int) (x))\n",
    "traffic['two'] = traffic['two'].map(lambda x: (int) (x))\n",
    "traffic['three'] = traffic['three'].map(lambda x: (int) (x))\n",
    "traffic['four'] = traffic['four'].map(lambda x: (int) (x))\n",
    "\n",
    "orderweathertraffic = pd.merge(orderweather, traffic, how='inner', on=['slot','grid'])\n",
    "orderweathertraffic.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print orderpoiweathertraffic.size / 465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print traffic.size / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traffic.dtypes\n",
    "#traffic[traffic['grid'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(traffic['slot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orderpoiweathertraffic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del orderpoiweathertraffic['index']\n",
    "del orderpoiweathertraffic['date']\n",
    "del orderpoiweathertraffic['time']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orderpoiweathertraffic.fillna(orderpoiweathertraffic.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gap_training = pd.read_csv('../gap_training_set')\n",
    "gap_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid</th>\n",
       "      <th>slot</th>\n",
       "      <th>count</th>\n",
       "      <th>avg_price_3</th>\n",
       "      <th>avg_count_3</th>\n",
       "      <th>price_delta_3</th>\n",
       "      <th>count_delta_1</th>\n",
       "      <th>count_delta_3</th>\n",
       "      <th>min_type_3</th>\n",
       "      <th>avg_temp_3</th>\n",
       "      <th>...</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>449</th>\n",
       "      <th>dayOfWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>172</td>\n",
       "      <td>17.263728</td>\n",
       "      <td>192.333333</td>\n",
       "      <td>-0.046004</td>\n",
       "      <td>-0.104167</td>\n",
       "      <td>0.014260</td>\n",
       "      <td>1</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>153</td>\n",
       "      <td>16.319391</td>\n",
       "      <td>187.333333</td>\n",
       "      <td>0.017630</td>\n",
       "      <td>-0.110465</td>\n",
       "      <td>-0.067235</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>132</td>\n",
       "      <td>16.777996</td>\n",
       "      <td>172.333333</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>-0.137255</td>\n",
       "      <td>-0.107316</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "      <td>17.028628</td>\n",
       "      <td>152.333333</td>\n",
       "      <td>0.046955</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.123860</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>130</td>\n",
       "      <td>17.327849</td>\n",
       "      <td>139.333333</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>-0.022556</td>\n",
       "      <td>-0.064840</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 467 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   grid  slot  count  avg_price_3  avg_count_3  price_delta_3  count_delta_1  \\\n",
       "0     1     4    172    17.263728   192.333333      -0.046004      -0.104167   \n",
       "1     1     5    153    16.319391   187.333333       0.017630      -0.110465   \n",
       "2     1     6    132    16.777996   172.333333       0.003557      -0.137255   \n",
       "3     1     7    133    17.028628   152.333333       0.046955       0.007576   \n",
       "4     1     8    130    17.327849   139.333333       0.001164      -0.022556   \n",
       "\n",
       "   count_delta_3  min_type_3  avg_temp_3    ...      441 442  443  444  445  \\\n",
       "0       0.014260           1    3.166667    ...        0   0    0    0    0   \n",
       "1      -0.067235           1    3.000000    ...        0   0    0    0    0   \n",
       "2      -0.107316           1    3.000000    ...        0   0    0    0    0   \n",
       "3      -0.123860           1    3.000000    ...        0   0    0    0    0   \n",
       "4      -0.064840           1    3.000000    ...        0   0    0    0    0   \n",
       "\n",
       "   446  447  448  449  dayOfWeek  \n",
       "0    0    0    0    0          4  \n",
       "1    0    0    0    0          4  \n",
       "2    0    0    0    0          4  \n",
       "3    0    0    0    0          4  \n",
       "4    0    0    0    0          4  \n",
       "\n",
       "[5 rows x 467 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "gap_train = pd.read_csv('../gap_training_set.csv')\n",
    "gap_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158105\n",
      "137231\n"
     ]
    }
   ],
   "source": [
    "#gap_train.dtypes\n",
    "print gap_train.size / 467\n",
    "train = gap_train.dropna(how = 'any')\n",
    "print train.size / 467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(Y,Y_predict):\n",
    "    rmse = np.sqrt(sum([x ** 2 for x in (Y_predict - Y)]) / len(Y))\n",
    "    return rmse\n",
    "def relative_err(Y, Y_predict):\n",
    "    rerr = sum([abs(b-a) / (a+0.01) for a, b in zip(Y, Y_predict)]) / len(Y)\n",
    "    return rerr\n",
    "def abs_err(Y, Y_predict):\n",
    "    aerr = sum( [abs(b-a) for a, b in zip(Y, Y_predict)]) / len(Y)\n",
    "    return aerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_regression_ridge(X, Y, alpha = 0.0):\n",
    "    print('....... linear regression with whole dataset, and the r2 score:  ........')\n",
    "    lr = linear_model.Ridge(alpha=alpha)\n",
    "    fit = lr.fit(X, Y)\n",
    "    score = lr.score(X, Y)\n",
    "    print('r2 score = ')\n",
    "    print(score)\n",
    "    print('....... cross_validation of linear regression .....................')\n",
    "    new_cv = ShuffleSplit(len(X), n_iter = 5, test_size = 0.3, random_state = 0)\n",
    "    print('................. r2 score.........................................................')\n",
    "    for train, test in new_cv:\n",
    "        svc = linear_model.Ridge(alpha=alpha).fit(X[train], Y[train])\n",
    "        print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(svc.score(X[train], Y[train]), svc.score(X[test], Y[test])))\n",
    "    print('.................. rmse ...........................................................')\n",
    "    for train, test in new_cv:\n",
    "        svc = linear_model.Ridge(alpha=alpha).fit(X[train], Y[train])\n",
    "        print(\"train rmse: {0:.3f}, test rmse: {1:.3f}\\n\".format(rmse(Y[train], svc.predict(X[train])), rmse(Y[test], svc.predict(X[test]))))\n",
    "    print('..................relative_error ...........................................................')\n",
    "    for train, test in new_cv:\n",
    "        svc = linear_model.Ridge(alpha=alpha).fit(X[train], Y[train])\n",
    "        print(\"train relative_err: {0:.3f}, test relative_err: {1:.3f}\\n\".format(relative_err(Y[train], svc.predict(X[train])), relative_err(Y[test], svc.predict(X[test]))))\n",
    "    print('.................. absolute error ...........................................................')\n",
    "    for train, test in new_cv:\n",
    "        svc = linear_model.Ridge(alpha=alpha).fit(X[train], Y[train])\n",
    "        print(\"train abs_err: {0:.3f}, test abs_err: {1:.3f}\\n\".format(abs_err(Y[train], svc.predict(X[train])), abs_err(Y[test], svc.predict(X[test]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....... linear regression with whole dataset, and the r2 score:  ........\n",
      "r2 score = \n",
      "0.934773234525\n",
      "....... cross_validation of linear regression .....................\n",
      "................. r2 score.........................................................\n",
      "train score: 0.936, test score: 0.931\n",
      "\n",
      "train score: 0.938, test score: 0.927\n",
      "\n",
      "train score: 0.937, test score: 0.928\n",
      "\n",
      "train score: 0.937, test score: 0.931\n",
      "\n",
      "train score: 0.934, test score: 0.937\n",
      "\n",
      ".................. rmse ...........................................................\n",
      "train rmse: 27.169, test rmse: 29.477\n",
      "\n",
      "train rmse: 27.303, test rmse: 29.195\n",
      "\n",
      "train rmse: 27.645, test rmse: 28.429\n",
      "\n",
      "train rmse: 27.330, test rmse: 29.150\n",
      "\n",
      "train rmse: 28.166, test rmse: 27.217\n",
      "\n",
      "..................relatice_error ...........................................................\n",
      "train relative_err: 0.800, test relative_err: 0.787\n",
      "\n",
      "train relative_err: 0.794, test relative_err: 0.781\n",
      "\n",
      "train relative_err: 0.796, test relative_err: 0.789\n",
      "\n",
      "train relative_err: 0.804, test relative_err: 0.771\n",
      "\n",
      "train relative_err: 0.798, test relative_err: 0.773\n",
      "\n",
      ".................. absolute error ...........................................................\n",
      "train abs_err: 9.975, test relative_err: 10.050\n",
      "\n",
      "train abs_err: 9.937, test relative_err: 10.193\n",
      "\n",
      "train abs_err: 10.053, test relative_err: 9.887\n",
      "\n",
      "train abs_err: 9.961, test relative_err: 10.045\n",
      "\n",
      "train abs_err: 9.929, test relative_err: 10.078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = train.drop(['count','date'], axis = 1).values\n",
    "target = train['count'].values\n",
    "linear_regression_ridge(features, target, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gridsearch(X, Y):\n",
    "    # Split the dataset in two equal parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "    # Set the parameters by cross-validation\n",
    "    #tuned_parameters = [{'learning_rate': [0.1,0.01,0.05], 'max_depth': [1,3,10],'n_estimators': [100,300,500], 'max_features':['sqrt','auto',5]},]\n",
    "    tuned_parameters = [{'max_depth': [1,3,10,30],'n_estimators': [100,300,500,1000], 'max_features':['sqrt','auto',5]}]\n",
    "    #scores = ['precision', 'recall']\n",
    "    #svr = GridSearchCV(GradientBoostingRegressor(), tuned_parameters, cv = 3, scoring = 'mean_squared_error')\n",
    "    svr = GridSearchCV(RandomForestRegressor(), tuned_parameters, cv = 3)\n",
    "    svr.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(svr.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in svr.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean_score, scores.std() * 2, params))\n",
    "        y_true, y_pred = y_test, svr.predict(X_test)\n",
    "        print(\"rmse: \")\n",
    "        print(rmse(y_true, y_pred))\n",
    "        print(\"relative_err: \")\n",
    "        print(relative_err(y_true, y_pred))\n",
    "        print(\"abs_err: \")\n",
    "        print(abs_err(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'max_features': 'auto', 'n_estimators': 300, 'max_depth': 30}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.227 (+/-0.049) for {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.227 (+/-0.022) for {'max_features': 'sqrt', 'n_estimators': 300, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.224 (+/-0.029) for {'max_features': 'sqrt', 'n_estimators': 500, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.230 (+/-0.005) for {'max_features': 'sqrt', 'n_estimators': 1000, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.602 (+/-0.015) for {'max_features': 'auto', 'n_estimators': 100, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.601 (+/-0.013) for {'max_features': 'auto', 'n_estimators': 300, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.601 (+/-0.015) for {'max_features': 'auto', 'n_estimators': 500, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.601 (+/-0.015) for {'max_features': 'auto', 'n_estimators': 1000, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.176 (+/-0.027) for {'max_features': 5, 'n_estimators': 100, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.206 (+/-0.025) for {'max_features': 5, 'n_estimators': 300, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.215 (+/-0.007) for {'max_features': 5, 'n_estimators': 500, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.217 (+/-0.009) for {'max_features': 5, 'n_estimators': 1000, 'max_depth': 1}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.481 (+/-0.058) for {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.487 (+/-0.029) for {'max_features': 'sqrt', 'n_estimators': 300, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.487 (+/-0.011) for {'max_features': 'sqrt', 'n_estimators': 500, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.484 (+/-0.008) for {'max_features': 'sqrt', 'n_estimators': 1000, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.904 (+/-0.017) for {'max_features': 'auto', 'n_estimators': 100, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.905 (+/-0.017) for {'max_features': 'auto', 'n_estimators': 300, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.905 (+/-0.016) for {'max_features': 'auto', 'n_estimators': 500, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.905 (+/-0.016) for {'max_features': 'auto', 'n_estimators': 1000, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.445 (+/-0.029) for {'max_features': 5, 'n_estimators': 100, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.455 (+/-0.005) for {'max_features': 5, 'n_estimators': 300, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.448 (+/-0.002) for {'max_features': 5, 'n_estimators': 500, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.465 (+/-0.012) for {'max_features': 5, 'n_estimators': 1000, 'max_depth': 3}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.822 (+/-0.031) for {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.825 (+/-0.016) for {'max_features': 'sqrt', 'n_estimators': 300, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.823 (+/-0.014) for {'max_features': 'sqrt', 'n_estimators': 500, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.823 (+/-0.014) for {'max_features': 'sqrt', 'n_estimators': 1000, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.983 (+/-0.007) for {'max_features': 'auto', 'n_estimators': 100, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.984 (+/-0.006) for {'max_features': 'auto', 'n_estimators': 300, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.984 (+/-0.007) for {'max_features': 'auto', 'n_estimators': 500, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.984 (+/-0.006) for {'max_features': 'auto', 'n_estimators': 1000, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.794 (+/-0.018) for {'max_features': 5, 'n_estimators': 100, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.796 (+/-0.011) for {'max_features': 5, 'n_estimators': 300, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.799 (+/-0.016) for {'max_features': 5, 'n_estimators': 500, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.800 (+/-0.017) for {'max_features': 5, 'n_estimators': 1000, 'max_depth': 10}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.906 (+/-0.004) for {'max_features': 'sqrt', 'n_estimators': 100, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.910 (+/-0.010) for {'max_features': 'sqrt', 'n_estimators': 300, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.911 (+/-0.012) for {'max_features': 'sqrt', 'n_estimators': 500, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.912 (+/-0.007) for {'max_features': 'sqrt', 'n_estimators': 1000, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.984 (+/-0.003) for {'max_features': 'auto', 'n_estimators': 100, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.984 (+/-0.008) for {'max_features': 'auto', 'n_estimators': 300, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.984 (+/-0.005) for {'max_features': 'auto', 'n_estimators': 500, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.984 (+/-0.007) for {'max_features': 'auto', 'n_estimators': 1000, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.895 (+/-0.008) for {'max_features': 5, 'n_estimators': 100, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.897 (+/-0.008) for {'max_features': 5, 'n_estimators': 300, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.897 (+/-0.013) for {'max_features': 5, 'n_estimators': 500, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n",
      "0.899 (+/-0.010) for {'max_features': 5, 'n_estimators': 1000, 'max_depth': 30}\n",
      "rmse: \n",
      "12.7780307924\n",
      "relative_err: \n",
      "0.0941098737536\n",
      "abs_err: \n",
      "2.62630928356\n"
     ]
    }
   ],
   "source": [
    "gridsearch(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../../test_set_1/order_data/order_data_2016-01-22_test',delim_whitespace=True, header=None)\n",
    "col = ['oid','did','pid','start','end','price','date','time']\n",
    "test.columns = col\n",
    "test['slot'] = test['time'].map(lambda x : time2slot(x))\n",
    "set(test['slot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>tampreture</th>\n",
       "      <th>pm25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>11:12:11</td>\n",
       "      <td>1</td>\n",
       "      <td>-6</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>13:16:58</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>15:06:53</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>15:21:52</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>17:01:37</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>17:22:19</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>19:07:06</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>21:13:01</td>\n",
       "      <td>1</td>\n",
       "      <td>-6</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>23:02:15</td>\n",
       "      <td>1</td>\n",
       "      <td>-7</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>23:16:51</td>\n",
       "      <td>1</td>\n",
       "      <td>-7</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-01-24</td>\n",
       "      <td>23:25:40</td>\n",
       "      <td>1</td>\n",
       "      <td>-7</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date      time  type  tampreture  pm25\n",
       "0   2016-01-24  11:12:11     1          -6    63\n",
       "1   2016-01-24  13:16:58     1          -4    61\n",
       "2   2016-01-24  15:06:53     1          -4    54\n",
       "3   2016-01-24  15:21:52     1          -4    54\n",
       "4   2016-01-24  17:01:37     1          -4    50\n",
       "5   2016-01-24  17:22:19     1          -5    50\n",
       "6   2016-01-24  19:07:06     2          -6    51\n",
       "7   2016-01-24  21:13:01     1          -6    58\n",
       "8   2016-01-24  23:02:15     1          -7    59\n",
       "9   2016-01-24  23:16:51     1          -7    59\n",
       "10  2016-01-24  23:25:40     1          -7    59"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wea = pd.read_csv('../../test_set_1/weather_data/weather_data_2016-01-24_test',delim_whitespace=True, header=None)\n",
    "\n",
    "col = ['date','time','type','tampreture','pm25']\n",
    "test_wea.columns = col\n",
    "test_wea\n",
    "#test_wea['slot'] = test['time'].map(lambda x : time2slot(x))\n",
    "#set(test_wea['slot'])\n",
    "\n",
    "#test_wea.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>slot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ecbb52d73c522f184a6fc53128b1ea1</td>\n",
       "      <td>1:239</td>\n",
       "      <td>2:127</td>\n",
       "      <td>3:28</td>\n",
       "      <td>4:21</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:10:47</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f2c8c4bb99e6377d21de71275afd6cd2</td>\n",
       "      <td>1:627</td>\n",
       "      <td>2:299</td>\n",
       "      <td>3:55</td>\n",
       "      <td>4:22</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:20:47</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f2c8c4bb99e6377d21de71275afd6cd2</td>\n",
       "      <td>1:660</td>\n",
       "      <td>2:143</td>\n",
       "      <td>3:18</td>\n",
       "      <td>4:19</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:20:45</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4b9e4cf2fbdc8281b8a1f9f12b80ce4d</td>\n",
       "      <td>1:90</td>\n",
       "      <td>2:28</td>\n",
       "      <td>3:5</td>\n",
       "      <td>4:0</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>13:00:40</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1cbfbdd079ef93e74405c53fcfff8567</td>\n",
       "      <td>1:301</td>\n",
       "      <td>2:53</td>\n",
       "      <td>3:19</td>\n",
       "      <td>4:19</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>11:10:39</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f9280c5dab6910ed44e518248048b9fe</td>\n",
       "      <td>1:303</td>\n",
       "      <td>2:39</td>\n",
       "      <td>3:23</td>\n",
       "      <td>4:0</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>15:00:42</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74ec84f1cf75cf89ae176c8c6ceec5ba</td>\n",
       "      <td>1:234</td>\n",
       "      <td>2:41</td>\n",
       "      <td>3:0</td>\n",
       "      <td>4:4</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>21:20:40</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74ec84f1cf75cf89ae176c8c6ceec5ba</td>\n",
       "      <td>1:224</td>\n",
       "      <td>2:29</td>\n",
       "      <td>3:9</td>\n",
       "      <td>4:3</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>13:10:39</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4f8d81b5c31af5d1ba579a65ddc8a5cb</td>\n",
       "      <td>1:405</td>\n",
       "      <td>2:113</td>\n",
       "      <td>3:43</td>\n",
       "      <td>4:28</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>19:10:48</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08f5b445ec6b29deba62e6fd8b0325a6</td>\n",
       "      <td>1:153</td>\n",
       "      <td>2:14</td>\n",
       "      <td>3:1</td>\n",
       "      <td>4:1</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>11:00:40</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4f4041f7db0c7f69892d9b74c1a7efa1</td>\n",
       "      <td>1:164</td>\n",
       "      <td>2:29</td>\n",
       "      <td>3:2</td>\n",
       "      <td>4:5</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:00:46</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2920ece99323b4c111d6f9affc7ea034</td>\n",
       "      <td>1:1511</td>\n",
       "      <td>2:302</td>\n",
       "      <td>3:71</td>\n",
       "      <td>4:62</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>21:00:40</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a814069db8d32f0fa6e188f41059c6e1</td>\n",
       "      <td>1:368</td>\n",
       "      <td>2:29</td>\n",
       "      <td>3:14</td>\n",
       "      <td>4:9</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:00:47</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>74c1c25f4b283fa74a5514307b0d0278</td>\n",
       "      <td>1:1734</td>\n",
       "      <td>2:422</td>\n",
       "      <td>3:101</td>\n",
       "      <td>4:56</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>19:00:48</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a5609739c6b5c2719a3752327c5e33a7</td>\n",
       "      <td>1:1145</td>\n",
       "      <td>2:207</td>\n",
       "      <td>3:90</td>\n",
       "      <td>4:48</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:10:43</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ba32abfc048219e933bee869741da911</td>\n",
       "      <td>1:529</td>\n",
       "      <td>2:44</td>\n",
       "      <td>3:18</td>\n",
       "      <td>4:16</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>23:20:31</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>f47f35242ed40655814bc086d7514046</td>\n",
       "      <td>1:371</td>\n",
       "      <td>2:73</td>\n",
       "      <td>3:9</td>\n",
       "      <td>4:5</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>11:00:39</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44c097b7bd219d104050abbafe51bd49</td>\n",
       "      <td>1:301</td>\n",
       "      <td>2:75</td>\n",
       "      <td>3:27</td>\n",
       "      <td>4:22</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:10:48</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>929ec6c160e6f52c20a4217c7978f681</td>\n",
       "      <td>1:1864</td>\n",
       "      <td>2:252</td>\n",
       "      <td>3:75</td>\n",
       "      <td>4:56</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>07:20:30</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>62afaf3288e236b389af9cfdc5206415</td>\n",
       "      <td>1:2543</td>\n",
       "      <td>2:873</td>\n",
       "      <td>3:263</td>\n",
       "      <td>4:135</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:10:42</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38d5ad2d22b61109fd8e7b43cd0e8901</td>\n",
       "      <td>1:1138</td>\n",
       "      <td>2:270</td>\n",
       "      <td>3:99</td>\n",
       "      <td>4:45</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:00:47</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cb6041cc08444746caf6039d8b9e43cb</td>\n",
       "      <td>1:117</td>\n",
       "      <td>2:17</td>\n",
       "      <td>3:4</td>\n",
       "      <td>4:3</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>07:10:29</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>1:189</td>\n",
       "      <td>2:32</td>\n",
       "      <td>3:3</td>\n",
       "      <td>4:0</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>21:10:41</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>49ac89aa860c27e26c0836cb8dab2df2</td>\n",
       "      <td>1:150</td>\n",
       "      <td>2:21</td>\n",
       "      <td>3:1</td>\n",
       "      <td>4:0</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>23:00:33</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8bb37d24db1ad665e706c2655d9c4c72</td>\n",
       "      <td>1:237</td>\n",
       "      <td>2:49</td>\n",
       "      <td>3:6</td>\n",
       "      <td>4:2</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>21:00:41</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8bb37d24db1ad665e706c2655d9c4c72</td>\n",
       "      <td>1:252</td>\n",
       "      <td>2:50</td>\n",
       "      <td>3:16</td>\n",
       "      <td>4:10</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>13:10:39</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>1:1709</td>\n",
       "      <td>2:355</td>\n",
       "      <td>3:66</td>\n",
       "      <td>4:111</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>11:00:39</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>52a4e8aaa12f70020e889aed8fd5ddbc</td>\n",
       "      <td>1:782</td>\n",
       "      <td>2:171</td>\n",
       "      <td>3:26</td>\n",
       "      <td>4:30</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:10:47</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>87285a66236346350541b8815c5fae94</td>\n",
       "      <td>1:705</td>\n",
       "      <td>2:152</td>\n",
       "      <td>3:39</td>\n",
       "      <td>4:21</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>21:00:41</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>87285a66236346350541b8815c5fae94</td>\n",
       "      <td>1:785</td>\n",
       "      <td>2:198</td>\n",
       "      <td>3:50</td>\n",
       "      <td>4:32</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>13:10:39</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>1:127</td>\n",
       "      <td>2:26</td>\n",
       "      <td>3:4</td>\n",
       "      <td>4:2</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>11:00:39</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1ecbb52d73c522f184a6fc53128b1ea1</td>\n",
       "      <td>1:193</td>\n",
       "      <td>2:20</td>\n",
       "      <td>3:16</td>\n",
       "      <td>4:20</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>23:20:32</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>1ecbb52d73c522f184a6fc53128b1ea1</td>\n",
       "      <td>1:256</td>\n",
       "      <td>2:94</td>\n",
       "      <td>3:22</td>\n",
       "      <td>4:21</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:00:47</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>f2c8c4bb99e6377d21de71275afd6cd2</td>\n",
       "      <td>1:626</td>\n",
       "      <td>2:301</td>\n",
       "      <td>3:44</td>\n",
       "      <td>4:26</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:10:44</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>f2c8c4bb99e6377d21de71275afd6cd2</td>\n",
       "      <td>1:688</td>\n",
       "      <td>2:142</td>\n",
       "      <td>3:40</td>\n",
       "      <td>4:27</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:10:46</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>4b9e4cf2fbdc8281b8a1f9f12b80ce4d</td>\n",
       "      <td>1:135</td>\n",
       "      <td>2:10</td>\n",
       "      <td>3:2</td>\n",
       "      <td>4:9</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>19:20:46</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>1cbfbdd079ef93e74405c53fcfff8567</td>\n",
       "      <td>1:302</td>\n",
       "      <td>2:58</td>\n",
       "      <td>3:16</td>\n",
       "      <td>4:27</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>11:00:39</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>f9280c5dab6910ed44e518248048b9fe</td>\n",
       "      <td>1:299</td>\n",
       "      <td>2:41</td>\n",
       "      <td>3:9</td>\n",
       "      <td>4:6</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>07:20:31</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>74ec84f1cf75cf89ae176c8c6ceec5ba</td>\n",
       "      <td>1:291</td>\n",
       "      <td>2:29</td>\n",
       "      <td>3:5</td>\n",
       "      <td>4:2</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>21:10:40</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>4f8d81b5c31af5d1ba579a65ddc8a5cb</td>\n",
       "      <td>1:423</td>\n",
       "      <td>2:116</td>\n",
       "      <td>3:53</td>\n",
       "      <td>4:15</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>19:00:48</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>4f4041f7db0c7f69892d9b74c1a7efa1</td>\n",
       "      <td>1:153</td>\n",
       "      <td>2:13</td>\n",
       "      <td>3:9</td>\n",
       "      <td>4:0</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>23:00:32</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>a5609739c6b5c2719a3752327c5e33a7</td>\n",
       "      <td>1:1074</td>\n",
       "      <td>2:202</td>\n",
       "      <td>3:66</td>\n",
       "      <td>4:32</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:00:46</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>a5609739c6b5c2719a3752327c5e33a7</td>\n",
       "      <td>1:1015</td>\n",
       "      <td>2:141</td>\n",
       "      <td>3:38</td>\n",
       "      <td>4:54</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>15:20:41</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>ba32abfc048219e933bee869741da911</td>\n",
       "      <td>1:541</td>\n",
       "      <td>2:41</td>\n",
       "      <td>3:17</td>\n",
       "      <td>4:18</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>23:10:32</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>44c097b7bd219d104050abbafe51bd49</td>\n",
       "      <td>1:305</td>\n",
       "      <td>2:33</td>\n",
       "      <td>3:8</td>\n",
       "      <td>4:4</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>21:20:41</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>44c097b7bd219d104050abbafe51bd49</td>\n",
       "      <td>1:288</td>\n",
       "      <td>2:52</td>\n",
       "      <td>3:14</td>\n",
       "      <td>4:2</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:00:46</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>7f84bdfc2b6d4541e1f6c0a3349e0251</td>\n",
       "      <td>1:200</td>\n",
       "      <td>2:19</td>\n",
       "      <td>3:3</td>\n",
       "      <td>4:2</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:20:48</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>929ec6c160e6f52c20a4217c7978f681</td>\n",
       "      <td>1:1770</td>\n",
       "      <td>2:283</td>\n",
       "      <td>3:71</td>\n",
       "      <td>4:38</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>07:10:28</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>62afaf3288e236b389af9cfdc5206415</td>\n",
       "      <td>1:2651</td>\n",
       "      <td>2:803</td>\n",
       "      <td>3:271</td>\n",
       "      <td>4:124</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:00:45</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>62afaf3288e236b389af9cfdc5206415</td>\n",
       "      <td>1:2564</td>\n",
       "      <td>2:742</td>\n",
       "      <td>3:230</td>\n",
       "      <td>4:160</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>15:20:41</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>cb6041cc08444746caf6039d8b9e43cb</td>\n",
       "      <td>1:124</td>\n",
       "      <td>2:18</td>\n",
       "      <td>3:3</td>\n",
       "      <td>4:2</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>07:00:28</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>1:140</td>\n",
       "      <td>2:41</td>\n",
       "      <td>3:10</td>\n",
       "      <td>4:3</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>21:00:41</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>de092beab9305613aca8f79d7d7224e7</td>\n",
       "      <td>1:83</td>\n",
       "      <td>2:65</td>\n",
       "      <td>3:14</td>\n",
       "      <td>4:2</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>13:20:40</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>c9f855e3e13480aad0af64b418e810c3</td>\n",
       "      <td>1:224</td>\n",
       "      <td>2:20</td>\n",
       "      <td>3:4</td>\n",
       "      <td>4:1</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:20:47</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>52a4e8aaa12f70020e889aed8fd5ddbc</td>\n",
       "      <td>1:822</td>\n",
       "      <td>2:196</td>\n",
       "      <td>3:37</td>\n",
       "      <td>4:23</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>21:20:39</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>52a4e8aaa12f70020e889aed8fd5ddbc</td>\n",
       "      <td>1:768</td>\n",
       "      <td>2:144</td>\n",
       "      <td>3:43</td>\n",
       "      <td>4:14</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>09:00:47</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>a735449c5c09df639c35a7d61fad3ee5</td>\n",
       "      <td>1:38</td>\n",
       "      <td>2:7</td>\n",
       "      <td>3:2</td>\n",
       "      <td>4:3</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>17:20:48</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>fc34648599753c9e74ab238e9a4a07ad</td>\n",
       "      <td>1:1439</td>\n",
       "      <td>2:310</td>\n",
       "      <td>3:47</td>\n",
       "      <td>4:41</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>13:00:40</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>1:129</td>\n",
       "      <td>2:7</td>\n",
       "      <td>3:6</td>\n",
       "      <td>4:0</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>23:20:31</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>fff4e8465d1e12621bc361276b6217cf</td>\n",
       "      <td>1:119</td>\n",
       "      <td>2:9</td>\n",
       "      <td>3:4</td>\n",
       "      <td>4:0</td>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>11:10:39</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1752 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 index     one    two  three   four  \\\n",
       "0     1ecbb52d73c522f184a6fc53128b1ea1   1:239  2:127   3:28   4:21   \n",
       "1     f2c8c4bb99e6377d21de71275afd6cd2   1:627  2:299   3:55   4:22   \n",
       "2     f2c8c4bb99e6377d21de71275afd6cd2   1:660  2:143   3:18   4:19   \n",
       "3     4b9e4cf2fbdc8281b8a1f9f12b80ce4d    1:90   2:28    3:5    4:0   \n",
       "4     1cbfbdd079ef93e74405c53fcfff8567   1:301   2:53   3:19   4:19   \n",
       "5     f9280c5dab6910ed44e518248048b9fe   1:303   2:39   3:23    4:0   \n",
       "6     74ec84f1cf75cf89ae176c8c6ceec5ba   1:234   2:41    3:0    4:4   \n",
       "7     74ec84f1cf75cf89ae176c8c6ceec5ba   1:224   2:29    3:9    4:3   \n",
       "8     4f8d81b5c31af5d1ba579a65ddc8a5cb   1:405  2:113   3:43   4:28   \n",
       "9     08f5b445ec6b29deba62e6fd8b0325a6   1:153   2:14    3:1    4:1   \n",
       "10    4f4041f7db0c7f69892d9b74c1a7efa1   1:164   2:29    3:2    4:5   \n",
       "11    2920ece99323b4c111d6f9affc7ea034  1:1511  2:302   3:71   4:62   \n",
       "12    a814069db8d32f0fa6e188f41059c6e1   1:368   2:29   3:14    4:9   \n",
       "13    74c1c25f4b283fa74a5514307b0d0278  1:1734  2:422  3:101   4:56   \n",
       "14    a5609739c6b5c2719a3752327c5e33a7  1:1145  2:207   3:90   4:48   \n",
       "15    ba32abfc048219e933bee869741da911   1:529   2:44   3:18   4:16   \n",
       "16    f47f35242ed40655814bc086d7514046   1:371   2:73    3:9    4:5   \n",
       "17    44c097b7bd219d104050abbafe51bd49   1:301   2:75   3:27   4:22   \n",
       "18    929ec6c160e6f52c20a4217c7978f681  1:1864  2:252   3:75   4:56   \n",
       "19    62afaf3288e236b389af9cfdc5206415  1:2543  2:873  3:263  4:135   \n",
       "20    38d5ad2d22b61109fd8e7b43cd0e8901  1:1138  2:270   3:99   4:45   \n",
       "21    cb6041cc08444746caf6039d8b9e43cb   1:117   2:17    3:4    4:3   \n",
       "22    08232402614a9b48895cc3d0aeb0e9f2   1:189   2:32    3:3    4:0   \n",
       "23    49ac89aa860c27e26c0836cb8dab2df2   1:150   2:21    3:1    4:0   \n",
       "24    8bb37d24db1ad665e706c2655d9c4c72   1:237   2:49    3:6    4:2   \n",
       "25    8bb37d24db1ad665e706c2655d9c4c72   1:252   2:50   3:16   4:10   \n",
       "26    90c5a34f06ac86aee0fd70e2adce7d8a  1:1709  2:355   3:66  4:111   \n",
       "27    52a4e8aaa12f70020e889aed8fd5ddbc   1:782  2:171   3:26   4:30   \n",
       "28    87285a66236346350541b8815c5fae94   1:705  2:152   3:39   4:21   \n",
       "29    87285a66236346350541b8815c5fae94   1:785  2:198   3:50   4:32   \n",
       "...                                ...     ...    ...    ...    ...   \n",
       "1722  fff4e8465d1e12621bc361276b6217cf   1:127   2:26    3:4    4:2   \n",
       "1723  1ecbb52d73c522f184a6fc53128b1ea1   1:193   2:20   3:16   4:20   \n",
       "1724  1ecbb52d73c522f184a6fc53128b1ea1   1:256   2:94   3:22   4:21   \n",
       "1725  f2c8c4bb99e6377d21de71275afd6cd2   1:626  2:301   3:44   4:26   \n",
       "1726  f2c8c4bb99e6377d21de71275afd6cd2   1:688  2:142   3:40   4:27   \n",
       "1727  4b9e4cf2fbdc8281b8a1f9f12b80ce4d   1:135   2:10    3:2    4:9   \n",
       "1728  1cbfbdd079ef93e74405c53fcfff8567   1:302   2:58   3:16   4:27   \n",
       "1729  f9280c5dab6910ed44e518248048b9fe   1:299   2:41    3:9    4:6   \n",
       "1730  74ec84f1cf75cf89ae176c8c6ceec5ba   1:291   2:29    3:5    4:2   \n",
       "1731  4f8d81b5c31af5d1ba579a65ddc8a5cb   1:423  2:116   3:53   4:15   \n",
       "1732  4f4041f7db0c7f69892d9b74c1a7efa1   1:153   2:13    3:9    4:0   \n",
       "1733  a5609739c6b5c2719a3752327c5e33a7  1:1074  2:202   3:66   4:32   \n",
       "1734  a5609739c6b5c2719a3752327c5e33a7  1:1015  2:141   3:38   4:54   \n",
       "1735  ba32abfc048219e933bee869741da911   1:541   2:41   3:17   4:18   \n",
       "1736  44c097b7bd219d104050abbafe51bd49   1:305   2:33    3:8    4:4   \n",
       "1737  44c097b7bd219d104050abbafe51bd49   1:288   2:52   3:14    4:2   \n",
       "1738  7f84bdfc2b6d4541e1f6c0a3349e0251   1:200   2:19    3:3    4:2   \n",
       "1739  929ec6c160e6f52c20a4217c7978f681  1:1770  2:283   3:71   4:38   \n",
       "1740  62afaf3288e236b389af9cfdc5206415  1:2651  2:803  3:271  4:124   \n",
       "1741  62afaf3288e236b389af9cfdc5206415  1:2564  2:742  3:230  4:160   \n",
       "1742  cb6041cc08444746caf6039d8b9e43cb   1:124   2:18    3:3    4:2   \n",
       "1743  08232402614a9b48895cc3d0aeb0e9f2   1:140   2:41   3:10    4:3   \n",
       "1744  de092beab9305613aca8f79d7d7224e7    1:83   2:65   3:14    4:2   \n",
       "1745  c9f855e3e13480aad0af64b418e810c3   1:224   2:20    3:4    4:1   \n",
       "1746  52a4e8aaa12f70020e889aed8fd5ddbc   1:822  2:196   3:37   4:23   \n",
       "1747  52a4e8aaa12f70020e889aed8fd5ddbc   1:768  2:144   3:43   4:14   \n",
       "1748  a735449c5c09df639c35a7d61fad3ee5    1:38    2:7    3:2    4:3   \n",
       "1749  fc34648599753c9e74ab238e9a4a07ad  1:1439  2:310   3:47   4:41   \n",
       "1750  fff4e8465d1e12621bc361276b6217cf   1:129    2:7    3:6    4:0   \n",
       "1751  fff4e8465d1e12621bc361276b6217cf   1:119    2:9    3:4    4:0   \n",
       "\n",
       "            date      time  slot  \n",
       "0     2016-01-22  09:10:47    56  \n",
       "1     2016-01-22  17:20:47   105  \n",
       "2     2016-01-22  09:20:45    57  \n",
       "3     2016-01-22  13:00:40    79  \n",
       "4     2016-01-22  11:10:39    68  \n",
       "5     2016-01-22  15:00:42    91  \n",
       "6     2016-01-22  21:20:40   129  \n",
       "7     2016-01-22  13:10:39    80  \n",
       "8     2016-01-22  19:10:48   116  \n",
       "9     2016-01-22  11:00:40    67  \n",
       "10    2016-01-22  17:00:46   103  \n",
       "11    2016-01-22  21:00:40   127  \n",
       "12    2016-01-22  09:00:47    55  \n",
       "13    2016-01-22  19:00:48   115  \n",
       "14    2016-01-22  17:10:43   104  \n",
       "15    2016-01-22  23:20:31   141  \n",
       "16    2016-01-22  11:00:39    67  \n",
       "17    2016-01-22  09:10:48    56  \n",
       "18    2016-01-22  07:20:30    45  \n",
       "19    2016-01-22  17:10:42   104  \n",
       "20    2016-01-22  09:00:47    55  \n",
       "21    2016-01-22  07:10:29    44  \n",
       "22    2016-01-22  21:10:41   128  \n",
       "23    2016-01-22  23:00:33   139  \n",
       "24    2016-01-22  21:00:41   127  \n",
       "25    2016-01-22  13:10:39    80  \n",
       "26    2016-01-22  11:00:39    67  \n",
       "27    2016-01-22  09:10:47    56  \n",
       "28    2016-01-22  21:00:41   127  \n",
       "29    2016-01-22  13:10:39    80  \n",
       "...          ...       ...   ...  \n",
       "1722  2016-01-22  11:00:39    67  \n",
       "1723  2016-01-22  23:20:32   141  \n",
       "1724  2016-01-22  09:00:47    55  \n",
       "1725  2016-01-22  17:10:44   104  \n",
       "1726  2016-01-22  09:10:46    56  \n",
       "1727  2016-01-22  19:20:46   117  \n",
       "1728  2016-01-22  11:00:39    67  \n",
       "1729  2016-01-22  07:20:31    45  \n",
       "1730  2016-01-22  21:10:40   128  \n",
       "1731  2016-01-22  19:00:48   115  \n",
       "1732  2016-01-22  23:00:32   139  \n",
       "1733  2016-01-22  17:00:46   103  \n",
       "1734  2016-01-22  15:20:41    93  \n",
       "1735  2016-01-22  23:10:32   140  \n",
       "1736  2016-01-22  21:20:41   129  \n",
       "1737  2016-01-22  09:00:46    55  \n",
       "1738  2016-01-22  17:20:48   105  \n",
       "1739  2016-01-22  07:10:28    44  \n",
       "1740  2016-01-22  17:00:45   103  \n",
       "1741  2016-01-22  15:20:41    93  \n",
       "1742  2016-01-22  07:00:28    43  \n",
       "1743  2016-01-22  21:00:41   127  \n",
       "1744  2016-01-22  13:20:40    81  \n",
       "1745  2016-01-22  17:20:47   105  \n",
       "1746  2016-01-22  21:20:39   129  \n",
       "1747  2016-01-22  09:00:47    55  \n",
       "1748  2016-01-22  17:20:48   105  \n",
       "1749  2016-01-22  13:00:40    79  \n",
       "1750  2016-01-22  23:20:31   141  \n",
       "1751  2016-01-22  11:10:39    68  \n",
       "\n",
       "[1752 rows x 8 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tra = pd.read_csv('../../test_set_1/traffic_data/traffic_data_2016-01-22_test',delim_whitespace=True, header=None)\n",
    "tra_col = ['index','one','two','three','four','date','time']\n",
    "test_tra.columns = tra_col\n",
    "test_tra['slot'] = test_tra['time'].map(lambda x: time2slot(x))\n",
    "#set(test_tra['slot'])\n",
    "test_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
